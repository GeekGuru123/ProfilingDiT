W0307 22:52:52.606000 140653797230400 torch/distributed/run.py:779] 
W0307 22:52:52.606000 140653797230400 torch/distributed/run.py:779] *****************************************
W0307 22:52:52.606000 140653797230400 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0307 22:52:52.606000 140653797230400 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 22:53:02.736 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:53:02 [parallel_state.py:200] world_size=8 rank=6 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 22:53:02.765 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:53:02 [parallel_state.py:200] world_size=8 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 22:53:02.798 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:53:02 [parallel_state.py:200] world_size=8 rank=5 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 22:53:02.841 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:53:02 [parallel_state.py:200] world_size=8 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 22:53:02.860 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:53:02 [parallel_state.py:200] world_size=8 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 22:53:02.894 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:53:02 [parallel_state.py:200] world_size=8 rank=7 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 22:53:02.905 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:53:02 [parallel_state.py:200] world_size=8 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 22:53:02.913 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:53:02 [parallel_state.py:200] world_size=8 rank=4 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-07 22:53:02.999 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:53:03.010 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:53:03.012 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:53:03.012 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:53:03.012 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:53:03.012 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:53:03.013 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:53:03.013 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:53:06.595 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:53:06.950 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:53:06.973 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:53:06.982 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:53:06.989 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:53:06.992 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:53:06.994 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:53:07.000 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:53:33.170 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 22:53:34.043 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 22:53:34.233 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 22:53:34.433 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 22:53:34.442 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 22:53:34.658 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 22:53:35.836 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 22:53:35.950 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 22:53:36.146 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 22:53:36.263 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 22:53:36.950 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 22:53:37.105 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:53:37.335 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 22:53:37.489 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:53:37.596 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 22:53:37.617 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 22:53:37.753 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:53:37.773 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.64s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.83s/it]2025-03-07 22:53:41.175 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.20s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.18s/it]/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.16s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.16s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.83s/it]2025-03-07 22:53:44.365 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 22:53:44.528 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.47s/it]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:08,  4.42s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.58s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.79s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.37s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.90s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.19s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.15s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.74s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.95s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.49s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.12s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:16,  5.51s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.26s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.62s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.32s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  2.84s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.59s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.65s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  2.90s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.64s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.37s/it]2025-03-07 22:53:56.106 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:53:58.530 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:53:58.824 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:53:58.849 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 22:53:59.179 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:53:59.333 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:53:59.374 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:53:59.448 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 22:53:59.562 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 22:53:59.772 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 22:54:00.610 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:54:00.996 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.42s/it]2025-03-07 22:54:01.153 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:54:01.295 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  3.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  4.12s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 22:54:01.452 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:54:01.826 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:01.994 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:54:02.042 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:02.117 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 22:54:02.221 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 22:54:03.537 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 22:54:03.958 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:04.117 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:54:04.160 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:04.230 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 22:54:04.314 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 22:54:04.375 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:54:04.723 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 22:54:04.878 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:54:04.925 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:05.004 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 22:54:05.104 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 22:54:05.186 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 22:54:05.591 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:05.743 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.37s/it]2025-03-07 22:54:05.819 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:05.892 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 22:54:05.996 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 22:54:08.000 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:07,  3.99s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.78s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.95s/it]
2025-03-07 22:54:14.904 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:54:15.495 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:15.718 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:54:15.760 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:15.873 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 22:54:16.038 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 22:54:17.057 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:54:22.067 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:54:22.404 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:54:22.745 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:22.906 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:54:22.944 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:23.007 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 22:54:23.130 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 22:54:25.017 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:54:25.374 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:25.529 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:54:25.567 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:54:25.635 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 22:54:25.733 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:33<27:06, 33.20s/it]  2%|▏         | 1/50 [00:30<24:34, 30.09s/it]  2%|▏         | 1/50 [00:36<29:45, 36.44s/it]  2%|▏         | 1/50 [00:10<08:37, 10.57s/it]  2%|▏         | 1/50 [00:13<10:39, 13.05s/it]  2%|▏         | 1/50 [00:31<26:05, 31.95s/it]  2%|▏         | 1/50 [00:31<25:29, 31.20s/it]  2%|▏         | 1/50 [00:19<16:17, 19.96s/it]  4%|▍         | 2/50 [00:37<13:09, 16.46s/it]  4%|▍         | 2/50 [00:17<06:31,  8.16s/it]  4%|▍         | 2/50 [00:15<05:42,  7.14s/it]  4%|▍         | 2/50 [00:24<08:47, 10.99s/it]  4%|▍         | 2/50 [00:36<12:44, 15.94s/it]  4%|▍         | 2/50 [00:41<14:13, 17.79s/it]  4%|▍         | 2/50 [00:35<12:30, 15.63s/it]  4%|▍         | 2/50 [00:34<12:10, 15.21s/it]  6%|▌         | 3/50 [00:20<04:43,  6.03s/it]  6%|▌         | 3/50 [00:42<08:41, 11.09s/it]  6%|▌         | 3/50 [00:29<06:21,  8.12s/it]  6%|▌         | 3/50 [00:41<08:27, 10.81s/it]  6%|▌         | 3/50 [00:22<05:09,  6.58s/it]  6%|▌         | 3/50 [00:45<09:15, 11.82s/it]  6%|▌         | 3/50 [00:40<08:20, 10.64s/it]  6%|▌         | 3/50 [00:39<08:09, 10.42s/it]  8%|▊         | 4/50 [00:24<04:13,  5.51s/it]  8%|▊         | 4/50 [00:47<06:34,  8.58s/it]  8%|▊         | 4/50 [00:27<04:29,  5.85s/it]  8%|▊         | 4/50 [00:50<06:54,  9.02s/it]  8%|▊         | 4/50 [00:34<05:11,  6.78s/it]  8%|▊         | 4/50 [00:45<06:22,  8.30s/it]  8%|▊         | 4/50 [00:46<06:26,  8.41s/it]  8%|▊         | 4/50 [00:44<06:15,  8.17s/it] 10%|█         | 5/50 [00:29<03:55,  5.23s/it] 10%|█         | 5/50 [00:52<05:23,  7.19s/it] 10%|█         | 5/50 [00:50<05:18,  7.08s/it] 10%|█         | 5/50 [00:31<04:04,  5.44s/it] 10%|█         | 5/50 [00:38<04:31,  6.04s/it] 10%|█         | 5/50 [00:55<05:36,  7.47s/it] 10%|█         | 5/50 [00:50<05:15,  7.01s/it] 10%|█         | 5/50 [00:49<05:11,  6.93s/it] 12%|█▏        | 6/50 [00:34<03:42,  5.06s/it] 12%|█▏        | 6/50 [00:56<04:39,  6.35s/it] 12%|█▏        | 6/50 [00:43<04:06,  5.59s/it] 12%|█▏        | 6/50 [00:36<03:48,  5.20s/it] 12%|█▏        | 6/50 [00:55<04:36,  6.28s/it] 12%|█▏        | 6/50 [00:54<04:34,  6.24s/it] 12%|█▏        | 6/50 [01:00<04:47,  6.54s/it] 12%|█▏        | 6/50 [00:53<04:31,  6.18s/it] 14%|█▍        | 7/50 [01:00<04:08,  5.77s/it] 14%|█▍        | 7/50 [00:38<03:32,  4.95s/it] 14%|█▍        | 7/50 [01:01<04:10,  5.82s/it] 14%|█▍        | 7/50 [00:48<03:48,  5.31s/it] 14%|█▍        | 7/50 [00:41<03:37,  5.05s/it] 14%|█▍        | 7/50 [01:04<04:15,  5.95s/it] 14%|█▍        | 7/50 [00:59<04:07,  5.75s/it] 14%|█▍        | 7/50 [00:58<04:05,  5.71s/it] 16%|█▌        | 8/50 [00:46<03:27,  4.94s/it] 16%|█▌        | 8/50 [01:05<03:48,  5.44s/it] 16%|█▌        | 8/50 [00:43<03:24,  4.88s/it] 16%|█▌        | 8/50 [01:06<03:49,  5.47s/it] 16%|█▌        | 8/50 [00:53<03:35,  5.12s/it] 16%|█▌        | 8/50 [01:09<03:53,  5.56s/it] 16%|█▌        | 8/50 [01:04<03:47,  5.42s/it] 16%|█▌        | 8/50 [01:03<03:46,  5.39s/it] 18%|█▊        | 9/50 [00:57<03:24,  5.00s/it] 18%|█▊        | 9/50 [00:50<03:19,  4.87s/it] 18%|█▊        | 9/50 [01:08<03:33,  5.20s/it] 18%|█▊        | 9/50 [01:10<03:34,  5.24s/it] 18%|█▊        | 9/50 [00:48<03:17,  4.83s/it] 18%|█▊        | 9/50 [01:14<03:37,  5.29s/it] 18%|█▊        | 9/50 [01:09<03:33,  5.21s/it] 18%|█▊        | 9/50 [01:07<03:32,  5.18s/it] 20%|██        | 10/50 [01:02<03:16,  4.91s/it] 20%|██        | 10/50 [01:14<03:22,  5.06s/it] 20%|██        | 10/50 [00:55<03:12,  4.82s/it] 20%|██        | 10/50 [00:53<03:11,  4.79s/it] 20%|██        | 10/50 [01:15<03:22,  5.07s/it] 20%|██        | 10/50 [01:13<03:21,  5.05s/it] 20%|██        | 10/50 [01:18<03:24,  5.11s/it] 20%|██        | 10/50 [01:12<03:21,  5.04s/it] 22%|██▏       | 11/50 [01:07<03:08,  4.84s/it] 22%|██▏       | 11/50 [01:00<03:06,  4.79s/it] 22%|██▏       | 11/50 [01:19<03:12,  4.95s/it] 22%|██▏       | 11/50 [00:57<03:05,  4.76s/it] 22%|██▏       | 11/50 [01:18<03:12,  4.94s/it] 22%|██▏       | 11/50 [01:20<03:13,  4.96s/it] 22%|██▏       | 11/50 [01:23<03:14,  4.99s/it] 22%|██▏       | 11/50 [01:17<03:12,  4.93s/it] 24%|██▍       | 12/50 [01:11<03:02,  4.80s/it] 24%|██▍       | 12/50 [01:28<03:06,  4.90s/it] 24%|██▍       | 12/50 [01:04<03:00,  4.76s/it] 24%|██▍       | 12/50 [01:23<03:05,  4.87s/it] 24%|██▍       | 12/50 [01:02<03:00,  4.74s/it] 24%|██▍       | 12/50 [01:25<03:05,  4.88s/it] 24%|██▍       | 12/50 [01:23<03:04,  4.87s/it] 24%|██▍       | 12/50 [01:22<03:04,  4.86s/it] 26%|██▌       | 13/50 [01:16<02:56,  4.77s/it] 26%|██▌       | 13/50 [01:09<02:55,  4.74s/it] 26%|██▌       | 13/50 [01:28<02:58,  4.82s/it] 26%|██▌       | 13/50 [01:07<02:55,  4.73s/it] 26%|██▌       | 13/50 [01:27<02:58,  4.82s/it] 26%|██▌       | 13/50 [01:29<02:58,  4.83s/it] 26%|██▌       | 13/50 [01:33<02:59,  4.84s/it] 26%|██▌       | 13/50 [01:26<02:58,  4.81s/it] 28%|██▊       | 14/50 [01:21<02:50,  4.75s/it] 28%|██▊       | 14/50 [01:14<02:50,  4.73s/it] 28%|██▊       | 14/50 [01:33<02:52,  4.79s/it] 28%|██▊       | 14/50 [01:37<02:52,  4.80s/it] 28%|██▊       | 14/50 [01:11<02:50,  4.72s/it] 28%|██▊       | 14/50 [01:32<02:52,  4.78s/it] 28%|██▊       | 14/50 [01:34<02:52,  4.79s/it] 28%|██▊       | 14/50 [01:31<02:52,  4.78s/it] 30%|███       | 15/50 [01:25<02:45,  4.74s/it] 30%|███       | 15/50 [01:37<02:46,  4.76s/it] 30%|███       | 15/50 [01:19<02:45,  4.72s/it] 30%|███       | 15/50 [01:16<02:45,  4.72s/it] 30%|███       | 15/50 [01:37<02:46,  4.76s/it] 30%|███       | 15/50 [01:39<02:46,  4.76s/it] 30%|███       | 15/50 [01:42<02:46,  4.77s/it] 30%|███       | 15/50 [01:36<02:46,  4.76s/it] 32%|███▏      | 16/50 [01:30<02:40,  4.73s/it] 32%|███▏      | 16/50 [01:23<02:40,  4.72s/it] 32%|███▏      | 16/50 [01:42<02:41,  4.74s/it] 32%|███▏      | 16/50 [01:21<02:40,  4.71s/it] 32%|███▏      | 16/50 [01:47<02:41,  4.75s/it] 32%|███▏      | 16/50 [01:41<02:41,  4.74s/it] 32%|███▏      | 16/50 [01:43<02:41,  4.74s/it] 32%|███▏      | 16/50 [01:40<02:41,  4.74s/it] 34%|███▍      | 17/50 [01:28<02:35,  4.71s/it] 34%|███▍      | 17/50 [01:47<02:36,  4.73s/it] 34%|███▍      | 17/50 [01:51<02:36,  4.74s/it] 34%|███▍      | 17/50 [01:25<02:35,  4.71s/it] 34%|███▍      | 17/50 [01:46<02:36,  4.73s/it] 34%|███▍      | 17/50 [01:48<02:36,  4.73s/it] 34%|███▍      | 17/50 [01:35<02:35,  4.72s/it] 34%|███▍      | 17/50 [01:45<02:36,  4.73s/it] 36%|███▌      | 18/50 [01:40<02:30,  4.72s/it] 36%|███▌      | 18/50 [01:33<02:30,  4.71s/it] 36%|███▌      | 18/50 [01:52<02:31,  4.73s/it] 36%|███▌      | 18/50 [01:56<02:31,  4.73s/it] 36%|███▌      | 18/50 [01:53<02:31,  4.73s/it] 36%|███▌      | 18/50 [01:51<02:31,  4.72s/it] 36%|███▌      | 18/50 [01:30<02:30,  4.71s/it] 36%|███▌      | 18/50 [01:50<02:31,  4.72s/it] 38%|███▊      | 19/50 [01:44<02:26,  4.71s/it] 38%|███▊      | 19/50 [01:37<02:25,  4.71s/it] 38%|███▊      | 19/50 [01:56<02:26,  4.72s/it] 38%|███▊      | 19/50 [01:35<02:25,  4.71s/it] 38%|███▊      | 19/50 [01:56<02:26,  4.72s/it] 38%|███▊      | 19/50 [02:01<02:26,  4.72s/it] 38%|███▊      | 19/50 [01:58<02:26,  4.72s/it] 38%|███▊      | 19/50 [01:54<02:26,  4.72s/it] 40%|████      | 20/50 [01:49<02:21,  4.71s/it] 40%|████      | 20/50 [02:01<02:21,  4.71s/it] 40%|████      | 20/50 [01:42<02:21,  4.71s/it] 40%|████      | 20/50 [01:40<02:21,  4.71s/it] 40%|████      | 20/50 [02:05<02:21,  4.71s/it] 40%|████      | 20/50 [02:02<02:21,  4.71s/it] 40%|████      | 20/50 [02:00<02:21,  4.71s/it] 40%|████      | 20/50 [01:59<02:21,  4.71s/it] 42%|████▏     | 21/50 [01:54<02:16,  4.71s/it] 42%|████▏     | 21/50 [01:47<02:16,  4.71s/it] 42%|████▏     | 21/50 [02:10<02:16,  4.71s/it] 42%|████▏     | 21/50 [02:06<02:16,  4.71s/it] 42%|████▏     | 21/50 [02:07<02:16,  4.71s/it] 42%|████▏     | 21/50 [02:05<02:16,  4.71s/it] 42%|████▏     | 21/50 [01:44<02:16,  4.71s/it] 42%|████▏     | 21/50 [02:04<02:16,  4.71s/it] 44%|████▍     | 22/50 [01:58<02:11,  4.71s/it] 44%|████▍     | 22/50 [02:10<02:11,  4.71s/it] 44%|████▍     | 22/50 [01:51<02:11,  4.71s/it] 44%|████▍     | 22/50 [02:10<02:11,  4.71s/it] 44%|████▍     | 22/50 [01:49<02:11,  4.71s/it] 44%|████▍     | 22/50 [02:12<02:11,  4.71s/it] 44%|████▍     | 22/50 [02:15<02:11,  4.71s/it] 44%|████▍     | 22/50 [02:09<02:11,  4.71s/it] 46%|████▌     | 23/50 [02:03<02:07,  4.71s/it] 46%|████▌     | 23/50 [01:56<02:07,  4.71s/it] 46%|████▌     | 23/50 [02:15<02:07,  4.71s/it] 46%|████▌     | 23/50 [02:20<02:07,  4.71s/it] 46%|████▌     | 23/50 [01:54<02:07,  4.71s/it] 46%|████▌     | 23/50 [02:14<02:07,  4.71s/it] 46%|████▌     | 23/50 [02:16<02:07,  4.71s/it] 46%|████▌     | 23/50 [02:13<02:07,  4.71s/it] 48%|████▊     | 24/50 [02:08<02:02,  4.71s/it] 48%|████▊     | 24/50 [02:01<02:02,  4.71s/it] 48%|████▊     | 24/50 [02:20<02:02,  4.71s/it] 48%|████▊     | 24/50 [01:58<02:02,  4.71s/it] 48%|████▊     | 24/50 [02:24<02:02,  4.71s/it] 48%|████▊     | 24/50 [02:19<02:02,  4.71s/it] 48%|████▊     | 24/50 [02:21<02:02,  4.71s/it] 48%|████▊     | 24/50 [02:18<02:02,  4.71s/it] 50%|█████     | 25/50 [02:06<01:57,  4.71s/it] 50%|█████     | 25/50 [02:13<01:57,  4.71s/it] 50%|█████     | 25/50 [02:25<01:57,  4.71s/it] 50%|█████     | 25/50 [02:26<01:57,  4.71s/it] 50%|█████     | 25/50 [02:24<01:57,  4.71s/it] 50%|█████     | 25/50 [02:03<01:57,  4.71s/it] 50%|█████     | 25/50 [02:29<01:57,  4.71s/it] 50%|█████     | 25/50 [02:23<01:57,  4.71s/it] 52%|█████▏    | 26/50 [02:10<01:52,  4.71s/it] 52%|█████▏    | 26/50 [02:29<01:52,  4.71s/it] 52%|█████▏    | 26/50 [02:17<01:52,  4.71s/it] 52%|█████▏    | 26/50 [02:34<01:52,  4.71s/it] 52%|█████▏    | 26/50 [02:28<01:52,  4.71s/it] 52%|█████▏    | 26/50 [02:30<01:52,  4.71s/it] 52%|█████▏    | 26/50 [02:08<01:52,  4.71s/it] 52%|█████▏    | 26/50 [02:27<01:52,  4.71s/it] 54%|█████▍    | 27/50 [02:15<01:48,  4.70s/it] 54%|█████▍    | 27/50 [02:22<01:48,  4.70s/it] 54%|█████▍    | 27/50 [02:34<01:48,  4.70s/it] 54%|█████▍    | 27/50 [02:38<01:48,  4.71s/it] 54%|█████▍    | 27/50 [02:33<01:48,  4.70s/it] 54%|█████▍    | 27/50 [02:13<01:48,  4.70s/it] 54%|█████▍    | 27/50 [02:35<01:48,  4.71s/it] 54%|█████▍    | 27/50 [02:32<01:48,  4.71s/it] 56%|█████▌    | 28/50 [02:39<01:43,  4.71s/it] 56%|█████▌    | 28/50 [02:20<01:43,  4.71s/it] 56%|█████▌    | 28/50 [02:17<01:43,  4.71s/it] 56%|█████▌    | 28/50 [02:27<01:43,  4.71s/it] 56%|█████▌    | 28/50 [02:38<01:43,  4.71s/it] 56%|█████▌    | 28/50 [02:40<01:43,  4.71s/it] 56%|█████▌    | 28/50 [02:43<01:43,  4.71s/it] 56%|█████▌    | 28/50 [02:37<01:43,  4.71s/it] 58%|█████▊    | 29/50 [02:31<01:38,  4.71s/it] 58%|█████▊    | 29/50 [02:24<01:38,  4.71s/it] 58%|█████▊    | 29/50 [02:43<01:38,  4.71s/it] 58%|█████▊    | 29/50 [02:22<01:38,  4.71s/it] 58%|█████▊    | 29/50 [02:48<01:38,  4.71s/it] 58%|█████▊    | 29/50 [02:43<01:38,  4.71s/it] 58%|█████▊    | 29/50 [02:45<01:38,  4.71s/it] 58%|█████▊    | 29/50 [02:42<01:38,  4.71s/it] 60%|██████    | 30/50 [02:29<01:34,  4.71s/it] 60%|██████    | 30/50 [02:48<01:34,  4.71s/it] 60%|██████    | 30/50 [02:36<01:34,  4.71s/it] 60%|██████    | 30/50 [02:53<01:34,  4.71s/it] 60%|██████    | 30/50 [02:47<01:34,  4.71s/it] 60%|██████    | 30/50 [02:49<01:34,  4.71s/it] 60%|██████    | 30/50 [02:27<01:34,  4.71s/it] 60%|██████    | 30/50 [02:46<01:34,  4.71s/it] 62%|██████▏   | 31/50 [02:41<01:29,  4.71s/it] 62%|██████▏   | 31/50 [02:34<01:29,  4.71s/it] 62%|██████▏   | 31/50 [02:53<01:29,  4.71s/it] 62%|██████▏   | 31/50 [02:57<01:29,  4.71s/it] 62%|██████▏   | 31/50 [02:52<01:29,  4.71s/it] 62%|██████▏   | 31/50 [02:31<01:29,  4.71s/it] 62%|██████▏   | 31/50 [02:54<01:29,  4.71s/it] 62%|██████▏   | 31/50 [02:51<01:29,  4.71s/it] 64%|██████▍   | 32/50 [02:57<01:24,  4.71s/it] 64%|██████▍   | 32/50 [02:39<01:24,  4.70s/it] 64%|██████▍   | 32/50 [02:45<01:24,  4.71s/it] 64%|██████▍   | 32/50 [02:36<01:24,  4.70s/it] 64%|██████▍   | 32/50 [02:57<01:24,  4.71s/it] 64%|██████▍   | 32/50 [02:59<01:24,  4.71s/it] 64%|██████▍   | 32/50 [03:02<01:24,  4.71s/it] 64%|██████▍   | 32/50 [02:56<01:24,  4.70s/it] 66%|██████▌   | 33/50 [02:50<01:19,  4.70s/it] 66%|██████▌   | 33/50 [02:43<01:19,  4.70s/it] 66%|██████▌   | 33/50 [03:02<01:19,  4.70s/it] 66%|██████▌   | 33/50 [03:07<01:19,  4.70s/it] 66%|██████▌   | 33/50 [02:41<01:19,  4.70s/it] 66%|██████▌   | 33/50 [03:01<01:19,  4.70s/it] 66%|██████▌   | 33/50 [03:03<01:19,  4.70s/it] 66%|██████▌   | 33/50 [03:00<01:19,  4.70s/it] 68%|██████▊   | 34/50 [02:55<01:15,  4.70s/it] 68%|██████▊   | 34/50 [03:07<01:15,  4.70s/it] 68%|██████▊   | 34/50 [02:48<01:15,  4.70s/it] 68%|██████▊   | 34/50 [03:11<01:15,  4.70s/it] 68%|██████▊   | 34/50 [03:06<01:15,  4.70s/it] 68%|██████▊   | 34/50 [03:08<01:15,  4.70s/it] 68%|██████▊   | 34/50 [02:45<01:15,  4.70s/it] 68%|██████▊   | 34/50 [03:05<01:15,  4.70s/it] 70%|███████   | 35/50 [02:53<01:10,  4.70s/it] 70%|███████   | 35/50 [03:00<01:10,  4.70s/it] 70%|███████   | 35/50 [03:12<01:10,  4.70s/it] 70%|███████   | 35/50 [03:16<01:10,  4.70s/it] 70%|███████   | 35/50 [02:50<01:10,  4.70s/it] 70%|███████   | 35/50 [03:13<01:10,  4.70s/it] 70%|███████   | 35/50 [03:11<01:10,  4.70s/it] 70%|███████   | 35/50 [03:10<01:10,  4.70s/it] 72%|███████▏  | 36/50 [03:04<01:05,  4.70s/it] 72%|███████▏  | 36/50 [03:16<01:05,  4.70s/it] 72%|███████▏  | 36/50 [02:57<01:05,  4.70s/it] 72%|███████▏  | 36/50 [03:18<01:05,  4.70s/it] 72%|███████▏  | 36/50 [03:21<01:05,  4.70s/it] 72%|███████▏  | 36/50 [03:15<01:05,  4.70s/it] 72%|███████▏  | 36/50 [02:55<01:05,  4.70s/it] 72%|███████▏  | 36/50 [03:14<01:05,  4.70s/it] 74%|███████▍  | 37/50 [03:02<01:01,  4.70s/it] 74%|███████▍  | 37/50 [03:21<01:01,  4.70s/it] 74%|███████▍  | 37/50 [03:09<01:01,  4.70s/it] 74%|███████▍  | 37/50 [03:00<01:01,  4.70s/it] 74%|███████▍  | 37/50 [03:20<01:01,  4.70s/it] 74%|███████▍  | 37/50 [03:25<01:01,  4.70s/it] 74%|███████▍  | 37/50 [03:22<01:01,  4.70s/it] 74%|███████▍  | 37/50 [03:19<01:01,  4.70s/it] 76%|███████▌  | 38/50 [03:14<00:56,  4.70s/it] 76%|███████▌  | 38/50 [03:07<00:56,  4.70s/it] 76%|███████▌  | 38/50 [03:26<00:56,  4.70s/it] 76%|███████▌  | 38/50 [03:30<00:56,  4.70s/it] 76%|███████▌  | 38/50 [03:25<00:56,  4.70s/it] 76%|███████▌  | 38/50 [03:04<00:56,  4.70s/it] 76%|███████▌  | 38/50 [03:27<00:56,  4.70s/it] 76%|███████▌  | 38/50 [03:24<00:56,  4.70s/it] 78%|███████▊  | 39/50 [03:11<00:51,  4.70s/it] 78%|███████▊  | 39/50 [03:30<00:51,  4.70s/it] 78%|███████▊  | 39/50 [03:09<00:51,  4.70s/it] 78%|███████▊  | 39/50 [03:18<00:51,  4.70s/it] 78%|███████▊  | 39/50 [03:35<00:51,  4.70s/it] 78%|███████▊  | 39/50 [03:30<00:51,  4.70s/it] 78%|███████▊  | 39/50 [03:32<00:51,  4.70s/it] 78%|███████▊  | 39/50 [03:29<00:51,  4.70s/it] 80%|████████  | 40/50 [03:35<00:47,  4.70s/it] 80%|████████  | 40/50 [03:23<00:47,  4.70s/it] 80%|████████  | 40/50 [03:16<00:47,  4.70s/it] 80%|████████  | 40/50 [03:40<00:47,  4.70s/it] 80%|████████  | 40/50 [03:14<00:47,  4.70s/it] 80%|████████  | 40/50 [03:34<00:47,  4.70s/it] 80%|████████  | 40/50 [03:36<00:47,  4.70s/it] 80%|████████  | 40/50 [03:33<00:47,  4.70s/it] 82%|████████▏ | 41/50 [03:21<00:42,  4.70s/it] 82%|████████▏ | 41/50 [03:40<00:42,  4.70s/it] 82%|████████▏ | 41/50 [03:28<00:42,  4.70s/it] 82%|████████▏ | 41/50 [03:44<00:42,  4.70s/it] 82%|████████▏ | 41/50 [03:41<00:42,  4.70s/it] 82%|████████▏ | 41/50 [03:18<00:42,  4.70s/it] 82%|████████▏ | 41/50 [03:39<00:42,  4.70s/it] 82%|████████▏ | 41/50 [03:38<00:42,  4.70s/it] 84%|████████▍ | 42/50 [03:26<00:37,  4.70s/it] 84%|████████▍ | 42/50 [03:44<00:37,  4.70s/it] 84%|████████▍ | 42/50 [03:32<00:37,  4.70s/it] 84%|████████▍ | 42/50 [03:49<00:37,  4.70s/it] 84%|████████▍ | 42/50 [03:46<00:37,  4.70s/it] 84%|████████▍ | 42/50 [03:23<00:37,  4.70s/it] 84%|████████▍ | 42/50 [03:44<00:37,  4.70s/it] 84%|████████▍ | 42/50 [03:43<00:37,  4.70s/it] 86%|████████▌ | 43/50 [03:49<00:32,  4.70s/it] 86%|████████▌ | 43/50 [03:30<00:32,  4.70s/it] 86%|████████▌ | 43/50 [03:37<00:32,  4.70s/it] 86%|████████▌ | 43/50 [03:54<00:32,  4.70s/it] 86%|████████▌ | 43/50 [03:50<00:32,  4.70s/it] 86%|████████▌ | 43/50 [03:48<00:32,  4.70s/it] 86%|████████▌ | 43/50 [03:28<00:32,  4.70s/it] 86%|████████▌ | 43/50 [03:47<00:32,  4.70s/it] 88%|████████▊ | 44/50 [03:35<00:28,  4.70s/it] 88%|████████▊ | 44/50 [03:42<00:28,  4.70s/it] 88%|████████▊ | 44/50 [03:54<00:28,  4.70s/it] 88%|████████▊ | 44/50 [03:32<00:28,  4.70s/it] 88%|████████▊ | 44/50 [03:58<00:28,  4.70s/it] 88%|████████▊ | 44/50 [03:53<00:28,  4.70s/it] 88%|████████▊ | 44/50 [03:55<00:28,  4.70s/it] 88%|████████▊ | 44/50 [03:52<00:28,  4.70s/it] 90%|█████████ | 45/50 [03:40<00:23,  4.70s/it] 90%|█████████ | 45/50 [03:59<00:23,  4.70s/it] 90%|█████████ | 45/50 [03:47<00:23,  4.70s/it] 90%|█████████ | 45/50 [03:37<00:23,  4.70s/it] 90%|█████████ | 45/50 [03:58<00:23,  4.70s/it] 90%|█████████ | 45/50 [04:03<00:23,  4.70s/it] 90%|█████████ | 45/50 [04:00<00:23,  4.70s/it] 90%|█████████ | 45/50 [03:57<00:23,  4.70s/it] 92%|█████████▏| 46/50 [04:03<00:18,  4.70s/it] 92%|█████████▏| 46/50 [03:44<00:18,  4.70s/it] 92%|█████████▏| 46/50 [03:51<00:18,  4.70s/it] 92%|█████████▏| 46/50 [03:42<00:18,  4.70s/it] 92%|█████████▏| 46/50 [04:03<00:18,  4.70s/it] 92%|█████████▏| 46/50 [04:08<00:18,  4.70s/it] 92%|█████████▏| 46/50 [04:05<00:18,  4.70s/it] 92%|█████████▏| 46/50 [04:01<00:18,  4.70s/it] 94%|█████████▍| 47/50 [03:56<00:14,  4.70s/it] 94%|█████████▍| 47/50 [03:49<00:14,  4.70s/it] 94%|█████████▍| 47/50 [04:08<00:14,  4.70s/it] 94%|█████████▍| 47/50 [03:47<00:14,  4.70s/it] 94%|█████████▍| 47/50 [04:12<00:14,  4.70s/it] 94%|█████████▍| 47/50 [04:07<00:14,  4.70s/it] 94%|█████████▍| 47/50 [04:09<00:14,  4.70s/it] 94%|█████████▍| 47/50 [04:06<00:14,  4.70s/it] 96%|█████████▌| 48/50 [04:01<00:09,  4.70s/it] 96%|█████████▌| 48/50 [03:54<00:09,  4.70s/it] 96%|█████████▌| 48/50 [04:13<00:09,  4.70s/it] 96%|█████████▌| 48/50 [04:17<00:09,  4.70s/it] 96%|█████████▌| 48/50 [03:51<00:09,  4.70s/it] 96%|█████████▌| 48/50 [04:14<00:09,  4.70s/it] 96%|█████████▌| 48/50 [04:12<00:09,  4.70s/it] 96%|█████████▌| 48/50 [04:11<00:09,  4.70s/it] 98%|█████████▊| 49/50 [04:05<00:04,  4.70s/it] 98%|█████████▊| 49/50 [03:58<00:04,  4.70s/it] 98%|█████████▊| 49/50 [04:17<00:04,  4.70s/it] 98%|█████████▊| 49/50 [04:22<00:04,  4.70s/it] 98%|█████████▊| 49/50 [03:56<00:04,  4.70s/it] 98%|█████████▊| 49/50 [04:17<00:04,  4.70s/it] 98%|█████████▊| 49/50 [04:19<00:04,  4.70s/it] 98%|█████████▊| 49/50 [04:16<00:04,  4.70s/it]100%|██████████| 50/50 [04:03<00:00,  4.70s/it]100%|██████████| 50/50 [04:10<00:00,  4.70s/it]100%|██████████| 50/50 [04:03<00:00,  4.87s/it]
100%|██████████| 50/50 [04:22<00:00,  4.70s/it]代码执行时间: 243.67 秒100%|██████████| 50/50 [04:10<00:00,  5.01s/it]

代码执行时间: 250.55 秒
100%|██████████| 50/50 [04:22<00:00,  5.25s/it]
代码执行时间: 262.56 秒
100%|██████████| 50/50 [04:27<00:00,  4.70s/it]100%|██████████| 50/50 [04:01<00:00,  4.70s/it]100%|██████████| 50/50 [04:21<00:00,  4.70s/it]100%|██████████| 50/50 [04:27<00:00,  5.34s/it]
代码执行时间: 267.06 秒
100%|██████████| 50/50 [04:01<00:00,  4.82s/it]
100%|██████████| 50/50 [04:23<00:00,  4.70s/it]代码执行时间: 241.19 秒
100%|██████████| 50/50 [04:21<00:00,  5.24s/it]
代码执行时间: 261.81 秒
100%|██████████| 50/50 [04:23<00:00,  5.28s/it]
代码执行时间: 263.82 秒
100%|██████████| 50/50 [04:20<00:00,  4.70s/it]100%|██████████| 50/50 [04:20<00:00,  5.22s/it]
代码执行时间: 260.78 秒
2025-03-07 22:58:59.837 | INFO     | hyvideo.inference:predict:669 - Success, time: 274.10336470603943
2025-03-07 22:59:00.038 | INFO     | hyvideo.inference:predict:669 - Success, time: 294.0424168109894
2025-03-07 22:59:00.096 | INFO     | hyvideo.inference:predict:669 - Success, time: 297.8754427433014
2025-03-07 22:59:00.260 | INFO     | hyvideo.inference:predict:669 - Success, time: 284.2211458683014
2025-03-07 22:59:00.278 | INFO     | hyvideo.inference:predict:669 - Success, time: 300.7157974243164
2025-03-07 22:59:00.336 | INFO     | hyvideo.inference:predict:669 - Success, time: 277.20610332489014
2025-03-07 22:59:00.351 | INFO     | hyvideo.inference:predict:669 - Success, time: 295.247234582901
2025-03-07 22:59:01.025 | INFO     | hyvideo.inference:predict:669 - Success, time: 296.71139216423035
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-07 22:59:04.787 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0307 22:59:09.136000 139846140970816 torch/distributed/run.py:779] 
W0307 22:59:09.136000 139846140970816 torch/distributed/run.py:779] *****************************************
W0307 22:59:09.136000 139846140970816 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0307 22:59:09.136000 139846140970816 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 22:59:15.471 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:59:15 [parallel_state.py:200] world_size=4 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 22:59:15.710 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:59:15 [parallel_state.py:200] world_size=4 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 22:59:15.836 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 22:59:15.839 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 22:59:15 [parallel_state.py:200] world_size=4 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
DEBUG 03-07 22:59:15 [parallel_state.py:200] world_size=4 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-07 22:59:15.882 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:59:15.882 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:59:15.883 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:59:15.883 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 22:59:17.020 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:59:17.031 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:59:17.082 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:59:17.088 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 22:59:32.837 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 22:59:32.876 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 22:59:34.818 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 22:59:34.855 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 22:59:34.963 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:59:34.996 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 22:59:37.240 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 22:59:37.293 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.95s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.92s/it]2025-03-07 22:59:40.076 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 22:59:40.135 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 22:59:40.223 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:59:40.280 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.82s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.79s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.05s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.07s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.71s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.70s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.32s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.86s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.85s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.12s/it]2025-03-07 22:59:54.184 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:59:54.394 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.50s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  2.79s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.54s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:15<00:05,  5.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.88s/it]
2025-03-07 22:59:56.884 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:59:57.026 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 22:59:57.233 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:59:57.376 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:59:57.381 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:59:57.420 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:59:57.487 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 22:59:57.524 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 22:59:57.563 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 22:59:57.583 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 22:59:57.629 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 22:59:57.724 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:00:02.600 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:00:03.832 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:00:05.986 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:00:06.398 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:00:06.409 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:00:06.550 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:00:06.589 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:00:06.663 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 23:00:06.754 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:00:06.777 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:00:06.901 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:00:06.949 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:00:07.040 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 23:00:07.155 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:12<10:06, 12.37s/it]  2%|▏         | 1/50 [00:21<17:22, 21.27s/it]  2%|▏         | 1/50 [00:11<09:42, 11.89s/it]  2%|▏         | 1/50 [00:21<17:30, 21.43s/it]  4%|▍         | 2/50 [00:20<08:10, 10.21s/it]  4%|▍         | 2/50 [00:21<08:19, 10.41s/it]  4%|▍         | 2/50 [00:30<11:18, 14.14s/it]  4%|▍         | 2/50 [00:30<11:19, 14.15s/it]  6%|▌         | 3/50 [00:30<07:42,  9.84s/it]  6%|▌         | 3/50 [00:30<07:37,  9.73s/it]  6%|▌         | 3/50 [00:39<09:17, 11.87s/it]  6%|▌         | 3/50 [00:39<09:17, 11.87s/it]  8%|▊         | 4/50 [00:39<07:19,  9.56s/it]  8%|▊         | 4/50 [00:48<08:16, 10.79s/it]  8%|▊         | 4/50 [00:39<07:16,  9.50s/it]  8%|▊         | 4/50 [00:48<08:16, 10.79s/it] 10%|█         | 5/50 [00:48<07:03,  9.42s/it] 10%|█         | 5/50 [00:57<07:39, 10.20s/it] 10%|█         | 5/50 [00:48<07:01,  9.38s/it] 10%|█         | 5/50 [00:57<07:39, 10.21s/it] 12%|█▏        | 6/50 [01:07<07:13,  9.84s/it] 12%|█▏        | 6/50 [00:57<06:49,  9.30s/it] 12%|█▏        | 6/50 [00:58<06:50,  9.33s/it] 12%|█▏        | 6/50 [01:07<07:13,  9.85s/it] 14%|█▍        | 7/50 [01:07<06:38,  9.27s/it] 14%|█▍        | 7/50 [01:06<06:37,  9.25s/it] 14%|█▍        | 7/50 [01:16<06:53,  9.62s/it] 14%|█▍        | 7/50 [01:16<06:53,  9.62s/it] 16%|█▌        | 8/50 [01:25<06:37,  9.47s/it] 16%|█▌        | 8/50 [01:16<06:27,  9.23s/it] 16%|█▌        | 8/50 [01:15<06:27,  9.22s/it] 16%|█▌        | 8/50 [01:25<06:37,  9.47s/it] 18%|█▊        | 9/50 [01:24<06:17,  9.20s/it] 18%|█▊        | 9/50 [01:25<06:17,  9.21s/it] 18%|█▊        | 9/50 [01:34<06:24,  9.37s/it] 18%|█▊        | 9/50 [01:34<06:24,  9.37s/it] 20%|██        | 10/50 [01:34<06:07,  9.19s/it] 20%|██        | 10/50 [01:43<06:12,  9.30s/it] 20%|██        | 10/50 [01:34<06:07,  9.19s/it] 20%|██        | 10/50 [01:43<06:12,  9.30s/it] 22%|██▏       | 11/50 [01:52<06:00,  9.25s/it] 22%|██▏       | 11/50 [01:43<05:57,  9.17s/it] 22%|██▏       | 11/50 [01:43<05:57,  9.18s/it] 22%|██▏       | 11/50 [01:52<06:00,  9.26s/it] 24%|██▍       | 12/50 [02:01<05:50,  9.22s/it] 24%|██▍       | 12/50 [01:52<05:48,  9.17s/it] 24%|██▍       | 12/50 [01:52<05:48,  9.17s/it] 24%|██▍       | 12/50 [02:01<05:50,  9.22s/it] 26%|██▌       | 13/50 [02:11<05:40,  9.20s/it] 26%|██▌       | 13/50 [02:02<05:38,  9.16s/it] 26%|██▌       | 13/50 [02:01<05:38,  9.16s/it] 26%|██▌       | 13/50 [02:11<05:40,  9.20s/it] 28%|██▊       | 14/50 [02:10<05:29,  9.15s/it] 28%|██▊       | 14/50 [02:11<05:29,  9.16s/it] 28%|██▊       | 14/50 [02:20<05:30,  9.18s/it] 28%|██▊       | 14/50 [02:20<05:30,  9.18s/it] 30%|███       | 15/50 [02:20<05:20,  9.15s/it] 30%|███       | 15/50 [02:19<05:20,  9.15s/it] 30%|███       | 15/50 [02:29<05:20,  9.17s/it] 30%|███       | 15/50 [02:29<05:20,  9.17s/it] 32%|███▏      | 16/50 [02:38<05:11,  9.17s/it] 32%|███▏      | 16/50 [02:29<05:11,  9.15s/it] 32%|███▏      | 16/50 [02:29<05:11,  9.15s/it] 32%|███▏      | 16/50 [02:38<05:11,  9.17s/it] 34%|███▍      | 17/50 [02:47<05:02,  9.16s/it] 34%|███▍      | 17/50 [02:38<05:02,  9.15s/it] 34%|███▍      | 17/50 [02:38<05:02,  9.15s/it] 34%|███▍      | 17/50 [02:47<05:02,  9.16s/it] 36%|███▌      | 18/50 [02:56<04:53,  9.16s/it] 36%|███▌      | 18/50 [02:47<04:52,  9.15s/it] 36%|███▌      | 18/50 [02:47<04:52,  9.15s/it] 36%|███▌      | 18/50 [02:56<04:53,  9.16s/it] 38%|███▊      | 19/50 [03:06<04:43,  9.15s/it] 38%|███▊      | 19/50 [02:56<04:43,  9.15s/it] 38%|███▊      | 19/50 [02:56<04:43,  9.15s/it] 38%|███▊      | 19/50 [03:05<04:43,  9.15s/it] 40%|████      | 20/50 [03:06<04:34,  9.15s/it] 40%|████      | 20/50 [03:15<04:34,  9.15s/it] 40%|████      | 20/50 [03:05<04:34,  9.15s/it] 40%|████      | 20/50 [03:15<04:34,  9.15s/it] 42%|████▏     | 21/50 [03:14<04:25,  9.15s/it] 42%|████▏     | 21/50 [03:24<04:25,  9.15s/it] 42%|████▏     | 21/50 [03:15<04:25,  9.15s/it] 42%|████▏     | 21/50 [03:24<04:25,  9.15s/it] 44%|████▍     | 22/50 [03:33<04:16,  9.15s/it] 44%|████▍     | 22/50 [03:23<04:16,  9.15s/it] 44%|████▍     | 22/50 [03:24<04:16,  9.15s/it] 44%|████▍     | 22/50 [03:33<04:16,  9.15s/it] 46%|████▌     | 23/50 [03:42<04:06,  9.14s/it] 46%|████▌     | 23/50 [03:33<04:06,  9.14s/it] 46%|████▌     | 23/50 [03:33<04:06,  9.14s/it] 46%|████▌     | 23/50 [03:42<04:06,  9.15s/it] 48%|████▊     | 24/50 [03:42<03:57,  9.15s/it] 48%|████▊     | 24/50 [03:51<03:57,  9.15s/it] 48%|████▊     | 24/50 [03:42<03:57,  9.15s/it] 48%|████▊     | 24/50 [03:51<03:57,  9.15s/it] 50%|█████     | 25/50 [03:51<03:48,  9.15s/it] 50%|█████     | 25/50 [03:51<03:48,  9.15s/it] 50%|█████     | 25/50 [04:00<03:48,  9.15s/it] 50%|█████     | 25/50 [04:00<03:48,  9.15s/it] 52%|█████▏    | 26/50 [04:10<03:39,  9.16s/it] 52%|█████▏    | 26/50 [04:01<03:39,  9.16s/it] 52%|█████▏    | 26/50 [04:00<03:39,  9.16s/it] 52%|█████▏    | 26/50 [04:10<03:39,  9.16s/it] 54%|█████▍    | 27/50 [04:09<03:30,  9.16s/it] 54%|█████▍    | 27/50 [04:10<03:30,  9.16s/it] 54%|█████▍    | 27/50 [04:19<03:30,  9.16s/it] 54%|█████▍    | 27/50 [04:19<03:30,  9.16s/it] 56%|█████▌    | 28/50 [04:28<03:21,  9.16s/it] 56%|█████▌    | 28/50 [04:19<03:21,  9.16s/it] 56%|█████▌    | 28/50 [04:18<03:21,  9.16s/it] 56%|█████▌    | 28/50 [04:28<03:21,  9.16s/it] 58%|█████▊    | 29/50 [04:37<03:12,  9.16s/it] 58%|█████▊    | 29/50 [04:28<03:12,  9.16s/it] 58%|█████▊    | 29/50 [04:28<03:12,  9.16s/it] 58%|█████▊    | 29/50 [04:37<03:12,  9.16s/it] 60%|██████    | 30/50 [04:37<03:03,  9.16s/it] 60%|██████    | 30/50 [04:37<03:03,  9.16s/it] 60%|██████    | 30/50 [04:46<03:03,  9.16s/it] 60%|██████    | 30/50 [04:46<03:03,  9.16s/it] 62%|██████▏   | 31/50 [04:55<02:54,  9.16s/it] 62%|██████▏   | 31/50 [04:46<02:54,  9.16s/it] 62%|██████▏   | 31/50 [04:46<02:54,  9.16s/it] 62%|██████▏   | 31/50 [04:55<02:54,  9.16s/it] 64%|██████▍   | 32/50 [05:05<02:44,  9.15s/it] 64%|██████▍   | 32/50 [04:55<02:44,  9.15s/it] 64%|██████▍   | 32/50 [04:55<02:44,  9.15s/it] 64%|██████▍   | 32/50 [05:05<02:44,  9.15s/it] 66%|██████▌   | 33/50 [05:05<02:35,  9.15s/it] 66%|██████▌   | 33/50 [05:14<02:35,  9.15s/it] 66%|██████▌   | 33/50 [05:04<02:35,  9.15s/it] 66%|██████▌   | 33/50 [05:14<02:35,  9.15s/it] 68%|██████▊   | 34/50 [05:14<02:26,  9.15s/it] 68%|██████▊   | 34/50 [05:23<02:26,  9.15s/it] 68%|██████▊   | 34/50 [05:13<02:26,  9.15s/it] 68%|██████▊   | 34/50 [05:23<02:26,  9.15s/it] 70%|███████   | 35/50 [05:32<02:17,  9.15s/it] 70%|███████   | 35/50 [05:22<02:17,  9.15s/it] 70%|███████   | 35/50 [05:23<02:17,  9.15s/it] 70%|███████   | 35/50 [05:32<02:17,  9.15s/it] 72%|███████▏  | 36/50 [05:41<02:08,  9.14s/it] 72%|███████▏  | 36/50 [05:32<02:08,  9.14s/it] 72%|███████▏  | 36/50 [05:32<02:08,  9.14s/it] 72%|███████▏  | 36/50 [05:41<02:07,  9.14s/it] 74%|███████▍  | 37/50 [05:41<01:58,  9.14s/it] 74%|███████▍  | 37/50 [05:50<01:58,  9.14s/it] 74%|███████▍  | 37/50 [05:41<01:58,  9.14s/it] 74%|███████▍  | 37/50 [05:50<01:58,  9.14s/it] 76%|███████▌  | 38/50 [05:59<01:49,  9.14s/it] 76%|███████▌  | 38/50 [05:50<01:49,  9.14s/it] 76%|███████▌  | 38/50 [05:50<01:49,  9.14s/it] 76%|███████▌  | 38/50 [05:59<01:49,  9.14s/it] 78%|███████▊  | 39/50 [06:09<01:40,  9.14s/it] 78%|███████▊  | 39/50 [05:59<01:40,  9.14s/it] 78%|███████▊  | 39/50 [05:59<01:40,  9.14s/it] 78%|███████▊  | 39/50 [06:08<01:40,  9.14s/it] 80%|████████  | 40/50 [06:18<01:31,  9.14s/it] 80%|████████  | 40/50 [06:09<01:31,  9.14s/it] 80%|████████  | 40/50 [06:08<01:31,  9.14s/it] 80%|████████  | 40/50 [06:18<01:31,  9.14s/it] 82%|████████▏ | 41/50 [06:18<01:22,  9.14s/it] 82%|████████▏ | 41/50 [06:27<01:22,  9.14s/it] 82%|████████▏ | 41/50 [06:17<01:22,  9.14s/it] 82%|████████▏ | 41/50 [06:27<01:22,  9.14s/it] 84%|████████▍ | 42/50 [06:36<01:13,  9.13s/it] 84%|████████▍ | 42/50 [06:27<01:13,  9.13s/it] 84%|████████▍ | 42/50 [06:26<01:13,  9.13s/it] 84%|████████▍ | 42/50 [06:36<01:13,  9.13s/it] 86%|████████▌ | 43/50 [06:36<01:03,  9.14s/it] 86%|████████▌ | 43/50 [06:45<01:03,  9.14s/it] 86%|████████▌ | 43/50 [06:36<01:03,  9.14s/it] 86%|████████▌ | 43/50 [06:45<01:03,  9.14s/it] 88%|████████▊ | 44/50 [06:54<00:54,  9.13s/it] 88%|████████▊ | 44/50 [06:45<00:54,  9.13s/it] 88%|████████▊ | 44/50 [06:45<00:54,  9.13s/it] 88%|████████▊ | 44/50 [06:54<00:54,  9.13s/it] 90%|█████████ | 45/50 [06:54<00:45,  9.13s/it] 90%|█████████ | 45/50 [07:03<00:45,  9.13s/it] 90%|█████████ | 45/50 [06:54<00:45,  9.13s/it] 90%|█████████ | 45/50 [07:03<00:45,  9.13s/it] 92%|█████████▏| 46/50 [07:03<00:36,  9.13s/it] 92%|█████████▏| 46/50 [07:12<00:36,  9.13s/it] 92%|█████████▏| 46/50 [07:03<00:36,  9.13s/it] 92%|█████████▏| 46/50 [07:12<00:36,  9.14s/it] 94%|█████████▍| 47/50 [07:13<00:27,  9.13s/it] 94%|█████████▍| 47/50 [07:22<00:27,  9.13s/it] 94%|█████████▍| 47/50 [07:12<00:27,  9.13s/it] 94%|█████████▍| 47/50 [07:22<00:27,  9.13s/it] 96%|█████████▌| 48/50 [07:31<00:18,  9.14s/it] 96%|█████████▌| 48/50 [07:21<00:18,  9.14s/it] 96%|█████████▌| 48/50 [07:22<00:18,  9.14s/it] 96%|█████████▌| 48/50 [07:31<00:18,  9.14s/it] 98%|█████████▊| 49/50 [07:40<00:09,  9.14s/it] 98%|█████████▊| 49/50 [07:30<00:09,  9.14s/it] 98%|█████████▊| 49/50 [07:31<00:09,  9.14s/it] 98%|█████████▊| 49/50 [07:40<00:09,  9.14s/it]100%|██████████| 50/50 [07:49<00:00,  9.13s/it]100%|██████████| 50/50 [07:39<00:00,  9.13s/it]100%|██████████| 50/50 [07:49<00:00,  9.39s/it]
代码执行时间: 469.49 秒
100%|██████████| 50/50 [07:39<00:00,  9.20s/it]
代码执行时间: 459.95 秒
100%|██████████| 50/50 [07:40<00:00,  9.13s/it]100%|██████████| 50/50 [07:40<00:00,  9.21s/it]
代码执行时间: 460.44 秒
100%|██████████| 50/50 [07:49<00:00,  9.13s/it]100%|██████████| 50/50 [07:49<00:00,  9.39s/it]
代码执行时间: 469.46 秒
2025-03-07 23:08:20.532 | INFO     | hyvideo.inference:predict:669 - Success, time: 502.808207988739
2025-03-07 23:08:20.751 | INFO     | hyvideo.inference:predict:669 - Success, time: 503.168123960495
2025-03-07 23:08:20.855 | INFO     | hyvideo.inference:predict:669 - Success, time: 494.0770597457886
2025-03-07 23:08:20.874 | INFO     | hyvideo.inference:predict:669 - Success, time: 493.7189235687256
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-07 23:08:24.984 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0307 23:08:29.799000 140057435834176 torch/distributed/run.py:779] 
W0307 23:08:29.799000 140057435834176 torch/distributed/run.py:779] *****************************************
W0307 23:08:29.799000 140057435834176 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0307 23:08:29.799000 140057435834176 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=2, ring_degree=1)
2025-03-07 23:08:37.032 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:08:37 [parallel_state.py:200] world_size=2 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=2, ring_degree=1)
2025-03-07 23:08:37.054 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:08:37 [parallel_state.py:200] world_size=2 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-07 23:08:37.088 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:08:37.091 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:08:37.757 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:08:37.791 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:09:01.591 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:09:02.265 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:09:03.459 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:09:03.581 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 23:09:04.103 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:09:04.226 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.63s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.64s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.64s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.65s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.58s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.22s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.73s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.58s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.75s/it]
2025-03-07 23:09:22.090 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:09:22.663 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:09:24.567 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:09:24.894 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:09:25.047 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:09:25.082 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:09:25.086 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:09:25.153 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 23:09:25.248 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:09:25.413 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:09:25.561 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:09:25.600 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:09:25.666 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 129)
2025-03-07 23:09:25.751 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:20<16:47, 20.56s/it]  2%|▏         | 1/50 [00:19<16:16, 19.93s/it]  4%|▍         | 2/50 [00:37<14:55, 18.66s/it]  4%|▍         | 2/50 [00:38<15:15, 19.08s/it]  6%|▌         | 3/50 [00:55<14:23, 18.37s/it]  6%|▌         | 3/50 [00:56<14:34, 18.60s/it]  8%|▊         | 4/50 [01:13<13:58, 18.23s/it]  8%|▊         | 4/50 [01:14<14:05, 18.37s/it] 10%|█         | 5/50 [01:31<13:36, 18.15s/it] 10%|█         | 5/50 [01:32<13:40, 18.24s/it] 12%|█▏        | 6/50 [01:49<13:16, 18.10s/it] 12%|█▏        | 6/50 [01:50<13:19, 18.16s/it] 14%|█▍        | 7/50 [02:07<12:56, 18.07s/it] 14%|█▍        | 7/50 [02:08<12:58, 18.11s/it] 16%|█▌        | 8/50 [02:25<12:38, 18.05s/it] 16%|█▌        | 8/50 [02:26<12:39, 18.08s/it] 18%|█▊        | 9/50 [02:43<12:19, 18.03s/it] 18%|█▊        | 9/50 [02:44<12:20, 18.05s/it] 20%|██        | 10/50 [03:01<12:00, 18.02s/it] 20%|██        | 10/50 [03:02<12:01, 18.04s/it] 22%|██▏       | 11/50 [03:19<11:42, 18.02s/it] 22%|██▏       | 11/50 [03:20<11:42, 18.03s/it] 24%|██▍       | 12/50 [03:37<11:24, 18.01s/it] 24%|██▍       | 12/50 [03:38<11:24, 18.02s/it] 26%|██▌       | 13/50 [03:55<11:06, 18.01s/it] 26%|██▌       | 13/50 [03:56<11:06, 18.01s/it] 28%|██▊       | 14/50 [04:13<10:48, 18.00s/it] 28%|██▊       | 14/50 [04:14<10:48, 18.01s/it] 30%|███       | 15/50 [04:31<10:30, 18.00s/it] 30%|███       | 15/50 [04:32<10:30, 18.00s/it] 32%|███▏      | 16/50 [04:49<10:11, 18.00s/it] 32%|███▏      | 16/50 [04:50<10:11, 18.00s/it] 34%|███▍      | 17/50 [05:07<09:53, 18.00s/it] 34%|███▍      | 17/50 [05:08<09:53, 18.00s/it] 36%|███▌      | 18/50 [05:25<09:35, 17.99s/it] 36%|███▌      | 18/50 [05:26<09:35, 17.99s/it] 38%|███▊      | 19/50 [05:43<09:17, 17.99s/it] 38%|███▊      | 19/50 [05:44<09:17, 17.99s/it] 40%|████      | 20/50 [06:01<08:59, 17.99s/it] 40%|████      | 20/50 [06:02<08:59, 17.99s/it] 42%|████▏     | 21/50 [06:19<08:41, 17.99s/it] 42%|████▏     | 21/50 [06:20<08:41, 17.99s/it] 44%|████▍     | 22/50 [06:37<08:23, 17.99s/it] 44%|████▍     | 22/50 [06:38<08:23, 17.99s/it] 46%|████▌     | 23/50 [06:55<08:05, 18.00s/it] 46%|████▌     | 23/50 [06:56<08:05, 18.00s/it] 48%|████▊     | 24/50 [07:13<07:47, 18.00s/it] 48%|████▊     | 24/50 [07:14<07:47, 18.00s/it] 50%|█████     | 25/50 [07:31<07:29, 18.00s/it] 50%|█████     | 25/50 [07:32<07:29, 18.00s/it] 52%|█████▏    | 26/50 [07:49<07:11, 17.99s/it] 52%|█████▏    | 26/50 [07:50<07:11, 18.00s/it] 54%|█████▍    | 27/50 [08:07<06:53, 18.00s/it] 54%|█████▍    | 27/50 [08:08<06:53, 18.00s/it] 56%|█████▌    | 28/50 [08:25<06:35, 18.00s/it] 56%|█████▌    | 28/50 [08:26<06:35, 18.00s/it] 58%|█████▊    | 29/50 [08:43<06:17, 18.00s/it] 58%|█████▊    | 29/50 [08:44<06:17, 18.00s/it] 60%|██████    | 30/50 [09:01<05:59, 18.00s/it] 60%|██████    | 30/50 [09:02<05:59, 18.00s/it] 62%|██████▏   | 31/50 [09:19<05:41, 18.00s/it] 62%|██████▏   | 31/50 [09:20<05:41, 18.00s/it] 64%|██████▍   | 32/50 [09:37<05:23, 17.99s/it] 64%|██████▍   | 32/50 [09:38<05:23, 17.99s/it] 66%|██████▌   | 33/50 [09:55<05:05, 17.99s/it] 66%|██████▌   | 33/50 [09:56<05:05, 17.99s/it] 68%|██████▊   | 34/50 [10:13<04:47, 17.99s/it] 68%|██████▊   | 34/50 [10:14<04:47, 17.99s/it] 70%|███████   | 35/50 [10:31<04:29, 17.99s/it] 70%|███████   | 35/50 [10:32<04:29, 17.99s/it] 72%|███████▏  | 36/50 [10:49<04:11, 17.99s/it] 72%|███████▏  | 36/50 [10:50<04:11, 17.99s/it] 74%|███████▍  | 37/50 [11:07<03:53, 17.98s/it] 74%|███████▍  | 37/50 [11:08<03:53, 17.99s/it] 76%|███████▌  | 38/50 [11:25<03:35, 17.99s/it] 76%|███████▌  | 38/50 [11:26<03:35, 17.99s/it] 78%|███████▊  | 39/50 [11:43<03:17, 17.99s/it] 78%|███████▊  | 39/50 [11:44<03:17, 17.99s/it] 80%|████████  | 40/50 [12:01<02:59, 17.99s/it] 80%|████████  | 40/50 [12:02<02:59, 17.99s/it] 82%|████████▏ | 41/50 [12:19<02:41, 17.98s/it] 82%|████████▏ | 41/50 [12:20<02:41, 17.98s/it] 84%|████████▍ | 42/50 [12:37<02:23, 17.98s/it] 84%|████████▍ | 42/50 [12:38<02:23, 17.98s/it] 86%|████████▌ | 43/50 [12:55<02:05, 17.98s/it] 86%|████████▌ | 43/50 [12:56<02:05, 17.99s/it] 88%|████████▊ | 44/50 [13:13<01:47, 17.99s/it] 88%|████████▊ | 44/50 [13:14<01:47, 17.99s/it] 90%|█████████ | 45/50 [13:31<01:29, 17.98s/it] 90%|█████████ | 45/50 [13:32<01:29, 17.98s/it] 92%|█████████▏| 46/50 [13:49<01:11, 17.98s/it] 92%|█████████▏| 46/50 [13:50<01:11, 17.97s/it] 94%|█████████▍| 47/50 [14:07<00:53, 17.97s/it] 94%|█████████▍| 47/50 [14:08<00:53, 17.97s/it] 96%|█████████▌| 48/50 [14:25<00:35, 17.97s/it] 96%|█████████▌| 48/50 [14:26<00:35, 17.97s/it] 98%|█████████▊| 49/50 [14:43<00:17, 17.97s/it] 98%|█████████▊| 49/50 [14:44<00:17, 17.97s/it]100%|██████████| 50/50 [15:01<00:00, 17.97s/it]100%|██████████| 50/50 [15:01<00:00, 18.03s/it]
代码执行时间: 901.29 秒
100%|██████████| 50/50 [15:02<00:00, 17.97s/it]100%|██████████| 50/50 [15:02<00:00, 18.04s/it]
代码执行时间: 902.19 秒
2025-03-07 23:25:01.210 | INFO     | hyvideo.inference:predict:669 - Success, time: 935.9616436958313
2025-03-07 23:25:01.565 | INFO     | hyvideo.inference:predict:669 - Success, time: 935.8131914138794
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-07 23:25:05.580 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0307 23:25:09.945000 139858084910912 torch/distributed/run.py:779] 
W0307 23:25:09.945000 139858084910912 torch/distributed/run.py:779] *****************************************
W0307 23:25:09.945000 139858084910912 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0307 23:25:09.945000 139858084910912 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:25:17.668 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:25:17 [parallel_state.py:200] world_size=8 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:25:18.418 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:25:18 [parallel_state.py:200] world_size=8 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:25:18.441 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:25:18 [parallel_state.py:200] world_size=8 rank=7 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:25:18.520 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:25:18 [parallel_state.py:200] world_size=8 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:25:18.534 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:25:18 [parallel_state.py:200] world_size=8 rank=5 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:25:18.542 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
DEBUG 03-07 23:25:18 [parallel_state.py:200] world_size=8 rank=6 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-07 23:25:18.548 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:25:18.554 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:25:18 [parallel_state.py:200] world_size=8 rank=4 local_rank=-1 distributed_init_method=env:// backend=nccl
DEBUG 03-07 23:25:18 [parallel_state.py:200] world_size=8 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-07 23:25:18.658 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:25:18.659 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:25:18.659 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:25:18.659 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:25:18.660 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:25:18.660 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:25:18.660 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:25:18.660 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:25:21.783 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:25:21.903 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:25:21.926 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:25:21.935 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:25:21.969 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:25:21.996 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:25:22.003 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:25:22.020 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:25:46.097 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:25:46.322 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:25:47.664 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:25:47.940 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:25:48.013 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:25:48.041 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:25:48.052 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 23:25:48.260 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:25:48.398 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:25:48.582 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:25:48.726 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:25:49.951 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:25:50.622 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:25:50.782 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:25:51.025 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:25:51.061 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 23:25:51.194 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:25:51.231 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:25:51.287 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:25:51.412 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:25:51.448 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 23:25:51.571 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.72s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.97s/it]2025-03-07 23:25:52.943 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:25:53.085 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.79s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.24s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.18s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.26s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.97s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.21s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.17s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.06s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.70s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.82s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.91s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.44s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.99s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.63s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.20s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.23s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.21s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.03s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.61s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.31s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.27s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.66s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.37s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:15<00:05,  5.15s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.87s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.78s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.22s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.94s/it]
2025-03-07 23:26:06.926 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:15<00:05,  5.18s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.96s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.59s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  2.83s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.56s/it]
2025-03-07 23:26:09.169 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:26:09.301 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:09.482 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:09.672 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:09.707 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:09.771 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:26:09.816 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:26:12.140 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:26:12.487 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:12.648 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:12.690 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:12.757 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:26:12.794 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:26:13.109 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:26:14.649 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:15.833 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:26:15.882 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:15.885 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:15.912 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:16.211 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:16.398 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:16.447 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:16.520 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:26:16.566 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:26:16.684 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:26:17.701 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:26:18.052 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:18.224 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:18.271 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:18.347 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:26:18.397 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:26:18.601 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:26:18.925 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:19.090 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:19.099 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:26:19.119 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:26:19.125 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:19.189 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:26:19.222 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:26:19.464 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:19.474 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:19.616 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:19.616 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:19.676 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:19.681 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:26:19.750 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:26:19.753 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:26:19.786 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:26:19.800 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:26:19.960 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:26:20.295 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:26:20.448 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:26:20.487 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:26:20.555 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:26:20.591 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:10<08:14, 10.09s/it]  2%|▏         | 1/50 [00:19<15:47, 19.34s/it]  2%|▏         | 1/50 [00:08<07:03,  8.65s/it]  2%|▏         | 1/50 [00:10<08:41, 10.64s/it]  2%|▏         | 1/50 [00:16<13:21, 16.36s/it]  2%|▏         | 1/50 [00:12<10:08, 12.42s/it]  2%|▏         | 1/50 [00:09<07:47,  9.55s/it]  2%|▏         | 1/50 [00:09<07:28,  9.15s/it]  4%|▍         | 2/50 [00:11<04:07,  5.15s/it]  4%|▍         | 2/50 [00:11<03:55,  4.90s/it]  4%|▍         | 2/50 [00:12<04:17,  5.37s/it]  4%|▍         | 2/50 [00:21<07:09,  8.96s/it]  4%|▍         | 2/50 [00:14<04:53,  6.11s/it]  4%|▍         | 2/50 [00:18<06:10,  7.73s/it]  4%|▍         | 2/50 [00:10<03:38,  4.55s/it]  4%|▍         | 2/50 [00:10<03:47,  4.75s/it]  6%|▌         | 3/50 [00:13<02:46,  3.55s/it]  6%|▌         | 3/50 [00:12<02:40,  3.42s/it]  6%|▌         | 3/50 [00:13<02:52,  3.67s/it]  6%|▌         | 3/50 [00:22<04:24,  5.62s/it]  6%|▌         | 3/50 [00:11<02:31,  3.23s/it]  6%|▌         | 3/50 [00:15<03:11,  4.07s/it]  6%|▌         | 3/50 [00:19<03:52,  4.95s/it]  6%|▌         | 3/50 [00:12<02:36,  3.33s/it]  8%|▊         | 4/50 [00:15<02:08,  2.80s/it]  8%|▊         | 4/50 [00:15<02:12,  2.87s/it]  8%|▊         | 4/50 [00:14<02:05,  2.72s/it]  8%|▊         | 4/50 [00:24<03:06,  4.05s/it]  8%|▊         | 4/50 [00:21<02:47,  3.65s/it]  8%|▊         | 4/50 [00:17<02:23,  3.12s/it]  8%|▊         | 4/50 [00:13<01:59,  2.60s/it]  8%|▊         | 4/50 [00:14<02:02,  2.67s/it] 10%|█         | 5/50 [00:16<01:47,  2.38s/it] 10%|█         | 5/50 [00:16<01:44,  2.33s/it] 10%|█         | 5/50 [00:17<01:49,  2.43s/it] 10%|█         | 5/50 [00:25<02:23,  3.19s/it] 10%|█         | 5/50 [00:22<02:11,  2.93s/it] 10%|█         | 5/50 [00:19<01:56,  2.59s/it] 10%|█         | 5/50 [00:15<01:41,  2.26s/it] 10%|█         | 5/50 [00:15<01:43,  2.30s/it] 12%|█▏        | 6/50 [00:18<01:33,  2.13s/it] 12%|█▏        | 6/50 [00:18<01:35,  2.16s/it] 12%|█▏        | 6/50 [00:27<01:57,  2.66s/it] 12%|█▏        | 6/50 [00:17<01:32,  2.10s/it] 12%|█▏        | 6/50 [00:20<01:39,  2.27s/it] 12%|█▏        | 6/50 [00:24<01:49,  2.49s/it] 12%|█▏        | 6/50 [00:16<01:30,  2.05s/it] 12%|█▏        | 6/50 [00:17<01:31,  2.08s/it] 14%|█▍        | 7/50 [00:20<01:25,  1.98s/it] 14%|█▍        | 7/50 [00:29<01:40,  2.33s/it] 14%|█▍        | 7/50 [00:19<01:24,  1.95s/it] 14%|█▍        | 7/50 [00:20<01:25,  2.00s/it] 14%|█▍        | 7/50 [00:22<01:28,  2.07s/it] 14%|█▍        | 7/50 [00:26<01:35,  2.22s/it] 14%|█▍        | 7/50 [00:18<01:22,  1.92s/it] 14%|█▍        | 7/50 [00:19<01:23,  1.94s/it] 16%|█▌        | 8/50 [00:21<01:18,  1.87s/it] 16%|█▌        | 8/50 [00:21<01:17,  1.86s/it] 16%|█▌        | 8/50 [00:30<01:28,  2.11s/it] 16%|█▌        | 8/50 [00:22<01:19,  1.89s/it] 16%|█▌        | 8/50 [00:27<01:25,  2.04s/it] 16%|█▌        | 8/50 [00:20<01:16,  1.83s/it] 16%|█▌        | 8/50 [00:24<01:21,  1.93s/it] 16%|█▌        | 8/50 [00:20<01:17,  1.85s/it] 18%|█▊        | 9/50 [00:23<01:13,  1.80s/it] 18%|█▊        | 9/50 [00:22<01:13,  1.79s/it] 18%|█▊        | 9/50 [00:23<01:14,  1.81s/it] 18%|█▊        | 9/50 [00:32<01:20,  1.97s/it] 18%|█▊        | 9/50 [00:25<01:15,  1.84s/it] 18%|█▊        | 9/50 [00:29<01:18,  1.91s/it] 18%|█▊        | 9/50 [00:21<01:12,  1.78s/it] 18%|█▊        | 9/50 [00:22<01:13,  1.78s/it] 20%|██        | 10/50 [00:24<01:10,  1.75s/it] 20%|██        | 10/50 [00:34<01:14,  1.87s/it] 20%|██        | 10/50 [00:24<01:09,  1.75s/it] 20%|██        | 10/50 [00:25<01:10,  1.76s/it] 20%|██        | 10/50 [00:31<01:13,  1.83s/it] 20%|██        | 10/50 [00:23<01:09,  1.74s/it] 20%|██        | 10/50 [00:27<01:11,  1.78s/it] 20%|██        | 10/50 [00:24<01:09,  1.74s/it] 22%|██▏       | 11/50 [00:26<01:07,  1.72s/it] 22%|██▏       | 11/50 [00:26<01:06,  1.72s/it] 22%|██▏       | 11/50 [00:35<01:10,  1.80s/it] 22%|██▏       | 11/50 [00:27<01:07,  1.73s/it] 22%|██▏       | 11/50 [00:28<01:07,  1.74s/it] 22%|██▏       | 11/50 [00:32<01:09,  1.78s/it] 22%|██▏       | 11/50 [00:25<01:06,  1.71s/it] 22%|██▏       | 11/50 [00:25<01:06,  1.71s/it] 24%|██▍       | 12/50 [00:28<01:04,  1.70s/it] 24%|██▍       | 12/50 [00:27<01:04,  1.70s/it] 24%|██▍       | 12/50 [00:37<01:06,  1.75s/it] 24%|██▍       | 12/50 [00:28<01:04,  1.70s/it] 24%|██▍       | 12/50 [00:26<01:04,  1.69s/it] 24%|██▍       | 12/50 [00:34<01:06,  1.74s/it] 24%|██▍       | 12/50 [00:30<01:05,  1.71s/it] 24%|██▍       | 12/50 [00:27<01:04,  1.69s/it] 26%|██▌       | 13/50 [00:39<01:03,  1.72s/it] 26%|██▌       | 13/50 [00:29<01:02,  1.68s/it] 26%|██▌       | 13/50 [00:28<01:02,  1.68s/it] 26%|██▌       | 13/50 [00:29<01:02,  1.68s/it] 26%|██▌       | 13/50 [00:30<01:02,  1.69s/it] 26%|██▌       | 13/50 [00:32<01:02,  1.69s/it] 26%|██▌       | 13/50 [00:36<01:03,  1.71s/it] 26%|██▌       | 13/50 [00:28<01:02,  1.68s/it] 28%|██▊       | 14/50 [00:31<01:00,  1.67s/it] 28%|██▊       | 14/50 [00:32<01:00,  1.67s/it] 28%|██▊       | 14/50 [00:40<01:01,  1.70s/it] 28%|██▊       | 14/50 [00:30<01:00,  1.67s/it] 28%|██▊       | 14/50 [00:30<01:00,  1.67s/it] 28%|██▊       | 14/50 [00:33<01:00,  1.68s/it] 28%|██▊       | 14/50 [00:37<01:00,  1.69s/it] 28%|██▊       | 14/50 [00:30<01:00,  1.67s/it] 30%|███       | 15/50 [00:33<00:58,  1.66s/it] 30%|███       | 15/50 [00:33<00:58,  1.66s/it] 30%|███       | 15/50 [00:42<00:58,  1.68s/it] 30%|███       | 15/50 [00:31<00:58,  1.66s/it] 30%|███       | 15/50 [00:32<00:58,  1.66s/it] 30%|███       | 15/50 [00:35<00:58,  1.67s/it] 30%|███       | 15/50 [00:39<00:58,  1.68s/it] 30%|███       | 15/50 [00:32<00:58,  1.66s/it] 32%|███▏      | 16/50 [00:44<00:56,  1.67s/it] 32%|███▏      | 16/50 [00:34<00:56,  1.66s/it] 32%|███▏      | 16/50 [00:34<00:56,  1.66s/it] 32%|███▏      | 16/50 [00:35<00:56,  1.66s/it] 32%|███▏      | 16/50 [00:41<00:56,  1.67s/it] 32%|███▏      | 16/50 [00:33<00:56,  1.66s/it] 32%|███▏      | 16/50 [00:37<00:56,  1.66s/it] 32%|███▏      | 16/50 [00:33<00:56,  1.66s/it] 34%|███▍      | 17/50 [00:36<00:54,  1.65s/it] 34%|███▍      | 17/50 [00:45<00:54,  1.66s/it] 34%|███▍      | 17/50 [00:35<00:54,  1.65s/it] 34%|███▍      | 17/50 [00:42<00:54,  1.66s/it] 34%|███▍      | 17/50 [00:37<00:54,  1.65s/it] 34%|███▍      | 17/50 [00:35<00:54,  1.65s/it] 34%|███▍      | 17/50 [00:38<00:54,  1.66s/it] 34%|███▍      | 17/50 [00:35<00:54,  1.65s/it] 36%|███▌      | 18/50 [00:47<00:53,  1.66s/it] 36%|███▌      | 18/50 [00:38<00:52,  1.65s/it] 36%|███▌      | 18/50 [00:37<00:52,  1.65s/it] 36%|███▌      | 18/50 [00:38<00:52,  1.65s/it] 36%|███▌      | 18/50 [00:44<00:52,  1.65s/it] 36%|███▌      | 18/50 [00:36<00:52,  1.65s/it] 36%|███▌      | 18/50 [00:40<00:52,  1.65s/it] 36%|███▌      | 18/50 [00:37<00:52,  1.65s/it] 38%|███▊      | 19/50 [00:39<00:51,  1.65s/it] 38%|███▊      | 19/50 [00:49<00:51,  1.65s/it] 38%|███▊      | 19/50 [00:38<00:51,  1.65s/it] 38%|███▊      | 19/50 [00:46<00:51,  1.65s/it] 38%|███▊      | 19/50 [00:39<00:51,  1.65s/it] 38%|███▊      | 19/50 [00:42<00:51,  1.65s/it] 38%|███▊      | 19/50 [00:40<00:51,  1.65s/it] 38%|███▊      | 19/50 [00:38<00:51,  1.65s/it] 40%|████      | 20/50 [00:41<00:49,  1.65s/it] 40%|████      | 20/50 [00:50<00:49,  1.65s/it] 40%|████      | 20/50 [00:41<00:49,  1.65s/it] 40%|████      | 20/50 [00:40<00:49,  1.65s/it] 40%|████      | 20/50 [00:47<00:49,  1.65s/it] 40%|████      | 20/50 [00:39<00:49,  1.65s/it] 40%|████      | 20/50 [00:43<00:49,  1.65s/it] 40%|████      | 20/50 [00:40<00:49,  1.65s/it] 42%|████▏     | 21/50 [00:43<00:47,  1.65s/it] 42%|████▏     | 21/50 [00:42<00:47,  1.65s/it] 42%|████▏     | 21/50 [00:43<00:47,  1.65s/it] 42%|████▏     | 21/50 [00:52<00:47,  1.65s/it] 42%|████▏     | 21/50 [00:41<00:47,  1.64s/it] 42%|████▏     | 21/50 [00:49<00:47,  1.65s/it] 42%|████▏     | 21/50 [00:45<00:47,  1.65s/it] 42%|████▏     | 21/50 [00:42<00:47,  1.64s/it] 44%|████▍     | 22/50 [00:44<00:46,  1.64s/it] 44%|████▍     | 22/50 [00:44<00:45,  1.64s/it] 44%|████▍     | 22/50 [00:53<00:46,  1.64s/it] 44%|████▍     | 22/50 [00:50<00:46,  1.64s/it] 44%|████▍     | 22/50 [00:43<00:45,  1.64s/it] 44%|████▍     | 22/50 [00:45<00:46,  1.64s/it] 44%|████▍     | 22/50 [00:47<00:46,  1.64s/it] 44%|████▍     | 22/50 [00:43<00:45,  1.64s/it] 46%|████▌     | 23/50 [00:46<00:44,  1.64s/it] 46%|████▌     | 23/50 [00:55<00:44,  1.64s/it] 46%|████▌     | 23/50 [00:45<00:44,  1.64s/it] 46%|████▌     | 23/50 [00:52<00:44,  1.64s/it] 46%|████▌     | 23/50 [00:44<00:44,  1.64s/it] 46%|████▌     | 23/50 [00:46<00:44,  1.64s/it] 46%|████▌     | 23/50 [00:48<00:44,  1.64s/it] 46%|████▌     | 23/50 [00:45<00:44,  1.64s/it] 48%|████▊     | 24/50 [00:47<00:42,  1.64s/it] 48%|████▊     | 24/50 [00:47<00:42,  1.64s/it] 48%|████▊     | 24/50 [00:57<00:42,  1.64s/it] 48%|████▊     | 24/50 [00:48<00:42,  1.64s/it] 48%|████▊     | 24/50 [00:50<00:42,  1.64s/it] 48%|████▊     | 24/50 [00:54<00:42,  1.64s/it] 48%|████▊     | 24/50 [00:46<00:42,  1.64s/it] 48%|████▊     | 24/50 [00:47<00:42,  1.64s/it] 50%|█████     | 25/50 [00:49<00:41,  1.64s/it] 50%|█████     | 25/50 [00:50<00:41,  1.64s/it] 50%|█████     | 25/50 [00:58<00:41,  1.64s/it] 50%|█████     | 25/50 [00:49<00:41,  1.64s/it] 50%|█████     | 25/50 [00:55<00:41,  1.64s/it] 50%|█████     | 25/50 [00:48<00:41,  1.64s/it] 50%|█████     | 25/50 [00:51<00:41,  1.64s/it] 50%|█████     | 25/50 [00:48<00:41,  1.64s/it] 52%|█████▏    | 26/50 [00:51<00:39,  1.64s/it] 52%|█████▏    | 26/50 [00:51<00:39,  1.64s/it] 52%|█████▏    | 26/50 [00:50<00:39,  1.64s/it] 52%|█████▏    | 26/50 [00:53<00:39,  1.64s/it] 52%|█████▏    | 26/50 [00:49<00:39,  1.64s/it] 52%|█████▏    | 26/50 [00:57<00:39,  1.64s/it] 52%|█████▏    | 26/50 [01:00<00:39,  1.64s/it] 52%|█████▏    | 26/50 [00:50<00:39,  1.64s/it] 54%|█████▍    | 27/50 [01:02<00:37,  1.64s/it] 54%|█████▍    | 27/50 [00:52<00:37,  1.64s/it] 54%|█████▍    | 27/50 [00:55<00:37,  1.64s/it] 54%|█████▍    | 27/50 [00:53<00:37,  1.64s/it] 54%|█████▍    | 27/50 [00:51<00:37,  1.64s/it] 54%|█████▍    | 27/50 [00:59<00:37,  1.64s/it] 54%|█████▍    | 27/50 [00:52<00:37,  1.64s/it] 54%|█████▍    | 27/50 [00:51<00:37,  1.64s/it] 56%|█████▌    | 28/50 [00:54<00:36,  1.64s/it] 56%|█████▌    | 28/50 [01:03<00:36,  1.64s/it] 56%|█████▌    | 28/50 [00:55<00:36,  1.64s/it] 56%|█████▌    | 28/50 [00:53<00:36,  1.64s/it] 56%|█████▌    | 28/50 [00:56<00:36,  1.64s/it] 56%|█████▌    | 28/50 [00:53<00:36,  1.64s/it] 56%|█████▌    | 28/50 [01:00<00:36,  1.64s/it] 56%|█████▌    | 28/50 [00:53<00:36,  1.64s/it] 58%|█████▊    | 29/50 [00:56<00:34,  1.64s/it] 58%|█████▊    | 29/50 [01:05<00:34,  1.64s/it] 58%|█████▊    | 29/50 [00:55<00:34,  1.64s/it] 58%|█████▊    | 29/50 [00:58<00:34,  1.64s/it] 58%|█████▊    | 29/50 [01:02<00:34,  1.64s/it] 58%|█████▊    | 29/50 [00:54<00:34,  1.64s/it] 58%|█████▊    | 29/50 [00:56<00:34,  1.64s/it] 58%|█████▊    | 29/50 [00:55<00:34,  1.64s/it] 60%|██████    | 30/50 [00:57<00:32,  1.64s/it] 60%|██████    | 30/50 [01:07<00:32,  1.64s/it] 60%|██████    | 30/50 [00:57<00:32,  1.64s/it] 60%|██████    | 30/50 [01:00<00:32,  1.64s/it] 60%|██████    | 30/50 [00:58<00:32,  1.64s/it] 60%|██████    | 30/50 [00:56<00:32,  1.64s/it] 60%|██████    | 30/50 [01:04<00:32,  1.64s/it] 60%|██████    | 30/50 [00:56<00:32,  1.64s/it] 62%|██████▏   | 31/50 [00:59<00:31,  1.64s/it] 62%|██████▏   | 31/50 [01:08<00:31,  1.64s/it] 62%|██████▏   | 31/50 [00:58<00:31,  1.64s/it] 62%|██████▏   | 31/50 [01:00<00:31,  1.64s/it] 62%|██████▏   | 31/50 [00:58<00:31,  1.64s/it] 62%|██████▏   | 31/50 [01:01<00:31,  1.64s/it] 62%|██████▏   | 31/50 [01:05<00:31,  1.64s/it] 62%|██████▏   | 31/50 [00:58<00:31,  1.64s/it] 64%|██████▍   | 32/50 [01:01<00:29,  1.64s/it] 64%|██████▍   | 32/50 [01:10<00:29,  1.64s/it] 64%|██████▍   | 32/50 [01:07<00:29,  1.64s/it] 64%|██████▍   | 32/50 [01:01<00:29,  1.64s/it] 64%|██████▍   | 32/50 [01:03<00:29,  1.64s/it] 64%|██████▍   | 32/50 [01:00<00:29,  1.64s/it] 64%|██████▍   | 32/50 [00:59<00:29,  1.64s/it] 64%|██████▍   | 32/50 [01:00<00:29,  1.64s/it] 66%|██████▌   | 33/50 [01:12<00:27,  1.64s/it] 66%|██████▌   | 33/50 [01:02<00:27,  1.64s/it] 66%|██████▌   | 33/50 [01:05<00:27,  1.64s/it] 66%|██████▌   | 33/50 [01:03<00:27,  1.64s/it] 66%|██████▌   | 33/50 [01:01<00:27,  1.64s/it] 66%|██████▌   | 33/50 [01:09<00:27,  1.64s/it] 66%|██████▌   | 33/50 [01:02<00:27,  1.64s/it] 66%|██████▌   | 33/50 [01:01<00:27,  1.64s/it] 68%|██████▊   | 34/50 [01:04<00:26,  1.64s/it] 68%|██████▊   | 34/50 [01:13<00:26,  1.64s/it] 68%|██████▊   | 34/50 [01:06<00:26,  1.64s/it] 68%|██████▊   | 34/50 [01:10<00:26,  1.64s/it] 68%|██████▊   | 34/50 [01:03<00:26,  1.64s/it] 68%|██████▊   | 34/50 [01:02<00:26,  1.64s/it] 68%|██████▊   | 34/50 [01:04<00:26,  1.64s/it] 68%|██████▊   | 34/50 [01:03<00:26,  1.64s/it] 70%|███████   | 35/50 [01:06<00:24,  1.64s/it] 70%|███████   | 35/50 [01:05<00:24,  1.64s/it] 70%|███████   | 35/50 [01:15<00:24,  1.64s/it] 70%|███████   | 35/50 [01:08<00:24,  1.64s/it] 70%|███████   | 35/50 [01:12<00:24,  1.64s/it] 70%|███████   | 35/50 [01:04<00:24,  1.64s/it] 70%|███████   | 35/50 [01:06<00:24,  1.64s/it] 70%|███████   | 35/50 [01:05<00:24,  1.64s/it] 72%|███████▏  | 36/50 [01:07<00:22,  1.64s/it] 72%|███████▏  | 36/50 [01:16<00:22,  1.64s/it] 72%|███████▏  | 36/50 [01:07<00:22,  1.64s/it] 72%|███████▏  | 36/50 [01:10<00:22,  1.64s/it] 72%|███████▏  | 36/50 [01:08<00:22,  1.64s/it] 72%|███████▏  | 36/50 [01:06<00:22,  1.64s/it] 72%|███████▏  | 36/50 [01:13<00:22,  1.64s/it] 72%|███████▏  | 36/50 [01:06<00:22,  1.64s/it] 74%|███████▍  | 37/50 [01:09<00:21,  1.64s/it] 74%|███████▍  | 37/50 [01:08<00:21,  1.64s/it] 74%|███████▍  | 37/50 [01:11<00:21,  1.64s/it] 74%|███████▍  | 37/50 [01:18<00:21,  1.64s/it] 74%|███████▍  | 37/50 [01:09<00:21,  1.64s/it] 74%|███████▍  | 37/50 [01:07<00:21,  1.64s/it] 74%|███████▍  | 37/50 [01:15<00:21,  1.64s/it] 74%|███████▍  | 37/50 [01:08<00:21,  1.64s/it] 76%|███████▌  | 38/50 [01:10<00:19,  1.64s/it] 76%|███████▌  | 38/50 [01:20<00:19,  1.64s/it] 76%|███████▌  | 38/50 [01:10<00:19,  1.64s/it] 76%|███████▌  | 38/50 [01:11<00:19,  1.64s/it] 76%|███████▌  | 38/50 [01:09<00:19,  1.64s/it] 76%|███████▌  | 38/50 [01:17<00:19,  1.64s/it] 76%|███████▌  | 38/50 [01:13<00:19,  1.64s/it] 76%|███████▌  | 38/50 [01:10<00:19,  1.64s/it] 78%|███████▊  | 39/50 [01:12<00:18,  1.64s/it] 78%|███████▊  | 39/50 [01:21<00:18,  1.64s/it] 78%|███████▊  | 39/50 [01:13<00:18,  1.64s/it] 78%|███████▊  | 39/50 [01:18<00:18,  1.64s/it] 78%|███████▊  | 39/50 [01:14<00:18,  1.64s/it] 78%|███████▊  | 39/50 [01:11<00:18,  1.64s/it] 78%|███████▊  | 39/50 [01:12<00:18,  1.64s/it] 78%|███████▊  | 39/50 [01:11<00:18,  1.64s/it] 80%|████████  | 40/50 [01:14<00:16,  1.64s/it] 80%|████████  | 40/50 [01:23<00:16,  1.64s/it] 80%|████████  | 40/50 [01:14<00:16,  1.64s/it] 80%|████████  | 40/50 [01:20<00:16,  1.64s/it] 80%|████████  | 40/50 [01:16<00:16,  1.64s/it] 80%|████████  | 40/50 [01:13<00:16,  1.64s/it] 80%|████████  | 40/50 [01:12<00:16,  1.64s/it] 80%|████████  | 40/50 [01:13<00:16,  1.64s/it] 82%|████████▏ | 41/50 [01:15<00:14,  1.64s/it] 82%|████████▏ | 41/50 [01:15<00:14,  1.64s/it] 82%|████████▏ | 41/50 [01:16<00:14,  1.64s/it] 82%|████████▏ | 41/50 [01:14<00:14,  1.64s/it] 82%|████████▏ | 41/50 [01:25<00:14,  1.64s/it] 82%|████████▏ | 41/50 [01:22<00:14,  1.64s/it] 82%|████████▏ | 41/50 [01:18<00:14,  1.64s/it] 82%|████████▏ | 41/50 [01:14<00:14,  1.64s/it] 84%|████████▍ | 42/50 [01:26<00:13,  1.64s/it] 84%|████████▍ | 42/50 [01:16<00:13,  1.64s/it] 84%|████████▍ | 42/50 [01:19<00:13,  1.64s/it] 84%|████████▍ | 42/50 [01:16<00:13,  1.64s/it] 84%|████████▍ | 42/50 [01:23<00:13,  1.64s/it] 84%|████████▍ | 42/50 [01:18<00:13,  1.64s/it] 84%|████████▍ | 42/50 [01:17<00:13,  1.64s/it] 84%|████████▍ | 42/50 [01:16<00:13,  1.64s/it] 86%|████████▌ | 43/50 [01:19<00:11,  1.64s/it] 86%|████████▌ | 43/50 [01:28<00:11,  1.64s/it] 86%|████████▌ | 43/50 [01:18<00:11,  1.64s/it] 86%|████████▌ | 43/50 [01:25<00:11,  1.64s/it] 86%|████████▌ | 43/50 [01:17<00:11,  1.64s/it] 86%|████████▌ | 43/50 [01:21<00:11,  1.64s/it] 86%|████████▌ | 43/50 [01:19<00:11,  1.64s/it] 86%|████████▌ | 43/50 [01:18<00:11,  1.64s/it] 88%|████████▊ | 44/50 [01:20<00:09,  1.64s/it] 88%|████████▊ | 44/50 [01:20<00:09,  1.64s/it] 88%|████████▊ | 44/50 [01:30<00:09,  1.64s/it] 88%|████████▊ | 44/50 [01:23<00:09,  1.64s/it] 88%|████████▊ | 44/50 [01:19<00:09,  1.64s/it] 88%|████████▊ | 44/50 [01:27<00:09,  1.64s/it] 88%|████████▊ | 44/50 [01:21<00:09,  1.64s/it] 88%|████████▊ | 44/50 [01:19<00:09,  1.64s/it] 90%|█████████ | 45/50 [01:22<00:08,  1.64s/it] 90%|█████████ | 45/50 [01:31<00:08,  1.64s/it] 90%|█████████ | 45/50 [01:28<00:08,  1.64s/it] 90%|█████████ | 45/50 [01:23<00:08,  1.64s/it] 90%|█████████ | 45/50 [01:21<00:08,  1.64s/it] 90%|█████████ | 45/50 [01:24<00:08,  1.64s/it] 90%|█████████ | 45/50 [01:21<00:08,  1.64s/it] 90%|█████████ | 45/50 [01:21<00:08,  1.64s/it] 92%|█████████▏| 46/50 [01:24<00:06,  1.64s/it] 92%|█████████▏| 46/50 [01:33<00:06,  1.64s/it] 92%|█████████▏| 46/50 [01:24<00:06,  1.64s/it] 92%|█████████▏| 46/50 [01:30<00:06,  1.64s/it] 92%|█████████▏| 46/50 [01:22<00:06,  1.64s/it] 92%|█████████▏| 46/50 [01:23<00:06,  1.64s/it] 92%|█████████▏| 46/50 [01:26<00:06,  1.64s/it] 92%|█████████▏| 46/50 [01:23<00:06,  1.64s/it] 94%|█████████▍| 47/50 [01:25<00:04,  1.64s/it] 94%|█████████▍| 47/50 [01:35<00:04,  1.64s/it] 94%|█████████▍| 47/50 [01:24<00:04,  1.64s/it] 94%|█████████▍| 47/50 [01:25<00:04,  1.64s/it] 94%|█████████▍| 47/50 [01:28<00:04,  1.64s/it] 94%|█████████▍| 47/50 [01:32<00:04,  1.64s/it] 94%|█████████▍| 47/50 [01:26<00:04,  1.64s/it] 94%|█████████▍| 47/50 [01:24<00:04,  1.64s/it] 96%|█████████▌| 48/50 [01:27<00:03,  1.64s/it] 96%|█████████▌| 48/50 [01:36<00:03,  1.64s/it] 96%|█████████▌| 48/50 [01:29<00:03,  1.64s/it] 96%|█████████▌| 48/50 [01:33<00:03,  1.64s/it] 96%|█████████▌| 48/50 [01:26<00:03,  1.64s/it] 96%|█████████▌| 48/50 [01:25<00:03,  1.64s/it] 96%|█████████▌| 48/50 [01:27<00:03,  1.64s/it] 96%|█████████▌| 48/50 [01:26<00:03,  1.64s/it] 98%|█████████▊| 49/50 [01:29<00:01,  1.64s/it] 98%|█████████▊| 49/50 [01:38<00:01,  1.64s/it] 98%|█████████▊| 49/50 [01:35<00:01,  1.64s/it] 98%|█████████▊| 49/50 [01:31<00:01,  1.64s/it] 98%|█████████▊| 49/50 [01:29<00:01,  1.64s/it] 98%|█████████▊| 49/50 [01:28<00:01,  1.64s/it] 98%|█████████▊| 49/50 [01:27<00:01,  1.64s/it] 98%|█████████▊| 49/50 [01:28<00:01,  1.64s/it]100%|██████████| 50/50 [01:39<00:00,  1.64s/it]100%|██████████| 50/50 [01:30<00:00,  1.64s/it]100%|██████████| 50/50 [01:39<00:00,  2.00s/it]
代码执行时间: 99.95 秒
100%|██████████| 50/50 [01:30<00:00,  1.81s/it]
100%|██████████| 50/50 [01:30<00:00,  1.64s/it]代码执行时间: 90.71 秒
100%|██████████| 50/50 [01:33<00:00,  1.64s/it]100%|██████████| 50/50 [01:36<00:00,  1.64s/it]100%|██████████| 50/50 [01:29<00:00,  1.64s/it]100%|██████████| 50/50 [01:30<00:00,  1.80s/it]
100%|██████████| 50/50 [01:36<00:00,  1.94s/it]100%|██████████| 50/50 [01:33<00:00,  1.86s/it]代码执行时间: 90.11 秒


100%|██████████| 50/50 [01:31<00:00,  1.64s/it]代码执行时间: 96.96 秒代码执行时间: 93.03 秒

100%|██████████| 50/50 [01:29<00:00,  1.79s/it]
代码执行时间: 89.26 秒
100%|██████████| 50/50 [01:31<00:00,  1.82s/it]
代码执行时间: 91.24 秒
100%|██████████| 50/50 [01:29<00:00,  1.64s/it]100%|██████████| 50/50 [01:29<00:00,  1.79s/it]
代码执行时间: 89.74 秒
2025-03-07 23:28:07.650 | INFO     | hyvideo.inference:predict:669 - Success, time: 111.08382940292358
2025-03-07 23:28:07.708 | INFO     | hyvideo.inference:predict:669 - Success, time: 107.92158460617065
2025-03-07 23:28:07.738 | INFO     | hyvideo.inference:predict:669 - Success, time: 108.51574230194092
2025-03-07 23:28:07.817 | INFO     | hyvideo.inference:predict:669 - Success, time: 107.22595453262329
2025-03-07 23:28:07.840 | INFO     | hyvideo.inference:predict:669 - Success, time: 108.0395655632019
2025-03-07 23:28:07.845 | INFO     | hyvideo.inference:predict:669 - Success, time: 115.05046796798706
2025-03-07 23:28:07.921 | INFO     | hyvideo.inference:predict:669 - Success, time: 109.52474188804626
2025-03-07 23:28:08.026 | INFO     | hyvideo.inference:predict:669 - Success, time: 118.21019434928894
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-07 23:28:10.742 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0307 23:28:15.158000 140712896386880 torch/distributed/run.py:779] 
W0307 23:28:15.158000 140712896386880 torch/distributed/run.py:779] *****************************************
W0307 23:28:15.158000 140712896386880 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0307 23:28:15.158000 140712896386880 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 23:28:22.044 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:28:22 [parallel_state.py:200] world_size=4 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 23:28:22.047 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:28:22 [parallel_state.py:200] world_size=4 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 23:28:22.059 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:28:22 [parallel_state.py:200] world_size=4 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 23:28:22.063 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:28:22 [parallel_state.py:200] world_size=4 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-07 23:28:22.100 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:28:22.104 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:28:22.104 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:28:22.105 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:28:23.409 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:28:23.423 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:28:23.462 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:28:23.469 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:28:50.140 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:28:50.141 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:28:50.204 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:28:50.205 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:28:53.050 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:28:53.140 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:28:53.144 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:28:53.147 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:28:53.160 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:28:53.292 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:28:53.297 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:28:53.297 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.68s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.38s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.53s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.84s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.73s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.01s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.04s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.68s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.81s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.82s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.81s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.39s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.98s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.38s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.99s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:03,  3.93s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.45s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.09s/it]
2025-03-07 23:29:12.181 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:29:13.127 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:29:13.153 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:29:13.633 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:29:14.885 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:29:15.247 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:29:15.416 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:29:15.463 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:29:15.534 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:29:15.572 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:29:16.025 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:29:16.067 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:29:16.363 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:29:16.485 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:29:16.522 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:29:16.550 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:29:16.564 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:29:16.632 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:29:16.648 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:29:16.668 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:29:16.689 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:29:16.760 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:29:16.797 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:29:16.955 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:29:17.108 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:29:17.204 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:29:17.353 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:29:17.401 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:06<05:32,  6.79s/it]  2%|▏         | 1/50 [00:08<06:52,  8.42s/it]  2%|▏         | 1/50 [00:06<05:10,  6.33s/it]  2%|▏         | 1/50 [00:07<05:57,  7.30s/it]  4%|▍         | 2/50 [00:10<03:45,  4.69s/it]  4%|▍         | 2/50 [00:09<03:35,  4.49s/it]  4%|▍         | 2/50 [00:10<03:54,  4.88s/it]  4%|▍         | 2/50 [00:11<04:18,  5.38s/it]  6%|▌         | 3/50 [00:13<03:08,  4.01s/it]  6%|▌         | 3/50 [00:12<03:03,  3.90s/it]  6%|▌         | 3/50 [00:13<03:13,  4.12s/it]  6%|▌         | 3/50 [00:14<03:26,  4.39s/it]  8%|▊         | 4/50 [00:16<02:50,  3.70s/it]  8%|▊         | 4/50 [00:15<02:47,  3.63s/it]  8%|▊         | 4/50 [00:16<02:53,  3.76s/it]  8%|▊         | 4/50 [00:18<03:00,  3.93s/it] 10%|█         | 5/50 [00:20<02:40,  3.57s/it] 10%|█         | 5/50 [00:19<02:38,  3.53s/it] 10%|█         | 5/50 [00:19<02:36,  3.49s/it] 10%|█         | 5/50 [00:21<02:45,  3.67s/it] 12%|█▏        | 6/50 [00:22<02:30,  3.43s/it] 12%|█▏        | 6/50 [00:23<02:31,  3.45s/it] 12%|█▏        | 6/50 [00:22<02:29,  3.40s/it] 12%|█▏        | 6/50 [00:24<02:35,  3.52s/it] 14%|█▍        | 7/50 [00:26<02:24,  3.36s/it] 14%|█▍        | 7/50 [00:26<02:25,  3.38s/it] 14%|█▍        | 7/50 [00:25<02:23,  3.34s/it] 14%|█▍        | 7/50 [00:27<02:27,  3.43s/it] 16%|█▌        | 8/50 [00:29<02:19,  3.32s/it] 16%|█▌        | 8/50 [00:29<02:19,  3.33s/it] 16%|█▌        | 8/50 [00:28<02:18,  3.31s/it] 16%|█▌        | 8/50 [00:31<02:21,  3.36s/it] 18%|█▊        | 9/50 [00:32<02:15,  3.29s/it] 18%|█▊        | 9/50 [00:33<02:15,  3.30s/it] 18%|█▊        | 9/50 [00:32<02:14,  3.29s/it] 18%|█▊        | 9/50 [00:34<02:16,  3.32s/it] 20%|██        | 10/50 [00:35<02:10,  3.27s/it] 20%|██        | 10/50 [00:36<02:11,  3.28s/it] 20%|██        | 10/50 [00:35<02:10,  3.27s/it] 20%|██        | 10/50 [00:37<02:11,  3.29s/it] 22%|██▏       | 11/50 [00:38<02:06,  3.26s/it] 22%|██▏       | 11/50 [00:39<02:07,  3.26s/it] 22%|██▏       | 11/50 [00:39<02:07,  3.26s/it] 22%|██▏       | 11/50 [00:40<02:07,  3.27s/it] 24%|██▍       | 12/50 [00:42<02:03,  3.25s/it] 24%|██▍       | 12/50 [00:42<02:03,  3.25s/it] 24%|██▍       | 12/50 [00:41<02:03,  3.25s/it] 24%|██▍       | 12/50 [00:43<02:03,  3.26s/it] 26%|██▌       | 13/50 [00:45<01:59,  3.24s/it] 26%|██▌       | 13/50 [00:45<02:00,  3.25s/it] 26%|██▌       | 13/50 [00:45<01:59,  3.24s/it] 26%|██▌       | 13/50 [00:47<02:00,  3.25s/it] 28%|██▊       | 14/50 [00:48<01:56,  3.24s/it] 28%|██▊       | 14/50 [00:48<01:56,  3.24s/it] 28%|██▊       | 14/50 [00:49<01:56,  3.24s/it] 28%|██▊       | 14/50 [00:50<01:56,  3.24s/it] 30%|███       | 15/50 [00:51<01:53,  3.24s/it] 30%|███       | 15/50 [00:52<01:53,  3.24s/it] 30%|███       | 15/50 [00:51<01:53,  3.24s/it] 30%|███       | 15/50 [00:53<01:53,  3.24s/it] 32%|███▏      | 16/50 [00:54<01:49,  3.23s/it] 32%|███▏      | 16/50 [00:55<01:49,  3.24s/it] 32%|███▏      | 16/50 [00:55<01:50,  3.24s/it] 32%|███▏      | 16/50 [00:56<01:50,  3.24s/it] 34%|███▍      | 17/50 [00:57<01:46,  3.23s/it] 34%|███▍      | 17/50 [00:58<01:46,  3.23s/it] 34%|███▍      | 17/50 [00:58<01:46,  3.23s/it] 34%|███▍      | 17/50 [01:00<01:46,  3.23s/it] 36%|███▌      | 18/50 [01:01<01:43,  3.23s/it] 36%|███▌      | 18/50 [01:01<01:43,  3.23s/it] 36%|███▌      | 18/50 [01:02<01:43,  3.23s/it] 36%|███▌      | 18/50 [01:03<01:43,  3.23s/it] 38%|███▊      | 19/50 [01:04<01:40,  3.23s/it] 38%|███▊      | 19/50 [01:04<01:40,  3.23s/it] 38%|███▊      | 19/50 [01:05<01:40,  3.23s/it] 38%|███▊      | 19/50 [01:06<01:40,  3.23s/it] 40%|████      | 20/50 [01:07<01:36,  3.23s/it] 40%|████      | 20/50 [01:08<01:36,  3.23s/it] 40%|████      | 20/50 [01:08<01:36,  3.23s/it] 40%|████      | 20/50 [01:09<01:36,  3.23s/it] 42%|████▏     | 21/50 [01:11<01:33,  3.23s/it] 42%|████▏     | 21/50 [01:10<01:33,  3.23s/it] 42%|████▏     | 21/50 [01:11<01:33,  3.23s/it] 42%|████▏     | 21/50 [01:12<01:33,  3.23s/it] 44%|████▍     | 22/50 [01:14<01:30,  3.23s/it] 44%|████▍     | 22/50 [01:14<01:30,  3.23s/it] 44%|████▍     | 22/50 [01:15<01:30,  3.23s/it] 44%|████▍     | 22/50 [01:16<01:30,  3.23s/it] 46%|████▌     | 23/50 [01:17<01:27,  3.23s/it] 46%|████▌     | 23/50 [01:18<01:27,  3.23s/it] 46%|████▌     | 23/50 [01:17<01:27,  3.23s/it] 46%|████▌     | 23/50 [01:19<01:27,  3.23s/it] 48%|████▊     | 24/50 [01:20<01:23,  3.23s/it] 48%|████▊     | 24/50 [01:21<01:23,  3.23s/it] 48%|████▊     | 24/50 [01:21<01:23,  3.23s/it] 48%|████▊     | 24/50 [01:22<01:23,  3.23s/it] 50%|█████     | 25/50 [01:23<01:20,  3.23s/it] 50%|█████     | 25/50 [01:24<01:20,  3.23s/it] 50%|█████     | 25/50 [01:24<01:20,  3.23s/it] 50%|█████     | 25/50 [01:25<01:20,  3.23s/it] 52%|█████▏    | 26/50 [01:26<01:17,  3.22s/it] 52%|█████▏    | 26/50 [01:27<01:17,  3.22s/it] 52%|█████▏    | 26/50 [01:27<01:17,  3.22s/it] 52%|█████▏    | 26/50 [01:29<01:17,  3.22s/it] 54%|█████▍    | 27/50 [01:30<01:14,  3.22s/it] 54%|█████▍    | 27/50 [01:30<01:14,  3.22s/it] 54%|█████▍    | 27/50 [01:31<01:14,  3.22s/it] 54%|█████▍    | 27/50 [01:32<01:14,  3.22s/it] 56%|█████▌    | 28/50 [01:33<01:10,  3.22s/it] 56%|█████▌    | 28/50 [01:34<01:10,  3.22s/it] 56%|█████▌    | 28/50 [01:33<01:10,  3.22s/it] 56%|█████▌    | 28/50 [01:35<01:10,  3.22s/it] 58%|█████▊    | 29/50 [01:37<01:07,  3.22s/it] 58%|█████▊    | 29/50 [01:37<01:07,  3.22s/it] 58%|█████▊    | 29/50 [01:36<01:07,  3.22s/it] 58%|█████▊    | 29/50 [01:38<01:07,  3.22s/it] 60%|██████    | 30/50 [01:39<01:04,  3.23s/it] 60%|██████    | 30/50 [01:40<01:04,  3.23s/it] 60%|██████    | 30/50 [01:40<01:04,  3.23s/it] 60%|██████    | 30/50 [01:42<01:04,  3.23s/it] 62%|██████▏   | 31/50 [01:43<01:01,  3.22s/it] 62%|██████▏   | 31/50 [01:43<01:01,  3.22s/it] 62%|██████▏   | 31/50 [01:44<01:01,  3.22s/it] 62%|██████▏   | 31/50 [01:45<01:01,  3.22s/it] 64%|██████▍   | 32/50 [01:46<00:58,  3.22s/it] 64%|██████▍   | 32/50 [01:46<00:58,  3.22s/it] 64%|██████▍   | 32/50 [01:47<00:58,  3.22s/it] 64%|██████▍   | 32/50 [01:48<00:58,  3.22s/it] 66%|██████▌   | 33/50 [01:49<00:54,  3.22s/it] 66%|██████▌   | 33/50 [01:50<00:54,  3.22s/it] 66%|██████▌   | 33/50 [01:50<00:54,  3.22s/it] 66%|██████▌   | 33/50 [01:51<00:54,  3.22s/it] 68%|██████▊   | 34/50 [01:52<00:51,  3.22s/it] 68%|██████▊   | 34/50 [01:53<00:51,  3.22s/it] 68%|██████▊   | 34/50 [01:53<00:51,  3.22s/it] 68%|██████▊   | 34/50 [01:54<00:51,  3.22s/it] 70%|███████   | 35/50 [01:55<00:48,  3.22s/it] 70%|███████   | 35/50 [01:56<00:48,  3.22s/it] 70%|███████   | 35/50 [01:56<00:48,  3.22s/it] 70%|███████   | 35/50 [01:58<00:48,  3.22s/it] 72%|███████▏  | 36/50 [01:59<00:45,  3.23s/it] 72%|███████▏  | 36/50 [01:59<00:45,  3.23s/it] 72%|███████▏  | 36/50 [02:00<00:45,  3.23s/it] 72%|███████▏  | 36/50 [02:01<00:45,  3.23s/it] 74%|███████▍  | 37/50 [02:02<00:41,  3.23s/it] 74%|███████▍  | 37/50 [02:03<00:41,  3.23s/it] 74%|███████▍  | 37/50 [02:02<00:41,  3.23s/it] 74%|███████▍  | 37/50 [02:04<00:41,  3.23s/it] 76%|███████▌  | 38/50 [02:06<00:38,  3.23s/it] 76%|███████▌  | 38/50 [02:05<00:38,  3.23s/it] 76%|███████▌  | 38/50 [02:06<00:38,  3.23s/it] 76%|███████▌  | 38/50 [02:07<00:38,  3.23s/it] 78%|███████▊  | 39/50 [02:08<00:35,  3.23s/it] 78%|███████▊  | 39/50 [02:09<00:35,  3.23s/it] 78%|███████▊  | 39/50 [02:09<00:35,  3.23s/it] 78%|███████▊  | 39/50 [02:11<00:35,  3.23s/it] 80%|████████  | 40/50 [02:12<00:32,  3.23s/it] 80%|████████  | 40/50 [02:13<00:32,  3.23s/it] 80%|████████  | 40/50 [02:12<00:32,  3.23s/it] 80%|████████  | 40/50 [02:14<00:32,  3.23s/it] 82%|████████▏ | 41/50 [02:15<00:29,  3.23s/it] 82%|████████▏ | 41/50 [02:15<00:29,  3.23s/it] 82%|████████▏ | 41/50 [02:16<00:29,  3.23s/it] 82%|████████▏ | 41/50 [02:17<00:29,  3.23s/it] 84%|████████▍ | 42/50 [02:19<00:25,  3.23s/it] 84%|████████▍ | 42/50 [02:18<00:25,  3.23s/it] 84%|████████▍ | 42/50 [02:19<00:25,  3.23s/it] 84%|████████▍ | 42/50 [02:20<00:25,  3.23s/it] 86%|████████▌ | 43/50 [02:21<00:22,  3.23s/it] 86%|████████▌ | 43/50 [02:22<00:22,  3.23s/it] 86%|████████▌ | 43/50 [02:22<00:22,  3.23s/it] 86%|████████▌ | 43/50 [02:23<00:22,  3.23s/it] 88%|████████▊ | 44/50 [02:25<00:19,  3.22s/it] 88%|████████▊ | 44/50 [02:25<00:19,  3.22s/it] 88%|████████▊ | 44/50 [02:25<00:19,  3.22s/it] 88%|████████▊ | 44/50 [02:27<00:19,  3.22s/it] 90%|█████████ | 45/50 [02:28<00:16,  3.22s/it] 90%|█████████ | 45/50 [02:28<00:16,  3.22s/it] 90%|█████████ | 45/50 [02:29<00:16,  3.22s/it] 90%|█████████ | 45/50 [02:30<00:16,  3.22s/it] 92%|█████████▏| 46/50 [02:31<00:12,  3.22s/it] 92%|█████████▏| 46/50 [02:32<00:12,  3.22s/it] 92%|█████████▏| 46/50 [02:31<00:12,  3.22s/it] 92%|█████████▏| 46/50 [02:33<00:12,  3.22s/it] 94%|█████████▍| 47/50 [02:34<00:09,  3.22s/it] 94%|█████████▍| 47/50 [02:35<00:09,  3.22s/it] 94%|█████████▍| 47/50 [02:35<00:09,  3.22s/it] 94%|█████████▍| 47/50 [02:36<00:09,  3.22s/it] 96%|█████████▌| 48/50 [02:37<00:06,  3.22s/it] 96%|█████████▌| 48/50 [02:38<00:06,  3.22s/it] 96%|█████████▌| 48/50 [02:38<00:06,  3.22s/it] 96%|█████████▌| 48/50 [02:40<00:06,  3.22s/it] 98%|█████████▊| 49/50 [02:41<00:03,  3.22s/it] 98%|█████████▊| 49/50 [02:41<00:03,  3.22s/it] 98%|█████████▊| 49/50 [02:42<00:03,  3.22s/it] 98%|█████████▊| 49/50 [02:43<00:03,  3.22s/it]100%|██████████| 50/50 [02:44<00:00,  3.22s/it]100%|██████████| 50/50 [02:44<00:00,  3.29s/it]
代码执行时间: 164.37 秒
100%|██████████| 50/50 [02:45<00:00,  3.22s/it]100%|██████████| 50/50 [02:44<00:00,  3.22s/it]100%|██████████| 50/50 [02:45<00:00,  3.31s/it]
代码执行时间: 165.32 秒
100%|██████████| 50/50 [02:44<00:00,  3.30s/it]
代码执行时间: 164.85 秒
100%|██████████| 50/50 [02:46<00:00,  3.22s/it]100%|██████████| 50/50 [02:46<00:00,  3.33s/it]
代码执行时间: 166.51 秒
2025-03-07 23:32:20.004 | INFO     | hyvideo.inference:predict:669 - Success, time: 184.43109822273254
2025-03-07 23:32:20.021 | INFO     | hyvideo.inference:predict:669 - Success, time: 182.62016940116882
2025-03-07 23:32:20.137 | INFO     | hyvideo.inference:predict:669 - Success, time: 183.4682536125183
2025-03-07 23:32:20.179 | INFO     | hyvideo.inference:predict:669 - Success, time: 183.38116550445557
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-07 23:32:22.759 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0307 23:32:26.550000 139834567808832 torch/distributed/run.py:779] 
W0307 23:32:26.550000 139834567808832 torch/distributed/run.py:779] *****************************************
W0307 23:32:26.550000 139834567808832 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0307 23:32:26.550000 139834567808832 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=2, ring_degree=1)
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=2, ring_degree=1)
2025-03-07 23:32:33.823 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
2025-03-07 23:32:33.823 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:32:33 [parallel_state.py:200] world_size=2 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
DEBUG 03-07 23:32:33 [parallel_state.py:200] world_size=2 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-07 23:32:33.862 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:32:33.862 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:32:34.400 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:32:34.435 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:32:59.774 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:32:59.923 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:33:01.614 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:33:01.729 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:33:01.785 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:33:01.891 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.63s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.56s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.63s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.56s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.53s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.58s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.73s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.69s/it]
2025-03-07 23:33:20.084 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:33:20.111 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:33:22.452 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:33:22.551 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:33:22.781 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:33:22.880 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:33:22.929 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:33:22.969 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:33:23.026 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:33:23.037 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:33:23.066 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:33:23.072 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:33:23.133 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:33:23.175 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:08<06:45,  8.27s/it]  2%|▏         | 1/50 [00:08<06:33,  8.04s/it]  4%|▍         | 2/50 [00:14<05:33,  6.95s/it]  4%|▍         | 2/50 [00:14<05:40,  7.10s/it]  6%|▌         | 3/50 [00:20<05:12,  6.64s/it]  6%|▌         | 3/50 [00:20<05:15,  6.72s/it]  8%|▊         | 4/50 [00:26<04:58,  6.49s/it]  8%|▊         | 4/50 [00:27<05:00,  6.54s/it] 10%|█         | 5/50 [00:32<04:47,  6.40s/it] 10%|█         | 5/50 [00:33<04:49,  6.43s/it] 12%|█▏        | 6/50 [00:39<04:39,  6.35s/it] 12%|█▏        | 6/50 [00:39<04:40,  6.37s/it] 14%|█▍        | 7/50 [00:45<04:31,  6.32s/it] 14%|█▍        | 7/50 [00:45<04:32,  6.33s/it] 16%|█▌        | 8/50 [00:51<04:24,  6.30s/it] 16%|█▌        | 8/50 [00:52<04:25,  6.31s/it] 18%|█▊        | 9/50 [00:58<04:17,  6.29s/it] 18%|█▊        | 9/50 [00:58<04:18,  6.29s/it] 20%|██        | 10/50 [01:04<04:11,  6.28s/it] 20%|██        | 10/50 [01:04<04:11,  6.28s/it] 22%|██▏       | 11/50 [01:10<04:04,  6.27s/it] 22%|██▏       | 11/50 [01:10<04:04,  6.27s/it] 24%|██▍       | 12/50 [01:16<03:58,  6.26s/it] 24%|██▍       | 12/50 [01:17<03:58,  6.27s/it] 26%|██▌       | 13/50 [01:23<03:51,  6.26s/it] 26%|██▌       | 13/50 [01:23<03:51,  6.26s/it] 28%|██▊       | 14/50 [01:29<03:45,  6.26s/it] 28%|██▊       | 14/50 [01:29<03:45,  6.26s/it] 30%|███       | 15/50 [01:35<03:38,  6.26s/it] 30%|███       | 15/50 [01:35<03:38,  6.26s/it] 32%|███▏      | 16/50 [01:41<03:32,  6.25s/it] 32%|███▏      | 16/50 [01:42<03:32,  6.25s/it] 34%|███▍      | 17/50 [01:48<03:26,  6.25s/it] 34%|███▍      | 17/50 [01:48<03:26,  6.25s/it] 36%|███▌      | 18/50 [01:54<03:19,  6.25s/it] 36%|███▌      | 18/50 [01:54<03:19,  6.25s/it] 38%|███▊      | 19/50 [02:00<03:13,  6.25s/it] 38%|███▊      | 19/50 [02:00<03:13,  6.25s/it] 40%|████      | 20/50 [02:06<03:07,  6.25s/it] 40%|████      | 20/50 [02:07<03:07,  6.25s/it] 42%|████▏     | 21/50 [02:13<03:01,  6.25s/it] 42%|████▏     | 21/50 [02:13<03:01,  6.25s/it] 44%|████▍     | 22/50 [02:19<02:54,  6.25s/it] 44%|████▍     | 22/50 [02:19<02:54,  6.25s/it] 46%|████▌     | 23/50 [02:25<02:48,  6.24s/it] 46%|████▌     | 23/50 [02:25<02:48,  6.24s/it] 48%|████▊     | 24/50 [02:31<02:42,  6.25s/it] 48%|████▊     | 24/50 [02:32<02:42,  6.25s/it] 50%|█████     | 25/50 [02:38<02:36,  6.25s/it] 50%|█████     | 25/50 [02:38<02:36,  6.25s/it] 52%|█████▏    | 26/50 [02:44<02:29,  6.25s/it] 52%|█████▏    | 26/50 [02:44<02:30,  6.25s/it] 54%|█████▍    | 27/50 [02:50<02:23,  6.25s/it] 54%|█████▍    | 27/50 [02:50<02:23,  6.25s/it] 56%|█████▌    | 28/50 [02:56<02:17,  6.25s/it] 56%|█████▌    | 28/50 [02:57<02:17,  6.25s/it] 58%|█████▊    | 29/50 [03:02<02:11,  6.25s/it] 58%|█████▊    | 29/50 [03:03<02:11,  6.25s/it] 60%|██████    | 30/50 [03:09<02:04,  6.25s/it] 60%|██████    | 30/50 [03:09<02:04,  6.25s/it] 62%|██████▏   | 31/50 [03:15<01:58,  6.25s/it] 62%|██████▏   | 31/50 [03:15<01:58,  6.25s/it] 64%|██████▍   | 32/50 [03:21<01:52,  6.25s/it] 64%|██████▍   | 32/50 [03:22<01:52,  6.25s/it] 66%|██████▌   | 33/50 [03:27<01:46,  6.25s/it] 66%|██████▌   | 33/50 [03:28<01:46,  6.25s/it] 68%|██████▊   | 34/50 [03:34<01:39,  6.25s/it] 68%|██████▊   | 34/50 [03:34<01:39,  6.25s/it] 70%|███████   | 35/50 [03:40<01:33,  6.25s/it] 70%|███████   | 35/50 [03:40<01:33,  6.25s/it] 72%|███████▏  | 36/50 [03:46<01:27,  6.25s/it] 72%|███████▏  | 36/50 [03:47<01:27,  6.25s/it] 74%|███████▍  | 37/50 [03:52<01:21,  6.25s/it] 74%|███████▍  | 37/50 [03:53<01:21,  6.25s/it] 76%|███████▌  | 38/50 [03:59<01:14,  6.25s/it] 76%|███████▌  | 38/50 [03:59<01:14,  6.25s/it] 78%|███████▊  | 39/50 [04:05<01:08,  6.25s/it] 78%|███████▊  | 39/50 [04:05<01:08,  6.25s/it] 80%|████████  | 40/50 [04:11<01:02,  6.25s/it] 80%|████████  | 40/50 [04:12<01:02,  6.25s/it] 82%|████████▏ | 41/50 [04:17<00:56,  6.25s/it] 82%|████████▏ | 41/50 [04:18<00:56,  6.25s/it] 84%|████████▍ | 42/50 [04:24<00:49,  6.24s/it] 84%|████████▍ | 42/50 [04:24<00:49,  6.24s/it] 86%|████████▌ | 43/50 [04:30<00:43,  6.24s/it] 86%|████████▌ | 43/50 [04:30<00:43,  6.24s/it] 88%|████████▊ | 44/50 [04:36<00:37,  6.24s/it] 88%|████████▊ | 44/50 [04:37<00:37,  6.24s/it] 90%|█████████ | 45/50 [04:42<00:31,  6.25s/it] 90%|█████████ | 45/50 [04:43<00:31,  6.25s/it] 92%|█████████▏| 46/50 [04:49<00:24,  6.24s/it] 92%|█████████▏| 46/50 [04:49<00:24,  6.24s/it] 94%|█████████▍| 47/50 [04:55<00:18,  6.24s/it] 94%|█████████▍| 47/50 [04:55<00:18,  6.24s/it] 96%|█████████▌| 48/50 [05:01<00:12,  6.24s/it] 96%|█████████▌| 48/50 [05:01<00:12,  6.24s/it] 98%|█████████▊| 49/50 [05:07<00:06,  6.24s/it] 98%|█████████▊| 49/50 [05:08<00:06,  6.24s/it]100%|██████████| 50/50 [05:14<00:00,  6.24s/it]100%|██████████| 50/50 [05:14<00:00,  6.28s/it]
代码执行时间: 314.15 秒
100%|██████████| 50/50 [05:14<00:00,  6.24s/it]100%|██████████| 50/50 [05:14<00:00,  6.29s/it]
代码执行时间: 314.47 秒
2025-03-07 23:38:55.420 | INFO     | hyvideo.inference:predict:669 - Success, time: 332.24460077285767
2025-03-07 23:38:55.439 | INFO     | hyvideo.inference:predict:669 - Success, time: 332.3664894104004
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-07 23:38:58.128 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[720, 1280], video_length=69, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=1, ring_degree=1)
2025-03-07 23:39:07.085 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
2025-03-07 23:39:07.085 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:39:07.325 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:39:22.842 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:39:24.511 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:39:24.651 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.04it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.06it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.57it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.32it/s]
2025-03-07 23:39:31.800 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:39:35.219 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:39:35.553 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:39:35.648 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:39:35.690 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:39:35.759 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (720, 1280, 69)
2025-03-07 23:39:35.778 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 720
                         width: 1280
                  video_length: 69
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 64800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:11<09:45, 11.96s/it]  4%|▍         | 2/50 [00:23<09:24, 11.76s/it]  6%|▌         | 3/50 [00:35<09:13, 11.78s/it]  8%|▊         | 4/50 [00:47<09:01, 11.78s/it] 10%|█         | 5/50 [00:58<08:50, 11.79s/it] 12%|█▏        | 6/50 [01:10<08:38, 11.78s/it] 14%|█▍        | 7/50 [01:22<08:26, 11.78s/it] 16%|█▌        | 8/50 [01:34<08:14, 11.78s/it] 18%|█▊        | 9/50 [01:46<08:02, 11.78s/it] 20%|██        | 10/50 [01:57<07:51, 11.78s/it] 22%|██▏       | 11/50 [02:09<07:39, 11.78s/it] 24%|██▍       | 12/50 [02:21<07:27, 11.78s/it] 26%|██▌       | 13/50 [02:33<07:15, 11.77s/it] 28%|██▊       | 14/50 [02:44<07:03, 11.78s/it] 30%|███       | 15/50 [02:56<06:52, 11.78s/it] 32%|███▏      | 16/50 [03:08<06:40, 11.77s/it] 34%|███▍      | 17/50 [03:20<06:28, 11.77s/it] 36%|███▌      | 18/50 [03:32<06:16, 11.77s/it] 38%|███▊      | 19/50 [03:43<06:04, 11.77s/it] 40%|████      | 20/50 [03:55<05:53, 11.77s/it] 42%|████▏     | 21/50 [04:07<05:41, 11.78s/it] 44%|████▍     | 22/50 [04:19<05:29, 11.78s/it] 46%|████▌     | 23/50 [04:30<05:17, 11.78s/it] 48%|████▊     | 24/50 [04:42<05:06, 11.78s/it] 50%|█████     | 25/50 [04:54<04:54, 11.77s/it] 52%|█████▏    | 26/50 [05:06<04:42, 11.77s/it] 54%|█████▍    | 27/50 [05:18<04:30, 11.78s/it] 56%|█████▌    | 28/50 [05:29<04:19, 11.78s/it] 58%|█████▊    | 29/50 [05:41<04:07, 11.77s/it] 60%|██████    | 30/50 [05:53<03:55, 11.77s/it] 62%|██████▏   | 31/50 [06:05<03:43, 11.78s/it] 64%|██████▍   | 32/50 [06:16<03:31, 11.78s/it] 66%|██████▌   | 33/50 [06:28<03:20, 11.78s/it] 68%|██████▊   | 34/50 [06:40<03:08, 11.78s/it] 70%|███████   | 35/50 [06:52<02:56, 11.78s/it] 72%|███████▏  | 36/50 [07:04<02:44, 11.78s/it] 74%|███████▍  | 37/50 [07:15<02:33, 11.78s/it] 76%|███████▌  | 38/50 [07:27<02:21, 11.78s/it] 78%|███████▊  | 39/50 [07:39<02:09, 11.78s/it] 80%|████████  | 40/50 [07:51<01:57, 11.78s/it] 82%|████████▏ | 41/50 [08:02<01:45, 11.77s/it] 84%|████████▍ | 42/50 [08:14<01:34, 11.78s/it] 86%|████████▌ | 43/50 [08:26<01:22, 11.78s/it] 88%|████████▊ | 44/50 [08:38<01:10, 11.78s/it] 90%|█████████ | 45/50 [08:50<00:58, 11.78s/it] 92%|█████████▏| 46/50 [09:01<00:47, 11.78s/it] 94%|█████████▍| 47/50 [09:13<00:35, 11.78s/it] 96%|█████████▌| 48/50 [09:25<00:23, 11.78s/it] 98%|█████████▊| 49/50 [09:37<00:11, 11.78s/it]100%|██████████| 50/50 [09:48<00:00, 11.77s/it]100%|██████████| 50/50 [09:48<00:00, 11.78s/it]
代码执行时间: 588.94 秒
2025-03-07 23:49:42.864 | INFO     | hyvideo.inference:predict:669 - Success, time: 607.0862121582031
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-07 23:49:45.338 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0307 23:49:49.534000 140662028662592 torch/distributed/run.py:779] 
W0307 23:49:49.534000 140662028662592 torch/distributed/run.py:779] *****************************************
W0307 23:49:49.534000 140662028662592 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0307 23:49:49.534000 140662028662592 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:49:57.593 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:49:57 [parallel_state.py:200] world_size=8 rank=4 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:49:58.242 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:49:58 [parallel_state.py:200] world_size=8 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:49:58.249 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:49:58 [parallel_state.py:200] world_size=8 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:49:58.259 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:49:58 [parallel_state.py:200] world_size=8 rank=5 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:49:58.266 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:49:58.271 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:49:58 [parallel_state.py:200] world_size=8 rank=7 local_rank=-1 distributed_init_method=env:// backend=nccl
DEBUG 03-07 23:49:58 [parallel_state.py:200] world_size=8 rank=6 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:49:58.284 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:49:58 [parallel_state.py:200] world_size=8 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-07 23:49:58.298 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:49:58 [parallel_state.py:200] world_size=8 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-07 23:49:58.398 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:49:58.399 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:49:58.400 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:49:58.401 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:49:58.401 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:49:58.401 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:49:58.402 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:49:58.403 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:50:01.344 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:50:01.451 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:50:01.530 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:50:01.540 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:50:01.567 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:50:01.569 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:50:01.587 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:50:01.605 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:50:22.619 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:50:23.616 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:50:24.027 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:50:24.504 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:50:24.617 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 23:50:25.068 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:50:25.272 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:50:25.275 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:50:25.505 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:50:25.613 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:50:25.645 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:50:26.199 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:50:26.334 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:50:27.050 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:50:27.195 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:50:27.946 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:50:28.085 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:50:28.242 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 23:50:28.412 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.77s/it]2025-03-07 23:50:28.652 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 23:50:28.833 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.72s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.05s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.13s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.02s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.82s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.76s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.68s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:16,  5.39s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.09s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.85s/it]
2025-03-07 23:50:36.276 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.12s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.69s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.81s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.35s/it]/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.50s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.07s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.24s/it]2025-03-07 23:50:39.304 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:03,  3.98s/it]2025-03-07 23:50:39.481 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.06s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.95s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.47s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.04s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.56s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.20s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.59s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  2.85s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.63s/it]
2025-03-07 23:50:43.522 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:44.635 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.81s/it]2025-03-07 23:50:45.895 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:50:46.235 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:46.420 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:46.456 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:46.520 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:50:46.537 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:50:46.985 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:47.146 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:50:47.508 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:47.670 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:47.733 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:47.777 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:47.855 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:50:47.881 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:50:48.648 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.30s/it]2025-03-07 23:50:50.113 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:50:50.466 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:50.587 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:50.638 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:50.688 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:50.759 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:50:50.778 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:50:50.809 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:50:51.266 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:50:51.436 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:51.480 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:51.542 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:50:51.551 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:50:51.569 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:50:51.765 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:51.898 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:52.045 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:52.207 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:52.364 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:50:52.387 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.05s/it]  0%|          | 0/50 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.51s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.16s/it]
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:50:54.568 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:50:54.992 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:55.155 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:50:55.196 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:55.266 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:50:55.284 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:50:55.326 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:50:55.684 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:55.831 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:50:55.869 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:50:55.936 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:50:55.952 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:51:00.831 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:51:04.095 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:51:04.429 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:51:04.601 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:51:04.638 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:51:04.701 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:51:04.718 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:06<05:18,  6.51s/it]  2%|▏         | 1/50 [00:16<13:07, 16.07s/it]  2%|▏         | 1/50 [00:14<12:14, 15.00s/it]  2%|▏         | 1/50 [00:24<20:08, 24.67s/it]  2%|▏         | 1/50 [00:19<15:53, 19.46s/it]  2%|▏         | 1/50 [00:20<16:51, 20.65s/it]  2%|▏         | 1/50 [00:23<19:02, 23.32s/it]  2%|▏         | 1/50 [00:18<15:21, 18.80s/it]  4%|▍         | 2/50 [00:16<05:34,  6.96s/it]  4%|▍         | 2/50 [00:07<02:25,  3.03s/it]  4%|▍         | 2/50 [00:20<06:41,  8.36s/it]  4%|▍         | 2/50 [00:19<06:27,  8.08s/it]  4%|▍         | 2/50 [00:15<05:13,  6.52s/it]  4%|▍         | 2/50 [00:23<07:57,  9.95s/it]  4%|▍         | 2/50 [00:25<08:24, 10.50s/it]  4%|▍         | 2/50 [00:21<07:04,  8.85s/it]  6%|▌         | 3/50 [00:17<03:09,  4.03s/it]  6%|▌         | 3/50 [00:19<03:38,  4.64s/it]  6%|▌         | 3/50 [00:07<01:28,  1.89s/it]  6%|▌         | 3/50 [00:25<04:39,  5.95s/it]  6%|▌         | 3/50 [00:24<04:25,  5.65s/it]  6%|▌         | 3/50 [00:16<02:58,  3.79s/it]  6%|▌         | 3/50 [00:20<03:45,  4.79s/it]  6%|▌         | 3/50 [00:21<03:57,  5.06s/it]  8%|▊         | 4/50 [00:17<02:02,  2.65s/it]  8%|▊         | 4/50 [00:20<02:19,  3.02s/it]  8%|▊         | 4/50 [00:26<02:55,  3.82s/it]  8%|▊         | 4/50 [00:16<01:55,  2.51s/it]  8%|▊         | 4/50 [00:21<02:23,  3.11s/it]  8%|▊         | 4/50 [00:08<01:02,  1.36s/it]  8%|▊         | 4/50 [00:24<02:47,  3.63s/it]  8%|▊         | 4/50 [00:22<02:30,  3.27s/it] 10%|█         | 5/50 [00:18<01:25,  1.89s/it] 10%|█         | 5/50 [00:21<01:35,  2.13s/it] 10%|█         | 5/50 [00:26<01:58,  2.63s/it] 10%|█         | 5/50 [00:21<01:38,  2.18s/it] 10%|█         | 5/50 [00:08<00:47,  1.06s/it] 10%|█         | 5/50 [00:17<01:20,  1.80s/it] 10%|█         | 5/50 [00:25<01:53,  2.52s/it] 10%|█         | 5/50 [00:22<01:42,  2.29s/it] 12%|█▏        | 6/50 [00:18<01:02,  1.43s/it] 12%|█▏        | 6/50 [00:22<01:11,  1.63s/it] 12%|█▏        | 6/50 [00:17<01:00,  1.37s/it] 12%|█▏        | 6/50 [00:21<01:09,  1.59s/it] 12%|█▏        | 6/50 [00:27<01:24,  1.92s/it] 12%|█▏        | 6/50 [00:26<01:21,  1.85s/it] 12%|█▏        | 6/50 [00:09<00:38,  1.13it/s] 12%|█▏        | 6/50 [00:23<01:14,  1.69s/it] 14%|█▍        | 7/50 [00:19<00:49,  1.14s/it] 14%|█▍        | 7/50 [00:09<00:33,  1.29it/s] 14%|█▍        | 7/50 [00:26<01:01,  1.42s/it] 14%|█▍        | 7/50 [00:18<00:47,  1.10s/it] 14%|█▍        | 7/50 [00:22<00:53,  1.25s/it] 14%|█▍        | 7/50 [00:27<01:03,  1.47s/it] 14%|█▍        | 7/50 [00:22<00:54,  1.27s/it] 14%|█▍        | 7/50 [00:23<00:56,  1.32s/it] 16%|█▌        | 8/50 [00:19<00:39,  1.05it/s] 16%|█▌        | 8/50 [00:22<00:42,  1.02s/it] 16%|█▌        | 8/50 [00:23<00:43,  1.04s/it] 16%|█▌        | 8/50 [00:10<00:29,  1.43it/s] 16%|█▌        | 8/50 [00:28<00:49,  1.18s/it] 16%|█▌        | 8/50 [00:27<00:47,  1.14s/it] 16%|█▌        | 8/50 [00:18<00:38,  1.08it/s] 16%|█▌        | 8/50 [00:24<00:44,  1.07s/it] 18%|█▊        | 9/50 [00:20<00:33,  1.22it/s] 18%|█▊        | 9/50 [00:23<00:35,  1.15it/s] 18%|█▊        | 9/50 [00:10<00:26,  1.54it/s] 18%|█▊        | 9/50 [00:27<00:39,  1.05it/s] 18%|█▊        | 9/50 [00:29<00:40,  1.02it/s] 18%|█▊        | 9/50 [00:19<00:32,  1.24it/s] 18%|█▊        | 9/50 [00:23<00:36,  1.13it/s] 18%|█▊        | 9/50 [00:25<00:37,  1.10it/s] 20%|██        | 10/50 [00:20<00:29,  1.36it/s] 20%|██        | 10/50 [00:23<00:30,  1.30it/s] 20%|██        | 10/50 [00:11<00:24,  1.62it/s] 20%|██        | 10/50 [00:24<00:31,  1.28it/s] 20%|██        | 10/50 [00:28<00:33,  1.21it/s] 20%|██        | 10/50 [00:19<00:28,  1.38it/s] 20%|██        | 10/50 [00:29<00:33,  1.19it/s] 20%|██        | 10/50 [00:25<00:31,  1.26it/s] 22%|██▏       | 11/50 [00:21<00:26,  1.48it/s] 22%|██▏       | 11/50 [00:24<00:27,  1.43it/s] 22%|██▏       | 11/50 [00:11<00:23,  1.68it/s] 22%|██▏       | 11/50 [00:20<00:26,  1.50it/s] 22%|██▏       | 11/50 [00:30<00:29,  1.33it/s] 22%|██▏       | 11/50 [00:28<00:28,  1.35it/s] 22%|██▏       | 11/50 [00:24<00:27,  1.42it/s] 22%|██▏       | 11/50 [00:26<00:27,  1.40it/s] 24%|██▍       | 12/50 [00:22<00:24,  1.58it/s] 24%|██▍       | 12/50 [00:24<00:24,  1.54it/s] 24%|██▍       | 12/50 [00:20<00:23,  1.59it/s] 24%|██▍       | 12/50 [00:12<00:21,  1.73it/s] 24%|██▍       | 12/50 [00:30<00:26,  1.46it/s] 24%|██▍       | 12/50 [00:29<00:25,  1.48it/s] 24%|██▍       | 12/50 [00:25<00:24,  1.53it/s] 24%|██▍       | 12/50 [00:26<00:25,  1.51it/s] 26%|██▌       | 13/50 [00:22<00:22,  1.65it/s] 26%|██▌       | 13/50 [00:25<00:22,  1.62it/s] 26%|██▌       | 13/50 [00:29<00:23,  1.57it/s] 26%|██▌       | 13/50 [00:21<00:22,  1.67it/s] 26%|██▌       | 13/50 [00:13<00:20,  1.77it/s] 26%|██▌       | 13/50 [00:25<00:22,  1.62it/s] 26%|██▌       | 13/50 [00:31<00:23,  1.56it/s] 26%|██▌       | 13/50 [00:27<00:23,  1.60it/s] 28%|██▊       | 14/50 [00:23<00:21,  1.71it/s] 28%|██▊       | 14/50 [00:25<00:21,  1.69it/s] 28%|██▊       | 14/50 [00:31<00:21,  1.64it/s] 28%|██▊       | 14/50 [00:22<00:20,  1.72it/s] 28%|██▊       | 14/50 [00:26<00:21,  1.68it/s] 28%|██▊       | 14/50 [00:30<00:21,  1.65it/s] 28%|██▊       | 14/50 [00:13<00:20,  1.79it/s] 28%|██▊       | 14/50 [00:27<00:21,  1.67it/s] 30%|███       | 15/50 [00:23<00:19,  1.75it/s] 30%|███       | 15/50 [00:22<00:19,  1.76it/s] 30%|███       | 15/50 [00:32<00:20,  1.70it/s] 30%|███       | 15/50 [00:14<00:19,  1.81it/s] 30%|███       | 15/50 [00:26<00:20,  1.73it/s] 30%|███       | 15/50 [00:30<00:20,  1.71it/s] 30%|███       | 15/50 [00:27<00:20,  1.73it/s] 30%|███       | 15/50 [00:28<00:20,  1.72it/s] 32%|███▏      | 16/50 [00:24<00:19,  1.78it/s] 32%|███▏      | 16/50 [00:26<00:19,  1.77it/s] 32%|███▏      | 16/50 [00:31<00:19,  1.75it/s] 32%|███▏      | 16/50 [00:23<00:19,  1.79it/s] 32%|███▏      | 16/50 [00:14<00:18,  1.83it/s] 32%|███▏      | 16/50 [00:27<00:19,  1.77it/s] 32%|███▏      | 16/50 [00:32<00:19,  1.74it/s] 32%|███▏      | 16/50 [00:28<00:19,  1.76it/s] 34%|███▍      | 17/50 [00:24<00:18,  1.80it/s] 34%|███▍      | 17/50 [00:27<00:18,  1.79it/s] 34%|███▍      | 17/50 [00:28<00:18,  1.79it/s] 34%|███▍      | 17/50 [00:32<00:18,  1.78it/s] 34%|███▍      | 17/50 [00:23<00:18,  1.81it/s] 34%|███▍      | 17/50 [00:33<00:18,  1.77it/s] 34%|███▍      | 17/50 [00:15<00:18,  1.83it/s] 34%|███▍      | 17/50 [00:29<00:18,  1.79it/s] 36%|███▌      | 18/50 [00:25<00:17,  1.82it/s] 36%|███▌      | 18/50 [00:28<00:17,  1.81it/s] 36%|███▌      | 18/50 [00:24<00:17,  1.82it/s] 36%|███▌      | 18/50 [00:33<00:17,  1.80it/s] 36%|███▌      | 18/50 [00:15<00:17,  1.84it/s] 36%|███▌      | 18/50 [00:28<00:17,  1.81it/s] 36%|███▌      | 18/50 [00:32<00:17,  1.80it/s] 36%|███▌      | 18/50 [00:29<00:17,  1.81it/s] 38%|███▊      | 19/50 [00:25<00:16,  1.83it/s] 38%|███▊      | 19/50 [00:28<00:16,  1.83it/s] 38%|███▊      | 19/50 [00:34<00:17,  1.82it/s] 38%|███▊      | 19/50 [00:24<00:16,  1.83it/s] 38%|███▊      | 19/50 [00:16<00:16,  1.85it/s] 38%|███▊      | 19/50 [00:33<00:17,  1.82it/s] 38%|███▊      | 19/50 [00:29<00:16,  1.83it/s] 38%|███▊      | 19/50 [00:30<00:17,  1.82it/s] 40%|████      | 20/50 [00:26<00:16,  1.84it/s] 40%|████      | 20/50 [00:29<00:16,  1.83it/s] 40%|████      | 20/50 [00:29<00:16,  1.83it/s] 40%|████      | 20/50 [00:33<00:16,  1.83it/s] 40%|████      | 20/50 [00:16<00:16,  1.85it/s] 40%|████      | 20/50 [00:25<00:16,  1.84it/s] 40%|████      | 20/50 [00:34<00:16,  1.83it/s] 40%|████      | 20/50 [00:30<00:16,  1.83it/s] 42%|████▏     | 21/50 [00:26<00:15,  1.84it/s] 42%|████▏     | 21/50 [00:29<00:15,  1.84it/s] 42%|████▏     | 21/50 [00:30<00:15,  1.84it/s] 42%|████▏     | 21/50 [00:17<00:15,  1.85it/s] 42%|████▏     | 21/50 [00:25<00:15,  1.85it/s] 42%|████▏     | 21/50 [00:35<00:15,  1.84it/s] 42%|████▏     | 21/50 [00:34<00:15,  1.84it/s] 42%|████▏     | 21/50 [00:31<00:15,  1.84it/s] 44%|████▍     | 22/50 [00:27<00:15,  1.85it/s] 44%|████▍     | 22/50 [00:30<00:15,  1.85it/s] 44%|████▍     | 22/50 [00:34<00:15,  1.84it/s] 44%|████▍     | 22/50 [00:30<00:15,  1.85it/s] 44%|████▍     | 22/50 [00:17<00:15,  1.85it/s] 44%|████▍     | 22/50 [00:36<00:15,  1.84it/s] 44%|████▍     | 22/50 [00:26<00:15,  1.85it/s] 44%|████▍     | 22/50 [00:32<00:15,  1.85it/s] 46%|████▌     | 23/50 [00:27<00:14,  1.85it/s] 46%|████▌     | 23/50 [00:30<00:14,  1.85it/s] 46%|████▌     | 23/50 [00:36<00:14,  1.85it/s] 46%|████▌     | 23/50 [00:18<00:14,  1.85it/s] 46%|████▌     | 23/50 [00:26<00:14,  1.85it/s] 46%|████▌     | 23/50 [00:35<00:14,  1.85it/s] 46%|████▌     | 23/50 [00:31<00:14,  1.85it/s] 46%|████▌     | 23/50 [00:32<00:14,  1.85it/s] 48%|████▊     | 24/50 [00:28<00:14,  1.85it/s] 48%|████▊     | 24/50 [00:31<00:14,  1.85it/s] 48%|████▊     | 24/50 [00:18<00:14,  1.86it/s] 48%|████▊     | 24/50 [00:27<00:14,  1.85it/s] 48%|████▊     | 24/50 [00:37<00:14,  1.85it/s] 48%|████▊     | 24/50 [00:35<00:14,  1.85it/s] 48%|████▊     | 24/50 [00:31<00:14,  1.85it/s] 48%|████▊     | 24/50 [00:33<00:14,  1.85it/s] 50%|█████     | 25/50 [00:29<00:13,  1.86it/s] 50%|█████     | 25/50 [00:31<00:13,  1.86it/s] 50%|█████     | 25/50 [00:32<00:13,  1.86it/s] 50%|█████     | 25/50 [00:19<00:13,  1.86it/s] 50%|█████     | 25/50 [00:36<00:13,  1.86it/s] 50%|█████     | 25/50 [00:27<00:13,  1.86it/s] 50%|█████     | 25/50 [00:37<00:13,  1.86it/s] 50%|█████     | 25/50 [00:33<00:13,  1.86it/s] 52%|█████▏    | 26/50 [00:29<00:12,  1.86it/s] 52%|█████▏    | 26/50 [00:32<00:12,  1.86it/s] 52%|█████▏    | 26/50 [00:20<00:12,  1.86it/s] 52%|█████▏    | 26/50 [00:36<00:12,  1.86it/s] 52%|█████▏    | 26/50 [00:28<00:12,  1.86it/s] 52%|█████▏    | 26/50 [00:38<00:12,  1.85it/s] 52%|█████▏    | 26/50 [00:32<00:12,  1.86it/s] 52%|█████▏    | 26/50 [00:34<00:12,  1.86it/s] 54%|█████▍    | 27/50 [00:30<00:12,  1.86it/s] 54%|█████▍    | 27/50 [00:33<00:12,  1.86it/s] 54%|█████▍    | 27/50 [00:29<00:12,  1.86it/s] 54%|█████▍    | 27/50 [00:20<00:12,  1.86it/s] 54%|█████▍    | 27/50 [00:37<00:12,  1.86it/s] 54%|█████▍    | 27/50 [00:32<00:12,  1.86it/s] 54%|█████▍    | 27/50 [00:38<00:12,  1.86it/s] 54%|█████▍    | 27/50 [00:34<00:12,  1.86it/s] 56%|█████▌    | 28/50 [00:30<00:11,  1.86it/s] 56%|█████▌    | 28/50 [00:33<00:11,  1.86it/s] 56%|█████▌    | 28/50 [00:29<00:11,  1.86it/s] 56%|█████▌    | 28/50 [00:37<00:11,  1.86it/s] 56%|█████▌    | 28/50 [00:21<00:11,  1.86it/s] 56%|█████▌    | 28/50 [00:39<00:11,  1.86it/s] 56%|█████▌    | 28/50 [00:34<00:11,  1.86it/s] 56%|█████▌    | 28/50 [00:35<00:11,  1.86it/s] 58%|█████▊    | 29/50 [00:31<00:11,  1.86it/s] 58%|█████▊    | 29/50 [00:21<00:11,  1.86it/s] 58%|█████▊    | 29/50 [00:30<00:11,  1.86it/s] 58%|█████▊    | 29/50 [00:39<00:11,  1.86it/s] 58%|█████▊    | 29/50 [00:33<00:11,  1.86it/s] 58%|█████▊    | 29/50 [00:34<00:11,  1.86it/s] 58%|█████▊    | 29/50 [00:38<00:11,  1.86it/s] 58%|█████▊    | 29/50 [00:35<00:11,  1.86it/s] 60%|██████    | 30/50 [00:31<00:10,  1.86it/s] 60%|██████    | 30/50 [00:34<00:10,  1.86it/s] 60%|██████    | 30/50 [00:30<00:10,  1.86it/s] 60%|██████    | 30/50 [00:40<00:10,  1.86it/s] 60%|██████    | 30/50 [00:35<00:10,  1.86it/s] 60%|██████    | 30/50 [00:39<00:10,  1.86it/s] 60%|██████    | 30/50 [00:22<00:10,  1.86it/s] 60%|██████    | 30/50 [00:36<00:10,  1.86it/s] 62%|██████▏   | 31/50 [00:32<00:10,  1.86it/s] 62%|██████▏   | 31/50 [00:35<00:10,  1.86it/s] 62%|██████▏   | 31/50 [00:35<00:10,  1.86it/s] 62%|██████▏   | 31/50 [00:22<00:10,  1.86it/s] 62%|██████▏   | 31/50 [00:39<00:10,  1.86it/s] 62%|██████▏   | 31/50 [00:40<00:10,  1.86it/s] 62%|██████▏   | 31/50 [00:31<00:10,  1.86it/s] 62%|██████▏   | 31/50 [00:36<00:10,  1.86it/s] 64%|██████▍   | 32/50 [00:32<00:09,  1.86it/s] 64%|██████▍   | 32/50 [00:35<00:09,  1.86it/s] 64%|██████▍   | 32/50 [00:36<00:09,  1.86it/s] 64%|██████▍   | 32/50 [00:40<00:09,  1.86it/s] 64%|██████▍   | 32/50 [00:31<00:09,  1.86it/s] 64%|██████▍   | 32/50 [00:23<00:09,  1.86it/s] 64%|██████▍   | 32/50 [00:41<00:09,  1.86it/s] 64%|██████▍   | 32/50 [00:37<00:09,  1.86it/s] 66%|██████▌   | 33/50 [00:33<00:09,  1.86it/s] 66%|██████▌   | 33/50 [00:36<00:09,  1.86it/s] 66%|██████▌   | 33/50 [00:36<00:09,  1.86it/s] 66%|██████▌   | 33/50 [00:32<00:09,  1.86it/s] 66%|██████▌   | 33/50 [00:40<00:09,  1.86it/s] 66%|██████▌   | 33/50 [00:41<00:09,  1.86it/s] 66%|██████▌   | 33/50 [00:23<00:09,  1.86it/s] 66%|██████▌   | 33/50 [00:37<00:09,  1.86it/s] 68%|██████▊   | 34/50 [00:33<00:08,  1.86it/s] 68%|██████▊   | 34/50 [00:36<00:08,  1.86it/s] 68%|██████▊   | 34/50 [00:42<00:08,  1.86it/s] 68%|██████▊   | 34/50 [00:41<00:08,  1.86it/s] 68%|██████▊   | 34/50 [00:37<00:08,  1.86it/s] 68%|██████▊   | 34/50 [00:24<00:08,  1.86it/s] 68%|██████▊   | 34/50 [00:32<00:08,  1.86it/s] 68%|██████▊   | 34/50 [00:38<00:08,  1.86it/s] 70%|███████   | 35/50 [00:34<00:08,  1.86it/s] 70%|███████   | 35/50 [00:37<00:08,  1.86it/s] 70%|███████   | 35/50 [00:24<00:08,  1.86it/s] 70%|███████   | 35/50 [00:41<00:08,  1.86it/s] 70%|███████   | 35/50 [00:43<00:08,  1.86it/s] 70%|███████   | 35/50 [00:33<00:08,  1.86it/s] 70%|███████   | 35/50 [00:37<00:08,  1.86it/s] 70%|███████   | 35/50 [00:39<00:08,  1.86it/s] 72%|███████▏  | 36/50 [00:34<00:07,  1.86it/s] 72%|███████▏  | 36/50 [00:37<00:07,  1.86it/s] 72%|███████▏  | 36/50 [00:43<00:07,  1.86it/s] 72%|███████▏  | 36/50 [00:42<00:07,  1.86it/s] 72%|███████▏  | 36/50 [00:25<00:07,  1.86it/s] 72%|███████▏  | 36/50 [00:38<00:07,  1.86it/s] 72%|███████▏  | 36/50 [00:33<00:07,  1.86it/s] 72%|███████▏  | 36/50 [00:39<00:07,  1.86it/s] 74%|███████▍  | 37/50 [00:35<00:06,  1.86it/s] 74%|███████▍  | 37/50 [00:34<00:06,  1.86it/s] 74%|███████▍  | 37/50 [00:25<00:06,  1.86it/s] 74%|███████▍  | 37/50 [00:38<00:06,  1.86it/s] 74%|███████▍  | 37/50 [00:44<00:06,  1.86it/s] 74%|███████▍  | 37/50 [00:38<00:06,  1.86it/s] 74%|███████▍  | 37/50 [00:42<00:06,  1.86it/s] 74%|███████▍  | 37/50 [00:40<00:06,  1.86it/s] 76%|███████▌  | 38/50 [00:36<00:06,  1.86it/s] 76%|███████▌  | 38/50 [00:38<00:06,  1.86it/s] 76%|███████▌  | 38/50 [00:26<00:06,  1.86it/s] 76%|███████▌  | 38/50 [00:39<00:06,  1.86it/s] 76%|███████▌  | 38/50 [00:43<00:06,  1.86it/s] 76%|███████▌  | 38/50 [00:34<00:06,  1.86it/s] 76%|███████▌  | 38/50 [00:44<00:06,  1.86it/s] 76%|███████▌  | 38/50 [00:40<00:06,  1.86it/s] 78%|███████▊  | 39/50 [00:36<00:05,  1.86it/s] 78%|███████▊  | 39/50 [00:39<00:05,  1.86it/s] 78%|███████▊  | 39/50 [00:27<00:05,  1.86it/s] 78%|███████▊  | 39/50 [00:45<00:05,  1.86it/s] 78%|███████▊  | 39/50 [00:39<00:05,  1.86it/s] 78%|███████▊  | 39/50 [00:43<00:05,  1.86it/s] 78%|███████▊  | 39/50 [00:35<00:05,  1.86it/s] 78%|███████▊  | 39/50 [00:41<00:05,  1.86it/s] 80%|████████  | 40/50 [00:37<00:05,  1.86it/s] 80%|████████  | 40/50 [00:44<00:05,  1.86it/s] 80%|████████  | 40/50 [00:40<00:05,  1.86it/s] 80%|████████  | 40/50 [00:27<00:05,  1.86it/s] 80%|████████  | 40/50 [00:36<00:05,  1.86it/s] 80%|████████  | 40/50 [00:45<00:05,  1.86it/s] 80%|████████  | 40/50 [00:39<00:05,  1.86it/s] 80%|████████  | 40/50 [00:41<00:05,  1.86it/s] 82%|████████▏ | 41/50 [00:37<00:04,  1.86it/s] 82%|████████▏ | 41/50 [00:36<00:04,  1.86it/s] 82%|████████▏ | 41/50 [00:40<00:04,  1.86it/s] 82%|████████▏ | 41/50 [00:46<00:04,  1.86it/s] 82%|████████▏ | 41/50 [00:28<00:04,  1.86it/s] 82%|████████▏ | 41/50 [00:44<00:04,  1.86it/s] 82%|████████▏ | 41/50 [00:41<00:04,  1.86it/s] 82%|████████▏ | 41/50 [00:42<00:04,  1.86it/s] 84%|████████▍ | 42/50 [00:38<00:04,  1.86it/s] 84%|████████▍ | 42/50 [00:40<00:04,  1.86it/s] 84%|████████▍ | 42/50 [00:37<00:04,  1.86it/s] 84%|████████▍ | 42/50 [00:45<00:04,  1.86it/s] 84%|████████▍ | 42/50 [00:46<00:04,  1.86it/s] 84%|████████▍ | 42/50 [00:28<00:04,  1.86it/s] 84%|████████▍ | 42/50 [00:41<00:04,  1.86it/s] 84%|████████▍ | 42/50 [00:42<00:04,  1.86it/s] 86%|████████▌ | 43/50 [00:38<00:03,  1.86it/s] 86%|████████▌ | 43/50 [00:41<00:03,  1.86it/s] 86%|████████▌ | 43/50 [00:37<00:03,  1.86it/s] 86%|████████▌ | 43/50 [00:29<00:03,  1.86it/s] 86%|████████▌ | 43/50 [00:47<00:03,  1.86it/s] 86%|████████▌ | 43/50 [00:45<00:03,  1.86it/s] 86%|████████▌ | 43/50 [00:42<00:03,  1.86it/s] 86%|████████▌ | 43/50 [00:43<00:03,  1.86it/s] 88%|████████▊ | 44/50 [00:39<00:03,  1.86it/s] 88%|████████▊ | 44/50 [00:42<00:03,  1.86it/s] 88%|████████▊ | 44/50 [00:38<00:03,  1.86it/s] 88%|████████▊ | 44/50 [00:47<00:03,  1.86it/s] 88%|████████▊ | 44/50 [00:46<00:03,  1.86it/s] 88%|████████▊ | 44/50 [00:42<00:03,  1.86it/s] 88%|████████▊ | 44/50 [00:29<00:03,  1.86it/s] 88%|████████▊ | 44/50 [00:43<00:03,  1.86it/s] 90%|█████████ | 45/50 [00:39<00:02,  1.86it/s] 90%|█████████ | 45/50 [00:42<00:02,  1.86it/s] 90%|█████████ | 45/50 [00:48<00:02,  1.86it/s] 90%|█████████ | 45/50 [00:30<00:02,  1.86it/s] 90%|█████████ | 45/50 [00:38<00:02,  1.86it/s] 90%|█████████ | 45/50 [00:43<00:02,  1.86it/s] 90%|█████████ | 45/50 [00:47<00:02,  1.86it/s] 90%|█████████ | 45/50 [00:44<00:02,  1.86it/s] 92%|█████████▏| 46/50 [00:40<00:02,  1.86it/s] 92%|█████████▏| 46/50 [00:43<00:02,  1.86it/s] 92%|█████████▏| 46/50 [00:43<00:02,  1.86it/s] 92%|█████████▏| 46/50 [00:47<00:02,  1.86it/s] 92%|█████████▏| 46/50 [00:39<00:02,  1.86it/s] 92%|█████████▏| 46/50 [00:48<00:02,  1.86it/s] 92%|█████████▏| 46/50 [00:30<00:02,  1.86it/s] 92%|█████████▏| 46/50 [00:44<00:02,  1.86it/s] 94%|█████████▍| 47/50 [00:40<00:01,  1.86it/s] 94%|█████████▍| 47/50 [00:31<00:01,  1.86it/s] 94%|█████████▍| 47/50 [00:43<00:01,  1.86it/s] 94%|█████████▍| 47/50 [00:39<00:01,  1.86it/s] 94%|█████████▍| 47/50 [00:44<00:01,  1.86it/s] 94%|█████████▍| 47/50 [00:48<00:01,  1.86it/s] 94%|█████████▍| 47/50 [00:49<00:01,  1.86it/s] 94%|█████████▍| 47/50 [00:45<00:01,  1.86it/s] 96%|█████████▌| 48/50 [00:41<00:01,  1.86it/s] 96%|█████████▌| 48/50 [00:31<00:01,  1.87it/s] 96%|█████████▌| 48/50 [00:40<00:01,  1.86it/s] 96%|█████████▌| 48/50 [00:44<00:01,  1.86it/s] 96%|█████████▌| 48/50 [00:44<00:01,  1.86it/s] 96%|█████████▌| 48/50 [00:50<00:01,  1.86it/s] 96%|█████████▌| 48/50 [00:48<00:01,  1.86it/s] 96%|█████████▌| 48/50 [00:46<00:01,  1.86it/s] 98%|█████████▊| 49/50 [00:41<00:00,  1.87it/s] 98%|█████████▊| 49/50 [00:32<00:00,  1.87it/s] 98%|█████████▊| 49/50 [00:40<00:00,  1.87it/s] 98%|█████████▊| 49/50 [00:44<00:00,  1.87it/s] 98%|█████████▊| 49/50 [00:49<00:00,  1.87it/s] 98%|█████████▊| 49/50 [00:45<00:00,  1.87it/s] 98%|█████████▊| 49/50 [00:50<00:00,  1.87it/s] 98%|█████████▊| 49/50 [00:46<00:00,  1.87it/s]100%|██████████| 50/50 [00:42<00:00,  1.87it/s]100%|██████████| 50/50 [00:32<00:00,  1.87it/s]100%|██████████| 50/50 [00:41<00:00,  1.87it/s]100%|██████████| 50/50 [00:42<00:00,  1.18it/s]
代码执行时间: 42.49 秒
100%|██████████| 50/50 [00:32<00:00,  1.52it/s]
代码执行时间: 32.94 秒
100%|██████████| 50/50 [00:41<00:00,  1.21it/s]
代码执行时间: 41.42 秒
100%|██████████| 50/50 [00:45<00:00,  1.87it/s]100%|██████████| 50/50 [00:49<00:00,  1.87it/s]100%|██████████| 50/50 [00:51<00:00,  1.87it/s]100%|██████████| 50/50 [00:45<00:00,  1.87it/s]100%|██████████| 50/50 [00:45<00:00,  1.09it/s]
100%|██████████| 50/50 [00:49<00:00,  1.01it/s]代码执行时间: 45.88 秒

代码执行时间: 49.74 秒
100%|██████████| 50/50 [00:51<00:00,  1.02s/it]
代码执行时间: 51.09 秒
100%|██████████| 50/50 [00:45<00:00,  1.11it/s]
代码执行时间: 45.22 秒
100%|██████████| 50/50 [00:47<00:00,  1.87it/s]100%|██████████| 50/50 [00:47<00:00,  1.06it/s]
代码执行时间: 47.08 秒
2025-03-07 23:51:46.074 | INFO     | hyvideo.inference:predict:669 - Success, time: 50.121885776519775
2025-03-07 23:51:46.079 | INFO     | hyvideo.inference:predict:669 - Success, time: 50.79503393173218
2025-03-07 23:51:46.131 | INFO     | hyvideo.inference:predict:669 - Success, time: 54.5616340637207
2025-03-07 23:51:46.288 | INFO     | hyvideo.inference:predict:669 - Success, time: 41.56981897354126
2025-03-07 23:51:46.597 | INFO     | hyvideo.inference:predict:669 - Success, time: 60.05966329574585
2025-03-07 23:51:47.348 | INFO     | hyvideo.inference:predict:669 - Success, time: 59.46697235107422
2025-03-07 23:51:47.386 | INFO     | hyvideo.inference:predict:669 - Success, time: 54.99942421913147
2025-03-07 23:51:47.397 | INFO     | hyvideo.inference:predict:669 - Success, time: 56.61910080909729
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-07 23:51:49.437 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0307 23:51:54.340000 139765579016000 torch/distributed/run.py:779] 
W0307 23:51:54.340000 139765579016000 torch/distributed/run.py:779] *****************************************
W0307 23:51:54.340000 139765579016000 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0307 23:51:54.340000 139765579016000 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 23:52:00.707 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:52:00 [parallel_state.py:200] world_size=4 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 23:52:00.934 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:52:00 [parallel_state.py:200] world_size=4 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 23:52:01.011 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:52:01 [parallel_state.py:200] world_size=4 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-07 23:52:01.042 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:52:01 [parallel_state.py:200] world_size=4 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-07 23:52:01.092 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:52:01.092 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:52:01.092 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:52:01.093 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:52:02.652 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:52:02.675 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:52:02.718 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:52:02.754 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:52:28.970 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:52:29.026 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:52:29.157 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:52:29.201 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:52:30.856 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:52:30.960 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-07 23:52:31.868 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:52:31.978 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:52:32.015 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:52:32.033 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:52:32.140 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:52:32.173 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.79s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.78s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.12s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.12s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.84s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.75s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.90s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.63s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.78s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.89s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.68s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.82s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.78s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.92s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.61s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.32s/it]
2025-03-07 23:52:50.329 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:52:51.291 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:52:51.819 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:52:52.950 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:52:53.312 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:52:53.478 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:52:53.481 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:52:53.526 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:52:53.597 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:52:53.616 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:52:54.081 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:52:54.501 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:52:54.664 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:52:54.720 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:52:54.727 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:52:54.835 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:52:54.855 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:52:55.063 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:52:55.216 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:52:55.258 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:52:55.324 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:52:55.340 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  0%|          | 0/50 [00:00<?, ?it/s]2025-03-07 23:52:56.255 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:52:56.589 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:52:56.734 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:52:56.771 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:52:56.835 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:52:56.851 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:07<05:52,  7.20s/it]  2%|▏         | 1/50 [00:05<04:25,  5.42s/it]  2%|▏         | 1/50 [00:03<02:59,  3.67s/it]  2%|▏         | 1/50 [00:05<04:53,  6.00s/it]  4%|▍         | 2/50 [00:04<01:39,  2.08s/it]  4%|▍         | 2/50 [00:06<02:25,  3.04s/it]  4%|▍         | 2/50 [00:08<02:50,  3.55s/it]  4%|▍         | 2/50 [00:06<02:15,  2.82s/it]  6%|▌         | 3/50 [00:07<01:38,  2.09s/it]  6%|▌         | 3/50 [00:05<01:13,  1.57s/it]  6%|▌         | 3/50 [00:09<01:51,  2.37s/it]  6%|▌         | 3/50 [00:07<01:32,  1.97s/it]  8%|▊         | 4/50 [00:06<01:01,  1.33s/it]  8%|▊         | 4/50 [00:08<01:15,  1.65s/it]  8%|▊         | 4/50 [00:10<01:23,  1.82s/it]  8%|▊         | 4/50 [00:08<01:12,  1.58s/it] 10%|█         | 5/50 [00:07<00:54,  1.20s/it] 10%|█         | 5/50 [00:09<01:03,  1.40s/it] 10%|█         | 5/50 [00:11<01:08,  1.51s/it] 10%|█         | 5/50 [00:09<01:01,  1.36s/it] 12%|█▏        | 6/50 [00:10<00:55,  1.26s/it] 12%|█▏        | 6/50 [00:08<00:49,  1.12s/it] 12%|█▏        | 6/50 [00:12<00:58,  1.33s/it] 12%|█▏        | 6/50 [00:10<00:53,  1.23s/it] 14%|█▍        | 7/50 [00:11<00:49,  1.16s/it] 14%|█▍        | 7/50 [00:09<00:46,  1.07s/it] 14%|█▍        | 7/50 [00:13<00:52,  1.21s/it] 14%|█▍        | 7/50 [00:11<00:49,  1.14s/it] 16%|█▌        | 8/50 [00:10<00:43,  1.04s/it] 16%|█▌        | 8/50 [00:12<00:46,  1.10s/it] 16%|█▌        | 8/50 [00:14<00:47,  1.13s/it] 16%|█▌        | 8/50 [00:12<00:45,  1.09s/it] 18%|█▊        | 9/50 [00:13<00:43,  1.06s/it] 18%|█▊        | 9/50 [00:11<00:41,  1.02s/it] 18%|█▊        | 9/50 [00:14<00:44,  1.08s/it] 18%|█▊        | 9/50 [00:13<00:43,  1.05s/it] 20%|██        | 10/50 [00:12<00:40,  1.00s/it] 20%|██        | 10/50 [00:14<00:41,  1.03s/it] 20%|██        | 10/50 [00:15<00:41,  1.05s/it] 20%|██        | 10/50 [00:14<00:40,  1.02s/it] 22%|██▏       | 11/50 [00:15<00:39,  1.01s/it] 22%|██▏       | 11/50 [00:13<00:38,  1.01it/s] 22%|██▏       | 11/50 [00:16<00:39,  1.02s/it] 22%|██▏       | 11/50 [00:15<00:39,  1.01s/it] 24%|██▍       | 12/50 [00:14<00:37,  1.01it/s] 24%|██▍       | 12/50 [00:16<00:37,  1.00it/s] 24%|██▍       | 12/50 [00:17<00:38,  1.01s/it] 24%|██▍       | 12/50 [00:16<00:37,  1.00it/s] 26%|██▌       | 13/50 [00:15<00:36,  1.02it/s] 26%|██▌       | 13/50 [00:17<00:36,  1.01it/s] 26%|██▌       | 13/50 [00:18<00:36,  1.00it/s] 26%|██▌       | 13/50 [00:17<00:36,  1.01it/s] 28%|██▊       | 14/50 [00:16<00:35,  1.02it/s] 28%|██▊       | 14/50 [00:18<00:35,  1.01it/s] 28%|██▊       | 14/50 [00:19<00:35,  1.01it/s] 28%|██▊       | 14/50 [00:18<00:35,  1.02it/s] 30%|███       | 15/50 [00:17<00:34,  1.02it/s] 30%|███       | 15/50 [00:19<00:34,  1.02it/s] 30%|███       | 15/50 [00:20<00:34,  1.02it/s] 30%|███       | 15/50 [00:19<00:34,  1.02it/s] 32%|███▏      | 16/50 [00:18<00:33,  1.02it/s] 32%|███▏      | 16/50 [00:20<00:33,  1.02it/s] 32%|███▏      | 16/50 [00:21<00:33,  1.02it/s] 32%|███▏      | 16/50 [00:20<00:33,  1.02it/s] 34%|███▍      | 17/50 [00:19<00:32,  1.03it/s] 34%|███▍      | 17/50 [00:21<00:32,  1.02it/s] 34%|███▍      | 17/50 [00:22<00:32,  1.02it/s] 34%|███▍      | 17/50 [00:20<00:32,  1.02it/s] 36%|███▌      | 18/50 [00:22<00:31,  1.02it/s] 36%|███▌      | 18/50 [00:20<00:31,  1.03it/s] 36%|███▌      | 18/50 [00:23<00:31,  1.02it/s] 36%|███▌      | 18/50 [00:21<00:31,  1.02it/s] 38%|███▊      | 19/50 [00:23<00:30,  1.02it/s] 38%|███▊      | 19/50 [00:21<00:30,  1.03it/s] 38%|███▊      | 19/50 [00:24<00:30,  1.02it/s] 38%|███▊      | 19/50 [00:22<00:30,  1.02it/s] 40%|████      | 20/50 [00:24<00:29,  1.03it/s] 40%|████      | 20/50 [00:22<00:29,  1.03it/s] 40%|████      | 20/50 [00:25<00:29,  1.03it/s] 40%|████      | 20/50 [00:23<00:29,  1.03it/s] 42%|████▏     | 21/50 [00:23<00:28,  1.03it/s] 42%|████▏     | 21/50 [00:25<00:28,  1.03it/s] 42%|████▏     | 21/50 [00:26<00:28,  1.03it/s] 42%|████▏     | 21/50 [00:24<00:28,  1.03it/s] 44%|████▍     | 22/50 [00:24<00:27,  1.03it/s] 44%|████▍     | 22/50 [00:26<00:27,  1.03it/s] 44%|████▍     | 22/50 [00:27<00:27,  1.03it/s] 44%|████▍     | 22/50 [00:25<00:27,  1.03it/s] 46%|████▌     | 23/50 [00:27<00:26,  1.03it/s] 46%|████▌     | 23/50 [00:25<00:26,  1.03it/s] 46%|████▌     | 23/50 [00:28<00:26,  1.03it/s] 46%|████▌     | 23/50 [00:26<00:26,  1.03it/s] 48%|████▊     | 24/50 [00:25<00:25,  1.03it/s] 48%|████▊     | 24/50 [00:28<00:25,  1.03it/s] 48%|████▊     | 24/50 [00:29<00:25,  1.03it/s] 48%|████▊     | 24/50 [00:27<00:25,  1.03it/s] 50%|█████     | 25/50 [00:26<00:24,  1.03it/s] 50%|█████     | 25/50 [00:29<00:24,  1.03it/s] 50%|█████     | 25/50 [00:30<00:24,  1.03it/s] 50%|█████     | 25/50 [00:28<00:24,  1.03it/s] 52%|█████▏    | 26/50 [00:27<00:23,  1.03it/s] 52%|█████▏    | 26/50 [00:30<00:23,  1.03it/s] 52%|█████▏    | 26/50 [00:31<00:23,  1.03it/s] 52%|█████▏    | 26/50 [00:29<00:23,  1.03it/s] 54%|█████▍    | 27/50 [00:28<00:22,  1.03it/s] 54%|█████▍    | 27/50 [00:31<00:22,  1.03it/s] 54%|█████▍    | 27/50 [00:32<00:22,  1.03it/s] 54%|█████▍    | 27/50 [00:30<00:22,  1.03it/s] 56%|█████▌    | 28/50 [00:29<00:21,  1.03it/s] 56%|█████▌    | 28/50 [00:32<00:21,  1.03it/s] 56%|█████▌    | 28/50 [00:33<00:21,  1.03it/s] 56%|█████▌    | 28/50 [00:31<00:21,  1.03it/s] 58%|█████▊    | 29/50 [00:30<00:20,  1.03it/s] 58%|█████▊    | 29/50 [00:33<00:20,  1.03it/s] 58%|█████▊    | 29/50 [00:34<00:20,  1.03it/s] 58%|█████▊    | 29/50 [00:32<00:20,  1.03it/s] 60%|██████    | 30/50 [00:31<00:19,  1.03it/s] 60%|██████    | 30/50 [00:34<00:19,  1.03it/s] 60%|██████    | 30/50 [00:35<00:19,  1.03it/s] 60%|██████    | 30/50 [00:33<00:19,  1.03it/s] 62%|██████▏   | 31/50 [00:32<00:18,  1.03it/s] 62%|██████▏   | 31/50 [00:35<00:18,  1.03it/s] 62%|██████▏   | 31/50 [00:36<00:18,  1.03it/s] 62%|██████▏   | 31/50 [00:34<00:18,  1.03it/s] 64%|██████▍   | 32/50 [00:33<00:17,  1.03it/s] 64%|██████▍   | 32/50 [00:36<00:17,  1.03it/s] 64%|██████▍   | 32/50 [00:37<00:17,  1.03it/s] 64%|██████▍   | 32/50 [00:35<00:17,  1.03it/s] 66%|██████▌   | 33/50 [00:37<00:16,  1.03it/s] 66%|██████▌   | 33/50 [00:34<00:16,  1.03it/s] 66%|██████▌   | 33/50 [00:38<00:16,  1.03it/s] 66%|██████▌   | 33/50 [00:36<00:16,  1.03it/s] 68%|██████▊   | 34/50 [00:35<00:15,  1.03it/s] 68%|██████▊   | 34/50 [00:38<00:15,  1.03it/s] 68%|██████▊   | 34/50 [00:39<00:15,  1.03it/s] 68%|██████▊   | 34/50 [00:37<00:15,  1.03it/s] 70%|███████   | 35/50 [00:38<00:14,  1.03it/s] 70%|███████   | 35/50 [00:36<00:14,  1.03it/s] 70%|███████   | 35/50 [00:40<00:14,  1.03it/s] 70%|███████   | 35/50 [00:38<00:14,  1.03it/s] 72%|███████▏  | 36/50 [00:37<00:13,  1.03it/s] 72%|███████▏  | 36/50 [00:39<00:13,  1.03it/s] 72%|███████▏  | 36/50 [00:41<00:13,  1.03it/s] 72%|███████▏  | 36/50 [00:39<00:13,  1.03it/s] 74%|███████▍  | 37/50 [00:38<00:12,  1.03it/s] 74%|███████▍  | 37/50 [00:40<00:12,  1.03it/s] 74%|███████▍  | 37/50 [00:42<00:12,  1.03it/s] 74%|███████▍  | 37/50 [00:40<00:12,  1.03it/s] 76%|███████▌  | 38/50 [00:41<00:11,  1.03it/s] 76%|███████▌  | 38/50 [00:39<00:11,  1.03it/s] 76%|███████▌  | 38/50 [00:43<00:11,  1.03it/s] 76%|███████▌  | 38/50 [00:41<00:11,  1.03it/s] 78%|███████▊  | 39/50 [00:40<00:10,  1.03it/s] 78%|███████▊  | 39/50 [00:42<00:10,  1.03it/s] 78%|███████▊  | 39/50 [00:44<00:10,  1.03it/s] 78%|███████▊  | 39/50 [00:42<00:10,  1.03it/s] 80%|████████  | 40/50 [00:41<00:09,  1.03it/s] 80%|████████  | 40/50 [00:43<00:09,  1.03it/s] 80%|████████  | 40/50 [00:45<00:09,  1.03it/s] 80%|████████  | 40/50 [00:43<00:09,  1.03it/s] 82%|████████▏ | 41/50 [00:44<00:08,  1.03it/s] 82%|████████▏ | 41/50 [00:42<00:08,  1.03it/s] 82%|████████▏ | 41/50 [00:46<00:08,  1.03it/s] 82%|████████▏ | 41/50 [00:44<00:08,  1.03it/s] 84%|████████▍ | 42/50 [00:43<00:07,  1.03it/s] 84%|████████▍ | 42/50 [00:45<00:07,  1.03it/s] 84%|████████▍ | 42/50 [00:47<00:07,  1.03it/s] 84%|████████▍ | 42/50 [00:45<00:07,  1.03it/s] 86%|████████▌ | 43/50 [00:44<00:06,  1.03it/s] 86%|████████▌ | 43/50 [00:48<00:06,  1.03it/s] 86%|████████▌ | 43/50 [00:46<00:06,  1.03it/s] 86%|████████▌ | 43/50 [00:46<00:06,  1.03it/s] 88%|████████▊ | 44/50 [00:47<00:05,  1.03it/s] 88%|████████▊ | 44/50 [00:45<00:05,  1.03it/s] 88%|████████▊ | 44/50 [00:48<00:05,  1.03it/s] 88%|████████▊ | 44/50 [00:47<00:05,  1.03it/s] 90%|█████████ | 45/50 [00:46<00:04,  1.03it/s] 90%|█████████ | 45/50 [00:49<00:04,  1.03it/s] 90%|█████████ | 45/50 [00:48<00:04,  1.03it/s] 90%|█████████ | 45/50 [00:48<00:04,  1.03it/s] 92%|█████████▏| 46/50 [00:49<00:03,  1.03it/s] 92%|█████████▏| 46/50 [00:47<00:03,  1.03it/s] 92%|█████████▏| 46/50 [00:50<00:03,  1.03it/s] 92%|█████████▏| 46/50 [00:49<00:03,  1.03it/s] 94%|█████████▍| 47/50 [00:48<00:02,  1.03it/s] 94%|█████████▍| 47/50 [00:50<00:02,  1.03it/s] 94%|█████████▍| 47/50 [00:51<00:02,  1.03it/s] 94%|█████████▍| 47/50 [00:50<00:02,  1.03it/s] 96%|█████████▌| 48/50 [00:49<00:01,  1.03it/s] 96%|█████████▌| 48/50 [00:51<00:01,  1.03it/s] 96%|█████████▌| 48/50 [00:52<00:01,  1.03it/s] 96%|█████████▌| 48/50 [00:51<00:01,  1.03it/s] 98%|█████████▊| 49/50 [00:50<00:00,  1.03it/s] 98%|█████████▊| 49/50 [00:53<00:00,  1.03it/s] 98%|█████████▊| 49/50 [00:52<00:00,  1.03it/s] 98%|█████████▊| 49/50 [00:52<00:00,  1.03it/s]100%|██████████| 50/50 [00:51<00:00,  1.03it/s]100%|██████████| 50/50 [00:53<00:00,  1.03it/s]100%|██████████| 50/50 [00:51<00:00,  1.02s/it]
代码执行时间: 51.25 秒100%|██████████| 50/50 [00:53<00:00,  1.07s/it]

代码执行时间: 53.58 秒
100%|██████████| 50/50 [00:54<00:00,  1.03it/s]100%|██████████| 50/50 [00:54<00:00,  1.10s/it]
代码执行时间: 54.81 秒
100%|██████████| 50/50 [00:53<00:00,  1.03it/s]100%|██████████| 50/50 [00:53<00:00,  1.06s/it]
代码执行时间: 53.03 秒
2025-03-07 23:53:56.857 | INFO     | hyvideo.inference:predict:669 - Success, time: 61.51665282249451
2025-03-07 23:53:56.918 | INFO     | hyvideo.inference:predict:669 - Success, time: 62.062384366989136
2025-03-07 23:53:56.951 | INFO     | hyvideo.inference:predict:669 - Success, time: 60.09984230995178
2025-03-07 23:53:56.999 | INFO     | hyvideo.inference:predict:669 - Success, time: 63.38263750076294
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-07 23:53:58.785 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0307 23:54:03.357000 139772449994560 torch/distributed/run.py:779] 
W0307 23:54:03.357000 139772449994560 torch/distributed/run.py:779] *****************************************
W0307 23:54:03.357000 139772449994560 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0307 23:54:03.357000 139772449994560 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=2, ring_degree=1)
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=2, ring_degree=1)
2025-03-07 23:54:10.604 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
2025-03-07 23:54:10.604 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-07 23:54:10 [parallel_state.py:200] world_size=2 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
DEBUG 03-07 23:54:10 [parallel_state.py:200] world_size=2 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-07 23:54:10.641 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:54:10.641 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:54:11.237 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:54:11.263 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:54:37.232 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-07 23:54:37.275 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:54:39.092 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:54:39.125 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:54:39.207 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:54:39.232 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.58s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.62s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.65s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.58s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.22s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.72s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.74s/it]
2025-03-07 23:54:57.442 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:54:57.577 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:54:59.936 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:54:59.999 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:55:00.271 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:55:00.332 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:55:00.419 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:55:00.459 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:55:00.478 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:55:00.516 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:55:00.526 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:55:00.543 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-07 23:55:00.581 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:55:00.598 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:04<03:55,  4.81s/it]  2%|▏         | 1/50 [00:04<03:55,  4.81s/it]  4%|▍         | 2/50 [00:06<02:29,  3.11s/it]  4%|▍         | 2/50 [00:06<02:29,  3.12s/it]  6%|▌         | 3/50 [00:08<02:00,  2.57s/it]  6%|▌         | 3/50 [00:08<02:01,  2.58s/it]  8%|▊         | 4/50 [00:10<01:46,  2.31s/it]  8%|▊         | 4/50 [00:10<01:46,  2.32s/it] 10%|█         | 5/50 [00:12<01:37,  2.17s/it] 10%|█         | 5/50 [00:12<01:37,  2.18s/it] 12%|█▏        | 6/50 [00:14<01:31,  2.09s/it] 12%|█▏        | 6/50 [00:14<01:32,  2.09s/it] 14%|█▍        | 7/50 [00:16<01:27,  2.04s/it] 14%|█▍        | 7/50 [00:16<01:27,  2.04s/it] 16%|█▌        | 8/50 [00:18<01:23,  1.99s/it] 16%|█▌        | 8/50 [00:18<01:23,  1.99s/it] 18%|█▊        | 9/50 [00:20<01:20,  1.95s/it] 18%|█▊        | 9/50 [00:20<01:20,  1.96s/it] 20%|██        | 10/50 [00:21<01:17,  1.93s/it] 20%|██        | 10/50 [00:22<01:17,  1.93s/it] 22%|██▏       | 11/50 [00:23<01:14,  1.91s/it] 22%|██▏       | 11/50 [00:23<01:14,  1.91s/it] 24%|██▍       | 12/50 [00:25<01:12,  1.90s/it] 24%|██▍       | 12/50 [00:25<01:12,  1.90s/it] 26%|██▌       | 13/50 [00:27<01:09,  1.89s/it] 26%|██▌       | 13/50 [00:27<01:09,  1.89s/it] 28%|██▊       | 14/50 [00:29<01:07,  1.88s/it] 28%|██▊       | 14/50 [00:29<01:07,  1.88s/it] 30%|███       | 15/50 [00:31<01:05,  1.88s/it] 30%|███       | 15/50 [00:31<01:05,  1.88s/it] 32%|███▏      | 16/50 [00:33<01:03,  1.87s/it] 32%|███▏      | 16/50 [00:33<01:03,  1.87s/it] 34%|███▍      | 17/50 [00:35<01:01,  1.87s/it] 34%|███▍      | 17/50 [00:35<01:01,  1.87s/it] 36%|███▌      | 18/50 [00:36<00:59,  1.87s/it] 36%|███▌      | 18/50 [00:36<00:59,  1.87s/it] 38%|███▊      | 19/50 [00:38<00:57,  1.87s/it] 38%|███▊      | 19/50 [00:38<00:57,  1.87s/it] 40%|████      | 20/50 [00:40<00:56,  1.87s/it] 40%|████      | 20/50 [00:40<00:56,  1.87s/it] 42%|████▏     | 21/50 [00:42<00:54,  1.87s/it] 42%|████▏     | 21/50 [00:42<00:54,  1.87s/it] 44%|████▍     | 22/50 [00:44<00:52,  1.87s/it] 44%|████▍     | 22/50 [00:44<00:52,  1.87s/it] 46%|████▌     | 23/50 [00:46<00:50,  1.87s/it] 46%|████▌     | 23/50 [00:46<00:50,  1.87s/it] 48%|████▊     | 24/50 [00:48<00:48,  1.87s/it] 48%|████▊     | 24/50 [00:48<00:48,  1.87s/it] 50%|█████     | 25/50 [00:50<00:46,  1.87s/it] 50%|█████     | 25/50 [00:50<00:46,  1.87s/it] 52%|█████▏    | 26/50 [00:51<00:44,  1.87s/it] 52%|█████▏    | 26/50 [00:51<00:44,  1.87s/it] 54%|█████▍    | 27/50 [00:53<00:42,  1.87s/it] 54%|█████▍    | 27/50 [00:53<00:42,  1.87s/it] 56%|█████▌    | 28/50 [00:55<00:41,  1.87s/it] 56%|█████▌    | 28/50 [00:55<00:41,  1.87s/it] 58%|█████▊    | 29/50 [00:57<00:39,  1.86s/it] 58%|█████▊    | 29/50 [00:57<00:39,  1.86s/it] 60%|██████    | 30/50 [00:59<00:37,  1.86s/it] 60%|██████    | 30/50 [00:59<00:37,  1.86s/it] 62%|██████▏   | 31/50 [01:01<00:35,  1.86s/it] 62%|██████▏   | 31/50 [01:01<00:35,  1.86s/it] 64%|██████▍   | 32/50 [01:03<00:33,  1.86s/it] 64%|██████▍   | 32/50 [01:03<00:33,  1.86s/it] 66%|██████▌   | 33/50 [01:04<00:31,  1.87s/it] 66%|██████▌   | 33/50 [01:04<00:31,  1.87s/it] 68%|██████▊   | 34/50 [01:06<00:29,  1.87s/it] 68%|██████▊   | 34/50 [01:06<00:29,  1.87s/it] 70%|███████   | 35/50 [01:08<00:27,  1.87s/it] 70%|███████   | 35/50 [01:08<00:27,  1.87s/it] 72%|███████▏  | 36/50 [01:10<00:26,  1.86s/it] 72%|███████▏  | 36/50 [01:10<00:26,  1.86s/it] 74%|███████▍  | 37/50 [01:12<00:24,  1.86s/it] 74%|███████▍  | 37/50 [01:12<00:24,  1.86s/it] 76%|███████▌  | 38/50 [01:14<00:22,  1.86s/it] 76%|███████▌  | 38/50 [01:14<00:22,  1.86s/it] 78%|███████▊  | 39/50 [01:16<00:20,  1.86s/it] 78%|███████▊  | 39/50 [01:16<00:20,  1.86s/it] 80%|████████  | 40/50 [01:17<00:18,  1.86s/it] 80%|████████  | 40/50 [01:17<00:18,  1.86s/it] 82%|████████▏ | 41/50 [01:19<00:16,  1.86s/it] 82%|████████▏ | 41/50 [01:19<00:16,  1.86s/it] 84%|████████▍ | 42/50 [01:21<00:14,  1.86s/it] 84%|████████▍ | 42/50 [01:21<00:14,  1.86s/it] 86%|████████▌ | 43/50 [01:23<00:13,  1.86s/it] 86%|████████▌ | 43/50 [01:23<00:13,  1.86s/it] 88%|████████▊ | 44/50 [01:25<00:11,  1.86s/it] 88%|████████▊ | 44/50 [01:25<00:11,  1.86s/it] 90%|█████████ | 45/50 [01:27<00:09,  1.86s/it] 90%|█████████ | 45/50 [01:27<00:09,  1.86s/it] 92%|█████████▏| 46/50 [01:29<00:07,  1.86s/it] 92%|█████████▏| 46/50 [01:29<00:07,  1.86s/it] 94%|█████████▍| 47/50 [01:31<00:05,  1.86s/it] 94%|█████████▍| 47/50 [01:31<00:05,  1.86s/it] 96%|█████████▌| 48/50 [01:32<00:03,  1.86s/it] 96%|█████████▌| 48/50 [01:32<00:03,  1.86s/it] 98%|█████████▊| 49/50 [01:34<00:01,  1.86s/it] 98%|█████████▊| 49/50 [01:34<00:01,  1.86s/it]100%|██████████| 50/50 [01:36<00:00,  1.86s/it]100%|██████████| 50/50 [01:36<00:00,  1.93s/it]
代码执行时间: 96.60 秒
100%|██████████| 50/50 [01:36<00:00,  1.86s/it]100%|██████████| 50/50 [01:36<00:00,  1.93s/it]
代码执行时间: 96.63 秒
2025-03-07 23:56:45.479 | INFO     | hyvideo.inference:predict:669 - Success, time: 104.88169693946838
2025-03-07 23:56:45.558 | INFO     | hyvideo.inference:predict:669 - Success, time: 105.0151252746582
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-07 23:56:47.362 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=129, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=1, ring_degree=1)
2025-03-07 23:56:58.658 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
2025-03-07 23:56:58.659 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-07 23:56:59.062 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-07 23:57:21.093 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-07 23:57:22.792 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-07 23:57:22.919 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.03it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.03it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.06it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.55it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.31it/s]
2025-03-07 23:57:29.975 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:57:34.000 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-07 23:57:34.336 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:57:34.427 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-07 23:57:34.467 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-07 23:57:34.537 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 129)
2025-03-07 23:57:34.557 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 129
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 30360
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:03<03:10,  3.88s/it]  4%|▍         | 2/50 [00:07<02:53,  3.62s/it]  6%|▌         | 3/50 [00:10<02:47,  3.57s/it]  8%|▊         | 4/50 [00:14<02:42,  3.54s/it] 10%|█         | 5/50 [00:17<02:38,  3.52s/it] 12%|█▏        | 6/50 [00:21<02:34,  3.51s/it] 14%|█▍        | 7/50 [00:24<02:30,  3.51s/it] 16%|█▌        | 8/50 [00:28<02:27,  3.50s/it] 18%|█▊        | 9/50 [00:31<02:21,  3.46s/it] 20%|██        | 10/50 [00:35<02:17,  3.43s/it] 22%|██▏       | 11/50 [00:38<02:12,  3.41s/it] 24%|██▍       | 12/50 [00:41<02:08,  3.39s/it] 26%|██▌       | 13/50 [00:45<02:05,  3.38s/it] 28%|██▊       | 14/50 [00:48<02:01,  3.38s/it] 30%|███       | 15/50 [00:51<01:58,  3.38s/it] 32%|███▏      | 16/50 [00:55<01:54,  3.37s/it] 34%|███▍      | 17/50 [00:58<01:51,  3.37s/it] 36%|███▌      | 18/50 [01:01<01:47,  3.37s/it] 38%|███▊      | 19/50 [01:05<01:44,  3.37s/it] 40%|████      | 20/50 [01:08<01:40,  3.37s/it] 42%|████▏     | 21/50 [01:12<01:37,  3.37s/it] 44%|████▍     | 22/50 [01:15<01:34,  3.36s/it] 46%|████▌     | 23/50 [01:18<01:30,  3.36s/it] 48%|████▊     | 24/50 [01:22<01:27,  3.36s/it] 50%|█████     | 25/50 [01:25<01:24,  3.36s/it] 52%|█████▏    | 26/50 [01:28<01:20,  3.36s/it] 54%|█████▍    | 27/50 [01:32<01:17,  3.36s/it] 56%|█████▌    | 28/50 [01:35<01:13,  3.36s/it] 58%|█████▊    | 29/50 [01:38<01:10,  3.36s/it] 60%|██████    | 30/50 [01:42<01:07,  3.36s/it] 62%|██████▏   | 31/50 [01:45<01:03,  3.36s/it] 64%|██████▍   | 32/50 [01:48<01:00,  3.36s/it] 66%|██████▌   | 33/50 [01:52<00:57,  3.36s/it] 68%|██████▊   | 34/50 [01:55<00:53,  3.36s/it] 70%|███████   | 35/50 [01:59<00:50,  3.36s/it] 72%|███████▏  | 36/50 [02:02<00:46,  3.36s/it] 74%|███████▍  | 37/50 [02:05<00:43,  3.36s/it] 76%|███████▌  | 38/50 [02:09<00:40,  3.36s/it] 78%|███████▊  | 39/50 [02:12<00:36,  3.36s/it] 80%|████████  | 40/50 [02:15<00:33,  3.36s/it] 82%|████████▏ | 41/50 [02:19<00:30,  3.35s/it] 84%|████████▍ | 42/50 [02:22<00:26,  3.35s/it] 86%|████████▌ | 43/50 [02:25<00:23,  3.35s/it] 88%|████████▊ | 44/50 [02:29<00:20,  3.36s/it] 90%|█████████ | 45/50 [02:32<00:16,  3.35s/it] 92%|█████████▏| 46/50 [02:35<00:13,  3.35s/it] 94%|█████████▍| 47/50 [02:39<00:10,  3.35s/it] 96%|█████████▌| 48/50 [02:42<00:06,  3.35s/it] 98%|█████████▊| 49/50 [02:46<00:03,  3.35s/it]100%|██████████| 50/50 [02:49<00:00,  3.35s/it]100%|██████████| 50/50 [02:49<00:00,  3.39s/it]
代码执行时间: 169.37 秒
2025-03-08 00:00:32.375 | INFO     | hyvideo.inference:predict:669 - Success, time: 177.81806707382202
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-08 00:00:34.130 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0308 00:00:38.463000 139729674929984 torch/distributed/run.py:779] 
W0308 00:00:38.463000 139729674929984 torch/distributed/run.py:779] *****************************************
W0308 00:00:38.463000 139729674929984 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0308 00:00:38.463000 139729674929984 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-08 00:00:48.417 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:00:48 [parallel_state.py:200] world_size=8 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-08 00:00:48.474 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:00:48 [parallel_state.py:200] world_size=8 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-08 00:00:48.483 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:00:48 [parallel_state.py:200] world_size=8 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-08 00:00:48.494 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-08 00:00:48.498 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:00:48 [parallel_state.py:200] world_size=8 rank=7 local_rank=-1 distributed_init_method=env:// backend=nccl
DEBUG 03-08 00:00:48 [parallel_state.py:200] world_size=8 rank=5 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-08 00:00:48.528 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:00:48 [parallel_state.py:200] world_size=8 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-08 00:00:48.543 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=8, ring_degree=1)
2025-03-08 00:00:48.544 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:00:48 [parallel_state.py:200] world_size=8 rank=4 local_rank=-1 distributed_init_method=env:// backend=nccl
DEBUG 03-08 00:00:48 [parallel_state.py:200] world_size=8 rank=6 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-08 00:00:48.630 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:00:48.637 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:00:48.637 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:00:48.637 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:00:48.638 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:00:48.638 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:00:48.638 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:00:48.638 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:00:51.633 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:00:51.681 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:00:51.898 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:00:51.921 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:00:51.931 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:00:51.932 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:00:51.936 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:00:51.944 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:01:15.132 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-08 00:01:15.358 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-08 00:01:15.860 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-08 00:01:16.079 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-08 00:01:16.248 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-08 00:01:16.307 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-08 00:01:16.379 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-08 00:01:16.446 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-08 00:01:17.244 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-08 00:01:17.374 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-08 00:01:18.031 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-08 00:01:18.164 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:18.195 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-08 00:01:18.258 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-08 00:01:18.332 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-08 00:01:18.402 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:18.614 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-08 00:01:18.728 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:18.796 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-08 00:01:18.948 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:19.156 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-08 00:01:19.326 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:19.361 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-08 00:01:19.518 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  4.00s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.91s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.94s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.71s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.93s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.01s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.30s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.29s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.99s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.94s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.77s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.95s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.94s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.99s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.92s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.46s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.01s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.67s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.89s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.28s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.80s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.27s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.44s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.98s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.25s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.88s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.43s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.98s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.88s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.42s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.97s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  2.92s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.64s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:15<00:05,  5.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.21s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.95s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:15<00:05,  5.22s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.26s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.99s/it]
2025-03-08 00:01:37.258 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:38.101 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:38.511 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:38.853 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:39.231 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:39.482 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:39.799 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:39.999 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:40.037 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:40.100 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:01:40.108 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-08 00:01:40.716 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-08 00:01:41.282 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:41.587 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:41.670 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:41.852 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:41.900 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:41.967 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:41.972 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:01:41.981 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-08 00:01:42.061 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:42.130 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:42.174 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:42.244 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:01:42.252 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-08 00:01:42.419 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:42.439 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-08 00:01:42.591 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:42.646 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:42.714 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:01:42.722 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-08 00:01:42.778 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-08 00:01:42.928 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:42.968 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:43.035 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:01:43.044 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-08 00:01:43.843 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:44.163 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-08 00:01:44.205 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:44.361 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:44.476 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:44.625 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:01:44.637 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-08 00:01:44.848 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-08 00:01:47.837 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:48.169 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:01:48.181 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:48.330 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:48.369 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:48.436 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:01:48.444 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-08 00:01:48.503 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:48.651 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:01:48.691 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:01:48.757 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:01:48.764 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:06<05:17,  6.47s/it]  2%|▏         | 1/50 [00:10<08:14, 10.10s/it]  2%|▏         | 1/50 [00:11<09:10, 11.23s/it]  2%|▏         | 1/50 [00:12<10:13, 12.51s/it]  2%|▏         | 1/50 [00:14<11:58, 14.66s/it]  2%|▏         | 1/50 [00:06<04:57,  6.07s/it]  2%|▏         | 1/50 [00:11<09:34, 11.73s/it]  2%|▏         | 1/50 [00:12<10:35, 12.97s/it]  4%|▍         | 2/50 [00:06<02:07,  2.67s/it]  4%|▍         | 2/50 [00:12<03:59,  4.99s/it]  4%|▍         | 2/50 [00:06<02:16,  2.85s/it]  4%|▍         | 2/50 [00:11<03:50,  4.81s/it]  4%|▍         | 2/50 [00:10<03:28,  4.34s/it]  4%|▍         | 2/50 [00:14<04:57,  6.21s/it]  4%|▍         | 2/50 [00:12<04:15,  5.33s/it]  4%|▍         | 2/50 [00:13<04:24,  5.51s/it]  6%|▌         | 3/50 [00:06<01:13,  1.57s/it]  6%|▌         | 3/50 [00:07<01:18,  1.67s/it]  6%|▌         | 3/50 [00:11<02:08,  2.73s/it]  6%|▌         | 3/50 [00:13<02:21,  3.02s/it]  6%|▌         | 3/50 [00:10<01:56,  2.48s/it]  6%|▌         | 3/50 [00:12<02:13,  2.83s/it]  6%|▌         | 3/50 [00:13<02:26,  3.11s/it]  6%|▌         | 3/50 [00:15<02:44,  3.49s/it]  8%|▊         | 4/50 [00:06<00:47,  1.04s/it]  8%|▊         | 4/50 [00:12<01:23,  1.81s/it]  8%|▊         | 4/50 [00:07<00:50,  1.10s/it]  8%|▊         | 4/50 [00:12<01:20,  1.74s/it]  8%|▊         | 4/50 [00:13<01:28,  1.92s/it]  8%|▊         | 4/50 [00:10<01:13,  1.59s/it]  8%|▊         | 4/50 [00:15<01:41,  2.20s/it]  8%|▊         | 4/50 [00:13<01:30,  1.97s/it] 10%|█         | 5/50 [00:07<00:33,  1.34it/s] 10%|█         | 5/50 [00:07<00:35,  1.28it/s] 10%|█         | 5/50 [00:12<00:55,  1.23s/it] 10%|█         | 5/50 [00:11<00:49,  1.10s/it] 10%|█         | 5/50 [00:13<00:58,  1.31s/it] 10%|█         | 5/50 [00:15<01:07,  1.49s/it] 10%|█         | 5/50 [00:12<00:53,  1.20s/it] 10%|█         | 5/50 [00:13<01:00,  1.34s/it] 12%|█▏        | 6/50 [00:07<00:24,  1.76it/s] 12%|█▏        | 6/50 [00:12<00:39,  1.12it/s] 12%|█▏        | 6/50 [00:07<00:26,  1.69it/s] 12%|█▏        | 6/50 [00:11<00:35,  1.25it/s] 12%|█▏        | 6/50 [00:12<00:38,  1.16it/s] 12%|█▏        | 6/50 [00:13<00:41,  1.07it/s] 12%|█▏        | 6/50 [00:15<00:46,  1.06s/it] 12%|█▏        | 6/50 [00:14<00:42,  1.04it/s] 14%|█▍        | 7/50 [00:13<00:28,  1.48it/s] 14%|█▍        | 7/50 [00:07<00:19,  2.19it/s] 14%|█▍        | 7/50 [00:07<00:20,  2.11it/s] 14%|█▍        | 7/50 [00:11<00:26,  1.63it/s] 14%|█▍        | 7/50 [00:12<00:28,  1.52it/s] 14%|█▍        | 7/50 [00:13<00:30,  1.42it/s] 14%|█▍        | 7/50 [00:16<00:33,  1.27it/s] 14%|█▍        | 7/50 [00:14<00:31,  1.39it/s] 16%|█▌        | 8/50 [00:07<00:16,  2.62it/s] 16%|█▌        | 8/50 [00:13<00:22,  1.89it/s] 16%|█▌        | 8/50 [00:08<00:16,  2.54it/s] 16%|█▌        | 8/50 [00:14<00:23,  1.81it/s] 16%|█▌        | 8/50 [00:12<00:21,  1.93it/s] 16%|█▌        | 8/50 [00:16<00:25,  1.65it/s] 16%|█▌        | 8/50 [00:11<00:20,  2.04it/s] 16%|█▌        | 8/50 [00:14<00:23,  1.78it/s] 18%|█▊        | 9/50 [00:13<00:17,  2.30it/s] 18%|█▊        | 9/50 [00:07<00:13,  3.01it/s] 18%|█▊        | 9/50 [00:08<00:13,  2.94it/s] 18%|█▊        | 9/50 [00:14<00:18,  2.23it/s] 18%|█▊        | 9/50 [00:13<00:17,  2.35it/s] 18%|█▊        | 9/50 [00:12<00:16,  2.47it/s] 18%|█▊        | 9/50 [00:16<00:19,  2.05it/s] 18%|█▊        | 9/50 [00:14<00:18,  2.19it/s] 20%|██        | 10/50 [00:08<00:11,  3.35it/s] 20%|██        | 10/50 [00:08<00:12,  3.29it/s] 20%|██        | 10/50 [00:13<00:14,  2.71it/s] 20%|██        | 10/50 [00:13<00:14,  2.75it/s] 20%|██        | 10/50 [00:14<00:15,  2.64it/s] 20%|██        | 10/50 [00:12<00:13,  2.87it/s] 20%|██        | 10/50 [00:16<00:16,  2.47it/s] 20%|██        | 10/50 [00:15<00:15,  2.60it/s] 22%|██▏       | 11/50 [00:14<00:12,  3.10it/s] 22%|██▏       | 11/50 [00:08<00:10,  3.65it/s] 22%|██▏       | 11/50 [00:08<00:10,  3.60it/s] 22%|██▏       | 11/50 [00:13<00:12,  3.14it/s] 22%|██▏       | 11/50 [00:12<00:12,  3.24it/s] 22%|██▏       | 11/50 [00:14<00:12,  3.03it/s] 22%|██▏       | 11/50 [00:16<00:13,  2.87it/s] 22%|██▏       | 11/50 [00:15<00:13,  3.00it/s] 24%|██▍       | 12/50 [00:08<00:09,  3.88it/s] 24%|██▍       | 12/50 [00:09<00:09,  3.84it/s] 24%|██▍       | 12/50 [00:14<00:11,  3.43it/s] 24%|██▍       | 12/50 [00:12<00:10,  3.54it/s] 24%|██▍       | 12/50 [00:13<00:10,  3.46it/s] 24%|██▍       | 12/50 [00:17<00:11,  3.23it/s] 24%|██▍       | 12/50 [00:15<00:11,  3.37it/s] 24%|██▍       | 12/50 [00:15<00:11,  3.34it/s] 26%|██▌       | 13/50 [00:08<00:09,  4.05it/s] 26%|██▌       | 13/50 [00:14<00:10,  3.69it/s] 26%|██▌       | 13/50 [00:09<00:09,  4.02it/s] 26%|██▌       | 13/50 [00:15<00:10,  3.65it/s] 26%|██▌       | 13/50 [00:14<00:09,  3.72it/s] 26%|██▌       | 13/50 [00:12<00:09,  3.78it/s] 26%|██▌       | 13/50 [00:17<00:10,  3.53it/s] 26%|██▌       | 13/50 [00:15<00:10,  3.62it/s] 28%|██▊       | 14/50 [00:14<00:09,  3.91it/s] 28%|██▊       | 14/50 [00:09<00:08,  4.18it/s] 28%|██▊       | 14/50 [00:09<00:08,  4.16it/s] 28%|██▊       | 14/50 [00:15<00:09,  3.87it/s] 28%|██▊       | 14/50 [00:14<00:09,  3.93it/s] 28%|██▊       | 14/50 [00:13<00:09,  3.98it/s] 28%|██▊       | 14/50 [00:17<00:09,  3.78it/s] 28%|██▊       | 14/50 [00:15<00:09,  3.86it/s] 30%|███       | 15/50 [00:14<00:08,  4.09it/s] 30%|███       | 15/50 [00:09<00:08,  4.27it/s] 30%|███       | 15/50 [00:09<00:08,  4.29it/s] 30%|███       | 15/50 [00:14<00:08,  4.10it/s] 30%|███       | 15/50 [00:15<00:08,  4.06it/s] 30%|███       | 15/50 [00:13<00:08,  4.14it/s] 30%|███       | 15/50 [00:17<00:08,  3.99it/s] 30%|███       | 15/50 [00:16<00:08,  4.05it/s] 32%|███▏      | 16/50 [00:15<00:08,  4.21it/s] 32%|███▏      | 16/50 [00:09<00:07,  4.36it/s] 32%|███▏      | 16/50 [00:09<00:07,  4.35it/s] 32%|███▏      | 16/50 [00:15<00:08,  4.19it/s] 32%|███▏      | 16/50 [00:18<00:08,  4.14it/s] 32%|███▏      | 16/50 [00:14<00:08,  4.23it/s] 32%|███▏      | 16/50 [00:13<00:07,  4.26it/s] 32%|███▏      | 16/50 [00:16<00:08,  4.18it/s] 34%|███▍      | 17/50 [00:10<00:07,  4.41it/s] 34%|███▍      | 17/50 [00:15<00:07,  4.31it/s] 34%|███▍      | 17/50 [00:09<00:07,  4.42it/s] 34%|███▍      | 17/50 [00:16<00:07,  4.30it/s] 34%|███▍      | 17/50 [00:18<00:07,  4.26it/s] 34%|███▍      | 17/50 [00:14<00:07,  4.32it/s] 34%|███▍      | 17/50 [00:13<00:07,  4.34it/s] 34%|███▍      | 17/50 [00:16<00:07,  4.29it/s] 36%|███▌      | 18/50 [00:15<00:07,  4.38it/s] 36%|███▌      | 18/50 [00:09<00:07,  4.46it/s] 36%|███▌      | 18/50 [00:10<00:07,  4.46it/s] 36%|███▌      | 18/50 [00:16<00:07,  4.37it/s] 36%|███▌      | 18/50 [00:15<00:07,  4.39it/s] 36%|███▌      | 18/50 [00:18<00:07,  4.35it/s] 36%|███▌      | 18/50 [00:14<00:07,  4.41it/s] 36%|███▌      | 18/50 [00:16<00:07,  4.37it/s] 38%|███▊      | 19/50 [00:10<00:06,  4.49it/s] 38%|███▊      | 19/50 [00:10<00:06,  4.49it/s] 38%|███▊      | 19/50 [00:15<00:06,  4.44it/s] 38%|███▊      | 19/50 [00:16<00:06,  4.43it/s] 38%|███▊      | 19/50 [00:14<00:06,  4.45it/s] 38%|███▊      | 19/50 [00:15<00:06,  4.44it/s] 38%|███▊      | 19/50 [00:18<00:07,  4.41it/s] 38%|███▊      | 19/50 [00:17<00:07,  4.43it/s] 40%|████      | 20/50 [00:10<00:06,  4.49it/s] 40%|████      | 20/50 [00:16<00:06,  4.46it/s] 40%|████      | 20/50 [00:10<00:06,  4.49it/s] 40%|████      | 20/50 [00:15<00:06,  4.46it/s] 40%|████      | 20/50 [00:14<00:06,  4.47it/s] 40%|████      | 20/50 [00:18<00:06,  4.43it/s] 40%|████      | 20/50 [00:16<00:06,  4.45it/s] 40%|████      | 20/50 [00:17<00:06,  4.45it/s] 42%|████▏     | 21/50 [00:10<00:06,  4.51it/s] 42%|████▏     | 21/50 [00:16<00:06,  4.49it/s] 42%|████▏     | 21/50 [00:11<00:06,  4.51it/s] 42%|████▏     | 21/50 [00:15<00:06,  4.49it/s] 42%|████▏     | 21/50 [00:14<00:06,  4.50it/s] 42%|████▏     | 21/50 [00:17<00:06,  4.48it/s] 42%|████▏     | 21/50 [00:19<00:06,  4.47it/s] 42%|████▏     | 21/50 [00:17<00:06,  4.48it/s] 44%|████▍     | 22/50 [00:10<00:06,  4.52it/s] 44%|████▍     | 22/50 [00:16<00:06,  4.50it/s] 44%|████▍     | 22/50 [00:11<00:06,  4.52it/s] 44%|████▍     | 22/50 [00:16<00:06,  4.50it/s] 44%|████▍     | 22/50 [00:19<00:06,  4.49it/s] 44%|████▍     | 22/50 [00:14<00:06,  4.51it/s] 44%|████▍     | 22/50 [00:17<00:06,  4.50it/s] 44%|████▍     | 22/50 [00:17<00:06,  4.50it/s] 46%|████▌     | 23/50 [00:16<00:05,  4.51it/s] 46%|████▌     | 23/50 [00:11<00:05,  4.52it/s] 46%|████▌     | 23/50 [00:11<00:05,  4.52it/s] 46%|████▌     | 23/50 [00:16<00:05,  4.51it/s] 46%|████▌     | 23/50 [00:17<00:05,  4.51it/s] 46%|████▌     | 23/50 [00:19<00:05,  4.50it/s] 46%|████▌     | 23/50 [00:15<00:05,  4.51it/s] 46%|████▌     | 23/50 [00:17<00:05,  4.51it/s] 48%|████▊     | 24/50 [00:11<00:05,  4.52it/s] 48%|████▊     | 24/50 [00:16<00:05,  4.51it/s] 48%|████▊     | 24/50 [00:11<00:05,  4.52it/s] 48%|████▊     | 24/50 [00:17<00:05,  4.51it/s] 48%|████▊     | 24/50 [00:19<00:05,  4.51it/s] 48%|████▊     | 24/50 [00:15<00:05,  4.52it/s] 48%|████▊     | 24/50 [00:16<00:05,  4.51it/s] 48%|████▊     | 24/50 [00:18<00:05,  4.51it/s] 50%|█████     | 25/50 [00:11<00:05,  4.53it/s] 50%|█████     | 25/50 [00:17<00:05,  4.52it/s] 50%|█████     | 25/50 [00:11<00:05,  4.53it/s] 50%|█████     | 25/50 [00:17<00:05,  4.52it/s] 50%|█████     | 25/50 [00:16<00:05,  4.53it/s] 50%|█████     | 25/50 [00:20<00:05,  4.52it/s] 50%|█████     | 25/50 [00:15<00:05,  4.53it/s] 50%|█████     | 25/50 [00:18<00:05,  4.52it/s] 52%|█████▏    | 26/50 [00:11<00:05,  4.52it/s] 52%|█████▏    | 26/50 [00:17<00:05,  4.52it/s] 52%|█████▏    | 26/50 [00:12<00:05,  4.52it/s] 52%|█████▏    | 26/50 [00:18<00:05,  4.52it/s] 52%|█████▏    | 26/50 [00:16<00:05,  4.52it/s] 52%|█████▏    | 26/50 [00:20<00:05,  4.52it/s] 52%|█████▏    | 26/50 [00:15<00:05,  4.52it/s] 52%|█████▏    | 26/50 [00:18<00:05,  4.52it/s] 54%|█████▍    | 27/50 [00:11<00:05,  4.54it/s] 54%|█████▍    | 27/50 [00:17<00:05,  4.53it/s] 54%|█████▍    | 27/50 [00:12<00:05,  4.54it/s] 54%|█████▍    | 27/50 [00:17<00:05,  4.53it/s] 54%|█████▍    | 27/50 [00:15<00:05,  4.53it/s] 54%|█████▍    | 27/50 [00:18<00:05,  4.53it/s] 54%|█████▍    | 27/50 [00:20<00:05,  4.53it/s] 54%|█████▍    | 27/50 [00:18<00:05,  4.53it/s] 56%|█████▌    | 28/50 [00:12<00:04,  4.54it/s] 56%|█████▌    | 28/50 [00:17<00:04,  4.54it/s] 56%|█████▌    | 28/50 [00:12<00:04,  4.54it/s] 56%|█████▌    | 28/50 [00:16<00:04,  4.54it/s] 56%|█████▌    | 28/50 [00:17<00:04,  4.54it/s] 56%|█████▌    | 28/50 [00:18<00:04,  4.54it/s] 56%|█████▌    | 28/50 [00:20<00:04,  4.54it/s] 56%|█████▌    | 28/50 [00:19<00:04,  4.54it/s] 58%|█████▊    | 29/50 [00:12<00:04,  4.55it/s] 58%|█████▊    | 29/50 [00:18<00:04,  4.55it/s] 58%|█████▊    | 29/50 [00:12<00:04,  4.55it/s] 58%|█████▊    | 29/50 [00:16<00:04,  4.55it/s] 58%|█████▊    | 29/50 [00:17<00:04,  4.55it/s] 58%|█████▊    | 29/50 [00:20<00:04,  4.55it/s] 58%|█████▊    | 29/50 [00:18<00:04,  4.55it/s] 58%|█████▊    | 29/50 [00:19<00:04,  4.55it/s] 60%|██████    | 30/50 [00:12<00:04,  4.53it/s] 60%|██████    | 30/50 [00:13<00:04,  4.53it/s] 60%|██████    | 30/50 [00:18<00:04,  4.53it/s] 60%|██████    | 30/50 [00:19<00:04,  4.53it/s] 60%|██████    | 30/50 [00:17<00:04,  4.53it/s] 60%|██████    | 30/50 [00:16<00:04,  4.53it/s] 60%|██████    | 30/50 [00:19<00:04,  4.53it/s] 60%|██████    | 30/50 [00:21<00:04,  4.52it/s] 62%|██████▏   | 31/50 [00:12<00:04,  4.17it/s] 62%|██████▏   | 31/50 [00:13<00:04,  4.17it/s] 62%|██████▏   | 31/50 [00:18<00:04,  4.17it/s] 62%|██████▏   | 31/50 [00:19<00:04,  4.17it/s] 62%|██████▏   | 31/50 [00:21<00:04,  4.17it/s] 62%|██████▏   | 31/50 [00:16<00:04,  4.17it/s] 62%|██████▏   | 31/50 [00:18<00:04,  4.16it/s] 62%|██████▏   | 31/50 [00:19<00:04,  4.17it/s] 64%|██████▍   | 32/50 [00:13<00:04,  4.28it/s] 64%|██████▍   | 32/50 [00:18<00:04,  4.28it/s] 64%|██████▍   | 32/50 [00:13<00:04,  4.28it/s] 64%|██████▍   | 32/50 [00:18<00:04,  4.28it/s] 64%|██████▍   | 32/50 [00:19<00:04,  4.28it/s] 64%|██████▍   | 32/50 [00:17<00:04,  4.28it/s] 64%|██████▍   | 32/50 [00:21<00:04,  4.28it/s] 64%|██████▍   | 32/50 [00:19<00:04,  4.28it/s] 66%|██████▌   | 33/50 [00:13<00:03,  4.34it/s] 66%|██████▌   | 33/50 [00:13<00:03,  4.34it/s] 66%|██████▌   | 33/50 [00:18<00:03,  4.34it/s] 66%|██████▌   | 33/50 [00:18<00:03,  4.34it/s] 66%|██████▌   | 33/50 [00:19<00:03,  4.34it/s] 66%|██████▌   | 33/50 [00:21<00:03,  4.34it/s] 66%|██████▌   | 33/50 [00:17<00:03,  4.34it/s] 66%|██████▌   | 33/50 [00:20<00:03,  4.34it/s] 68%|██████▊   | 34/50 [00:19<00:03,  4.41it/s] 68%|██████▊   | 34/50 [00:13<00:03,  4.41it/s] 68%|██████▊   | 34/50 [00:13<00:03,  4.41it/s] 68%|██████▊   | 34/50 [00:19<00:03,  4.41it/s] 68%|██████▊   | 34/50 [00:17<00:03,  4.41it/s] 68%|██████▊   | 34/50 [00:18<00:03,  4.41it/s] 68%|██████▊   | 34/50 [00:22<00:03,  4.41it/s] 68%|██████▊   | 34/50 [00:20<00:03,  4.41it/s] 70%|███████   | 35/50 [00:13<00:03,  4.45it/s] 70%|███████   | 35/50 [00:14<00:03,  4.45it/s] 70%|███████   | 35/50 [00:19<00:03,  4.45it/s] 70%|███████   | 35/50 [00:20<00:03,  4.45it/s] 70%|███████   | 35/50 [00:18<00:03,  4.45it/s] 70%|███████   | 35/50 [00:17<00:03,  4.45it/s] 70%|███████   | 35/50 [00:22<00:03,  4.45it/s] 70%|███████   | 35/50 [00:20<00:03,  4.45it/s] 72%|███████▏  | 36/50 [00:13<00:03,  4.47it/s] 72%|███████▏  | 36/50 [00:14<00:03,  4.47it/s] 72%|███████▏  | 36/50 [00:19<00:03,  4.47it/s] 72%|███████▏  | 36/50 [00:20<00:03,  4.47it/s] 72%|███████▏  | 36/50 [00:18<00:03,  4.47it/s] 72%|███████▏  | 36/50 [00:19<00:03,  4.47it/s] 72%|███████▏  | 36/50 [00:22<00:03,  4.47it/s] 72%|███████▏  | 36/50 [00:20<00:03,  4.47it/s] 74%|███████▍  | 37/50 [00:14<00:02,  4.49it/s] 74%|███████▍  | 37/50 [00:14<00:02,  4.49it/s] 74%|███████▍  | 37/50 [00:19<00:02,  4.49it/s] 74%|███████▍  | 37/50 [00:20<00:02,  4.49it/s] 74%|███████▍  | 37/50 [00:19<00:02,  4.49it/s] 74%|███████▍  | 37/50 [00:18<00:02,  4.49it/s] 74%|███████▍  | 37/50 [00:22<00:02,  4.49it/s] 74%|███████▍  | 37/50 [00:21<00:02,  4.49it/s] 76%|███████▌  | 38/50 [00:14<00:02,  4.49it/s] 76%|███████▌  | 38/50 [00:20<00:02,  4.49it/s] 76%|███████▌  | 38/50 [00:14<00:02,  4.49it/s] 76%|███████▌  | 38/50 [00:19<00:02,  4.49it/s] 76%|███████▌  | 38/50 [00:20<00:02,  4.49it/s] 76%|███████▌  | 38/50 [00:18<00:02,  4.49it/s] 76%|███████▌  | 38/50 [00:23<00:02,  4.49it/s] 76%|███████▌  | 38/50 [00:21<00:02,  4.49it/s] 78%|███████▊  | 39/50 [00:14<00:02,  4.49it/s] 78%|███████▊  | 39/50 [00:15<00:02,  4.49it/s] 78%|███████▊  | 39/50 [00:20<00:02,  4.49it/s] 78%|███████▊  | 39/50 [00:19<00:02,  4.49it/s] 78%|███████▊  | 39/50 [00:21<00:02,  4.49it/s] 78%|███████▊  | 39/50 [00:18<00:02,  4.49it/s] 78%|███████▊  | 39/50 [00:23<00:02,  4.49it/s] 78%|███████▊  | 39/50 [00:21<00:02,  4.49it/s] 80%|████████  | 40/50 [00:14<00:02,  4.50it/s] 80%|████████  | 40/50 [00:15<00:02,  4.50it/s] 80%|████████  | 40/50 [00:20<00:02,  4.49it/s] 80%|████████  | 40/50 [00:20<00:02,  4.50it/s] 80%|████████  | 40/50 [00:21<00:02,  4.50it/s] 80%|████████  | 40/50 [00:23<00:02,  4.50it/s] 80%|████████  | 40/50 [00:18<00:02,  4.50it/s] 80%|████████  | 40/50 [00:21<00:02,  4.50it/s] 82%|████████▏ | 41/50 [00:15<00:01,  4.51it/s] 82%|████████▏ | 41/50 [00:15<00:01,  4.51it/s] 82%|████████▏ | 41/50 [00:20<00:01,  4.51it/s] 82%|████████▏ | 41/50 [00:20<00:01,  4.51it/s] 82%|████████▏ | 41/50 [00:21<00:01,  4.51it/s] 82%|████████▏ | 41/50 [00:23<00:01,  4.52it/s] 82%|████████▏ | 41/50 [00:19<00:01,  4.51it/s] 82%|████████▏ | 41/50 [00:21<00:01,  4.51it/s] 84%|████████▍ | 42/50 [00:15<00:01,  4.53it/s] 84%|████████▍ | 42/50 [00:15<00:01,  4.53it/s] 84%|████████▍ | 42/50 [00:20<00:01,  4.53it/s] 84%|████████▍ | 42/50 [00:19<00:01,  4.53it/s] 84%|████████▍ | 42/50 [00:20<00:01,  4.53it/s] 84%|████████▍ | 42/50 [00:23<00:01,  4.53it/s] 84%|████████▍ | 42/50 [00:21<00:01,  4.52it/s] 84%|████████▍ | 42/50 [00:22<00:01,  4.52it/s] 86%|████████▌ | 43/50 [00:15<00:01,  4.53it/s] 86%|████████▌ | 43/50 [00:15<00:01,  4.53it/s] 86%|████████▌ | 43/50 [00:21<00:01,  4.53it/s] 86%|████████▌ | 43/50 [00:20<00:01,  4.53it/s] 86%|████████▌ | 43/50 [00:21<00:01,  4.53it/s] 86%|████████▌ | 43/50 [00:24<00:01,  4.53it/s] 86%|████████▌ | 43/50 [00:19<00:01,  4.53it/s] 86%|████████▌ | 43/50 [00:22<00:01,  4.53it/s] 88%|████████▊ | 44/50 [00:15<00:01,  4.54it/s] 88%|████████▊ | 44/50 [00:16<00:01,  4.54it/s] 88%|████████▊ | 44/50 [00:21<00:01,  4.54it/s] 88%|████████▊ | 44/50 [00:20<00:01,  4.54it/s] 88%|████████▊ | 44/50 [00:22<00:01,  4.54it/s] 88%|████████▊ | 44/50 [00:19<00:01,  4.54it/s] 88%|████████▊ | 44/50 [00:24<00:01,  4.54it/s] 88%|████████▊ | 44/50 [00:22<00:01,  4.54it/s] 90%|█████████ | 45/50 [00:15<00:01,  4.55it/s] 90%|█████████ | 45/50 [00:16<00:01,  4.55it/s] 90%|█████████ | 45/50 [00:21<00:01,  4.55it/s] 90%|█████████ | 45/50 [00:21<00:01,  4.55it/s] 90%|█████████ | 45/50 [00:20<00:01,  4.55it/s] 90%|█████████ | 45/50 [00:22<00:01,  4.55it/s] 90%|█████████ | 45/50 [00:24<00:01,  4.55it/s] 90%|█████████ | 45/50 [00:22<00:01,  4.55it/s] 92%|█████████▏| 46/50 [00:16<00:00,  4.56it/s] 92%|█████████▏| 46/50 [00:16<00:00,  4.56it/s] 92%|█████████▏| 46/50 [00:21<00:00,  4.56it/s] 92%|█████████▏| 46/50 [00:22<00:00,  4.56it/s] 92%|█████████▏| 46/50 [00:21<00:00,  4.56it/s] 92%|█████████▏| 46/50 [00:20<00:00,  4.56it/s] 92%|█████████▏| 46/50 [00:24<00:00,  4.56it/s] 92%|█████████▏| 46/50 [00:23<00:00,  4.56it/s] 94%|█████████▍| 47/50 [00:16<00:00,  4.54it/s] 94%|█████████▍| 47/50 [00:16<00:00,  4.54it/s] 94%|█████████▍| 47/50 [00:22<00:00,  4.54it/s] 94%|█████████▍| 47/50 [00:21<00:00,  4.54it/s] 94%|█████████▍| 47/50 [00:20<00:00,  4.54it/s] 94%|█████████▍| 47/50 [00:22<00:00,  4.54it/s] 94%|█████████▍| 47/50 [00:24<00:00,  4.54it/s] 94%|█████████▍| 47/50 [00:23<00:00,  4.54it/s] 96%|█████████▌| 48/50 [00:16<00:00,  4.52it/s] 96%|█████████▌| 48/50 [00:22<00:00,  4.52it/s] 96%|█████████▌| 48/50 [00:17<00:00,  4.52it/s] 96%|█████████▌| 48/50 [00:21<00:00,  4.52it/s] 96%|█████████▌| 48/50 [00:20<00:00,  4.52it/s] 96%|█████████▌| 48/50 [00:25<00:00,  4.52it/s] 96%|█████████▌| 48/50 [00:23<00:00,  4.52it/s] 96%|█████████▌| 48/50 [00:23<00:00,  4.52it/s] 98%|█████████▊| 49/50 [00:16<00:00,  4.53it/s] 98%|█████████▊| 49/50 [00:17<00:00,  4.53it/s] 98%|█████████▊| 49/50 [00:22<00:00,  4.53it/s] 98%|█████████▊| 49/50 [00:20<00:00,  4.53it/s] 98%|█████████▊| 49/50 [00:23<00:00,  4.53it/s] 98%|█████████▊| 49/50 [00:22<00:00,  4.53it/s] 98%|█████████▊| 49/50 [00:25<00:00,  4.52it/s] 98%|█████████▊| 49/50 [00:23<00:00,  4.52it/s]100%|██████████| 50/50 [00:17<00:00,  4.51it/s]100%|██████████| 50/50 [00:17<00:00,  4.51it/s]100%|██████████| 50/50 [00:22<00:00,  4.51it/s]100%|██████████| 50/50 [00:17<00:00,  2.93it/s]
代码执行时间: 17.07 秒
100%|██████████| 50/50 [00:17<00:00,  2.86it/s]
代码执行时间: 17.50 秒
100%|██████████| 50/50 [00:22<00:00,  2.20it/s]
代码执行时间: 22.73 秒
100%|██████████| 50/50 [00:23<00:00,  4.51it/s]100%|██████████| 50/50 [00:22<00:00,  4.51it/s]100%|██████████| 50/50 [00:25<00:00,  4.51it/s]100%|██████████| 50/50 [00:21<00:00,  4.51it/s]100%|██████████| 50/50 [00:23<00:00,  2.12it/s]100%|██████████| 50/50 [00:22<00:00,  2.25it/s]

代码执行时间: 23.53 秒
代码执行时间: 22.26 秒
100%|██████████| 50/50 [00:25<00:00,  1.95it/s]
100%|██████████| 50/50 [00:21<00:00,  2.37it/s]
代码执行时间: 25.67 秒
代码执行时间: 21.12 秒
100%|██████████| 50/50 [00:23<00:00,  4.51it/s]100%|██████████| 50/50 [00:23<00:00,  2.09it/s]
代码执行时间: 23.97 秒
2025-03-08 00:02:08.820 | INFO     | hyvideo.inference:predict:669 - Success, time: 26.098105430603027
2025-03-08 00:02:08.828 | INFO     | hyvideo.inference:predict:669 - Success, time: 20.06378197669983
2025-03-08 00:02:08.837 | INFO     | hyvideo.inference:predict:669 - Success, time: 20.392463445663452
2025-03-08 00:02:09.181 | INFO     | hyvideo.inference:predict:669 - Success, time: 27.199880838394165
2025-03-08 00:02:09.205 | INFO     | hyvideo.inference:predict:669 - Success, time: 24.56688690185547
2025-03-08 00:02:09.206 | INFO     | hyvideo.inference:predict:669 - Success, time: 26.16225266456604
2025-03-08 00:02:09.209 | INFO     | hyvideo.inference:predict:669 - Success, time: 29.100812673568726
2025-03-08 00:02:09.221 | INFO     | hyvideo.inference:predict:669 - Success, time: 26.968472480773926
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-08 00:02:10.250 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0308 00:02:15.306000 139730853885760 torch/distributed/run.py:779] 
W0308 00:02:15.306000 139730853885760 torch/distributed/run.py:779] *****************************************
W0308 00:02:15.306000 139730853885760 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0308 00:02:15.306000 139730853885760 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-08 00:02:22.003 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:02:22 [parallel_state.py:200] world_size=4 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-08 00:02:22.035 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:02:22 [parallel_state.py:200] world_size=4 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-08 00:02:22.045 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:02:22 [parallel_state.py:200] world_size=4 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=4, ring_degree=1)
2025-03-08 00:02:22.058 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:02:22 [parallel_state.py:200] world_size=4 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-08 00:02:22.102 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:02:22.103 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:02:22.104 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:02:22.104 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:02:23.457 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:02:23.475 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:02:23.488 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:02:23.515 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:02:48.969 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-08 00:02:49.258 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-08 00:02:49.307 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
2025-03-08 00:02:49.401 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-08 00:02:50.903 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-08 00:02:51.018 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-08 00:02:52.070 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-08 00:02:52.109 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-08 00:02:52.224 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:02:52.260 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:02:52.332 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-08 00:02:52.473 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.73s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.80s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.08s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.06s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.75s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.69s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.83s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.97s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.98s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:03,  3.94s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.46s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.10s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.37s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.72s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.45s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.37s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.72s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.46s/it]
2025-03-08 00:03:10.481 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:03:12.709 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:03:13.115 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:03:13.460 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:03:13.613 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:03:13.658 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:03:13.727 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:03:13.735 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-08 00:03:14.280 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-08 00:03:14.797 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:03:15.453 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:03:15.869 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:03:16.027 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:03:16.069 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:03:16.141 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:03:16.150 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-08 00:03:17.100 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:03:17.500 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:03:17.652 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:03:17.871 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:03:18.039 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:03:18.044 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:03:18.051 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
2025-03-08 00:03:18.480 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-08 00:03:18.632 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:03:18.683 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:03:18.767 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:03:18.775 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:03<02:39,  3.26s/it]  2%|▏         | 1/50 [00:08<06:41,  8.19s/it]  2%|▏         | 1/50 [00:05<04:45,  5.83s/it]  2%|▏         | 1/50 [00:04<03:16,  4.01s/it]  4%|▍         | 2/50 [00:03<01:14,  1.56s/it]  4%|▍         | 2/50 [00:04<01:29,  1.87s/it]  4%|▍         | 2/50 [00:08<02:52,  3.59s/it]  4%|▍         | 2/50 [00:06<02:05,  2.62s/it]  6%|▌         | 3/50 [00:03<00:46,  1.00it/s]  6%|▌         | 3/50 [00:04<00:54,  1.16s/it]  6%|▌         | 3/50 [00:08<01:38,  2.10s/it]  6%|▌         | 3/50 [00:06<01:13,  1.57s/it]  8%|▊         | 4/50 [00:04<00:33,  1.37it/s]  8%|▊         | 4/50 [00:09<01:04,  1.40s/it]  8%|▊         | 4/50 [00:05<00:38,  1.20it/s]  8%|▊         | 4/50 [00:06<00:49,  1.08s/it] 10%|█         | 5/50 [00:04<00:26,  1.71it/s] 10%|█         | 5/50 [00:05<00:29,  1.54it/s] 10%|█         | 5/50 [00:09<00:45,  1.01s/it] 10%|█         | 5/50 [00:07<00:36,  1.24it/s] 12%|█▏        | 6/50 [00:04<00:21,  2.01it/s] 12%|█▏        | 6/50 [00:05<00:23,  1.85it/s] 12%|█▏        | 6/50 [00:09<00:34,  1.28it/s] 12%|█▏        | 6/50 [00:07<00:28,  1.55it/s] 14%|█▍        | 7/50 [00:05<00:19,  2.26it/s] 14%|█▍        | 7/50 [00:10<00:27,  1.58it/s] 14%|█▍        | 7/50 [00:06<00:20,  2.12it/s] 14%|█▍        | 7/50 [00:07<00:23,  1.85it/s] 16%|█▌        | 8/50 [00:05<00:17,  2.46it/s] 16%|█▌        | 8/50 [00:10<00:22,  1.87it/s] 16%|█▌        | 8/50 [00:06<00:17,  2.35it/s] 16%|█▌        | 8/50 [00:08<00:19,  2.11it/s] 18%|█▊        | 9/50 [00:05<00:15,  2.63it/s] 18%|█▊        | 9/50 [00:06<00:16,  2.54it/s] 18%|█▊        | 9/50 [00:10<00:19,  2.13it/s] 18%|█▊        | 9/50 [00:08<00:17,  2.34it/s] 20%|██        | 10/50 [00:06<00:14,  2.75it/s] 20%|██        | 10/50 [00:06<00:14,  2.68it/s] 20%|██        | 10/50 [00:11<00:17,  2.35it/s] 20%|██        | 10/50 [00:08<00:15,  2.52it/s] 22%|██▏       | 11/50 [00:06<00:13,  2.84it/s] 22%|██▏       | 11/50 [00:11<00:15,  2.53it/s] 22%|██▏       | 11/50 [00:07<00:14,  2.79it/s] 22%|██▏       | 11/50 [00:09<00:14,  2.67it/s] 24%|██▍       | 12/50 [00:06<00:13,  2.90it/s] 24%|██▍       | 12/50 [00:07<00:13,  2.87it/s] 24%|██▍       | 12/50 [00:11<00:14,  2.67it/s] 24%|██▍       | 12/50 [00:09<00:13,  2.78it/s] 26%|██▌       | 13/50 [00:07<00:12,  2.95it/s] 26%|██▌       | 13/50 [00:07<00:12,  2.92it/s] 26%|██▌       | 13/50 [00:12<00:13,  2.78it/s] 26%|██▌       | 13/50 [00:09<00:12,  2.86it/s] 28%|██▊       | 14/50 [00:07<00:12,  2.98it/s] 28%|██▊       | 14/50 [00:08<00:12,  2.96it/s] 28%|██▊       | 14/50 [00:12<00:12,  2.86it/s] 28%|██▊       | 14/50 [00:10<00:12,  2.92it/s] 30%|███       | 15/50 [00:07<00:11,  2.99it/s] 30%|███       | 15/50 [00:08<00:11,  2.98it/s] 30%|███       | 15/50 [00:12<00:12,  2.90it/s] 30%|███       | 15/50 [00:10<00:11,  2.94it/s] 32%|███▏      | 16/50 [00:08<00:11,  3.01it/s] 32%|███▏      | 16/50 [00:08<00:11,  3.01it/s] 32%|███▏      | 16/50 [00:13<00:11,  2.95it/s] 32%|███▏      | 16/50 [00:10<00:11,  2.98it/s] 34%|███▍      | 17/50 [00:08<00:10,  3.03it/s] 34%|███▍      | 17/50 [00:09<00:10,  3.03it/s] 34%|███▍      | 17/50 [00:13<00:11,  2.99it/s] 34%|███▍      | 17/50 [00:11<00:10,  3.01it/s] 36%|███▌      | 18/50 [00:08<00:10,  3.04it/s] 36%|███▌      | 18/50 [00:09<00:10,  3.04it/s] 36%|███▌      | 18/50 [00:13<00:10,  3.01it/s] 36%|███▌      | 18/50 [00:11<00:10,  3.03it/s] 38%|███▊      | 19/50 [00:09<00:10,  3.05it/s] 38%|███▊      | 19/50 [00:09<00:10,  3.05it/s] 38%|███▊      | 19/50 [00:14<00:10,  3.03it/s] 38%|███▊      | 19/50 [00:11<00:10,  3.04it/s] 40%|████      | 20/50 [00:09<00:09,  3.06it/s] 40%|████      | 20/50 [00:10<00:09,  3.06it/s] 40%|████      | 20/50 [00:14<00:09,  3.05it/s] 40%|████      | 20/50 [00:12<00:09,  3.05it/s] 42%|████▏     | 21/50 [00:09<00:09,  3.06it/s] 42%|████▏     | 21/50 [00:10<00:09,  3.06it/s] 42%|████▏     | 21/50 [00:14<00:09,  3.05it/s] 42%|████▏     | 21/50 [00:12<00:09,  3.06it/s] 44%|████▍     | 22/50 [00:10<00:09,  3.06it/s] 44%|████▍     | 22/50 [00:10<00:09,  3.05it/s] 44%|████▍     | 22/50 [00:15<00:09,  3.05it/s] 44%|████▍     | 22/50 [00:12<00:09,  3.05it/s] 46%|████▌     | 23/50 [00:10<00:08,  3.06it/s] 46%|████▌     | 23/50 [00:11<00:08,  3.06it/s] 46%|████▌     | 23/50 [00:15<00:08,  3.05it/s] 46%|████▌     | 23/50 [00:13<00:08,  3.05it/s] 48%|████▊     | 24/50 [00:10<00:08,  3.06it/s] 48%|████▊     | 24/50 [00:11<00:08,  3.06it/s] 48%|████▊     | 24/50 [00:15<00:08,  3.06it/s] 48%|████▊     | 24/50 [00:13<00:08,  3.06it/s] 50%|█████     | 25/50 [00:11<00:08,  3.07it/s] 50%|█████     | 25/50 [00:16<00:08,  3.06it/s] 50%|█████     | 25/50 [00:11<00:08,  3.07it/s] 50%|█████     | 25/50 [00:13<00:08,  3.06it/s] 52%|█████▏    | 26/50 [00:11<00:07,  3.06it/s] 52%|█████▏    | 26/50 [00:16<00:07,  3.06it/s] 52%|█████▏    | 26/50 [00:12<00:07,  3.06it/s] 52%|█████▏    | 26/50 [00:14<00:07,  3.06it/s] 54%|█████▍    | 27/50 [00:11<00:07,  3.06it/s] 54%|█████▍    | 27/50 [00:12<00:07,  3.06it/s] 54%|█████▍    | 27/50 [00:16<00:07,  3.06it/s] 54%|█████▍    | 27/50 [00:14<00:07,  3.06it/s] 56%|█████▌    | 28/50 [00:12<00:07,  3.07it/s] 56%|█████▌    | 28/50 [00:17<00:07,  3.07it/s] 56%|█████▌    | 28/50 [00:12<00:07,  3.07it/s] 56%|█████▌    | 28/50 [00:14<00:07,  3.07it/s] 58%|█████▊    | 29/50 [00:12<00:06,  3.07it/s] 58%|█████▊    | 29/50 [00:13<00:06,  3.07it/s] 58%|█████▊    | 29/50 [00:17<00:06,  3.07it/s] 58%|█████▊    | 29/50 [00:15<00:06,  3.07it/s] 60%|██████    | 30/50 [00:12<00:06,  3.07it/s] 60%|██████    | 30/50 [00:17<00:06,  3.07it/s] 60%|██████    | 30/50 [00:13<00:06,  3.07it/s] 60%|██████    | 30/50 [00:15<00:06,  3.07it/s] 62%|██████▏   | 31/50 [00:13<00:06,  3.07it/s] 62%|██████▏   | 31/50 [00:13<00:06,  3.07it/s] 62%|██████▏   | 31/50 [00:18<00:06,  3.07it/s] 62%|██████▏   | 31/50 [00:15<00:06,  3.07it/s] 64%|██████▍   | 32/50 [00:13<00:05,  3.07it/s] 64%|██████▍   | 32/50 [00:14<00:05,  3.07it/s] 64%|██████▍   | 32/50 [00:18<00:05,  3.07it/s] 64%|██████▍   | 32/50 [00:15<00:05,  3.07it/s] 66%|██████▌   | 33/50 [00:13<00:05,  3.08it/s] 66%|██████▌   | 33/50 [00:14<00:05,  3.08it/s] 66%|██████▌   | 33/50 [00:18<00:05,  3.08it/s] 66%|██████▌   | 33/50 [00:16<00:05,  3.08it/s] 68%|██████▊   | 34/50 [00:14<00:05,  3.07it/s] 68%|██████▊   | 34/50 [00:14<00:05,  3.07it/s] 68%|██████▊   | 34/50 [00:18<00:05,  3.07it/s] 68%|██████▊   | 34/50 [00:16<00:05,  3.07it/s] 70%|███████   | 35/50 [00:14<00:04,  3.06it/s] 70%|███████   | 35/50 [00:19<00:04,  3.06it/s] 70%|███████   | 35/50 [00:15<00:04,  3.06it/s] 70%|███████   | 35/50 [00:16<00:04,  3.06it/s] 72%|███████▏  | 36/50 [00:14<00:04,  3.06it/s] 72%|███████▏  | 36/50 [00:19<00:04,  3.06it/s] 72%|███████▏  | 36/50 [00:15<00:04,  3.06it/s] 72%|███████▏  | 36/50 [00:17<00:04,  3.06it/s] 74%|███████▍  | 37/50 [00:15<00:04,  3.07it/s] 74%|███████▍  | 37/50 [00:15<00:04,  3.07it/s] 74%|███████▍  | 37/50 [00:19<00:04,  3.07it/s] 74%|███████▍  | 37/50 [00:17<00:04,  3.07it/s] 76%|███████▌  | 38/50 [00:15<00:03,  3.07it/s] 76%|███████▌  | 38/50 [00:20<00:03,  3.07it/s] 76%|███████▌  | 38/50 [00:16<00:03,  3.07it/s] 76%|███████▌  | 38/50 [00:17<00:03,  3.07it/s] 78%|███████▊  | 39/50 [00:15<00:03,  3.07it/s] 78%|███████▊  | 39/50 [00:20<00:03,  3.07it/s] 78%|███████▊  | 39/50 [00:16<00:03,  3.07it/s] 78%|███████▊  | 39/50 [00:18<00:03,  3.07it/s] 80%|████████  | 40/50 [00:16<00:03,  3.07it/s] 80%|████████  | 40/50 [00:20<00:03,  3.07it/s] 80%|████████  | 40/50 [00:16<00:03,  3.07it/s] 80%|████████  | 40/50 [00:18<00:03,  3.07it/s] 82%|████████▏ | 41/50 [00:21<00:02,  3.08it/s] 82%|████████▏ | 41/50 [00:16<00:02,  3.08it/s] 82%|████████▏ | 41/50 [00:17<00:02,  3.08it/s] 82%|████████▏ | 41/50 [00:18<00:02,  3.08it/s] 84%|████████▍ | 42/50 [00:16<00:02,  3.06it/s] 84%|████████▍ | 42/50 [00:21<00:02,  3.07it/s] 84%|████████▍ | 42/50 [00:17<00:02,  3.06it/s] 84%|████████▍ | 42/50 [00:19<00:02,  3.06it/s] 86%|████████▌ | 43/50 [00:17<00:02,  3.07it/s] 86%|████████▌ | 43/50 [00:21<00:02,  3.07it/s] 86%|████████▌ | 43/50 [00:17<00:02,  3.07it/s] 86%|████████▌ | 43/50 [00:19<00:02,  3.07it/s] 88%|████████▊ | 44/50 [00:17<00:01,  3.07it/s] 88%|████████▊ | 44/50 [00:22<00:01,  3.07it/s] 88%|████████▊ | 44/50 [00:18<00:01,  3.07it/s] 88%|████████▊ | 44/50 [00:19<00:01,  3.07it/s] 90%|█████████ | 45/50 [00:22<00:01,  3.08it/s] 90%|█████████ | 45/50 [00:17<00:01,  3.07it/s] 90%|█████████ | 45/50 [00:18<00:01,  3.07it/s] 90%|█████████ | 45/50 [00:20<00:01,  3.07it/s] 92%|█████████▏| 46/50 [00:17<00:01,  3.08it/s] 92%|█████████▏| 46/50 [00:22<00:01,  3.08it/s] 92%|█████████▏| 46/50 [00:18<00:01,  3.08it/s] 92%|█████████▏| 46/50 [00:20<00:01,  3.08it/s] 94%|█████████▍| 47/50 [00:18<00:00,  3.08it/s] 94%|█████████▍| 47/50 [00:23<00:00,  3.08it/s] 94%|█████████▍| 47/50 [00:19<00:00,  3.08it/s] 94%|█████████▍| 47/50 [00:20<00:00,  3.08it/s] 96%|█████████▌| 48/50 [00:23<00:00,  3.08it/s] 96%|█████████▌| 48/50 [00:18<00:00,  3.08it/s] 96%|█████████▌| 48/50 [00:19<00:00,  3.08it/s] 96%|█████████▌| 48/50 [00:21<00:00,  3.08it/s] 98%|█████████▊| 49/50 [00:23<00:00,  3.08it/s] 98%|█████████▊| 49/50 [00:18<00:00,  3.08it/s] 98%|█████████▊| 49/50 [00:19<00:00,  3.08it/s] 98%|█████████▊| 49/50 [00:21<00:00,  3.08it/s]100%|██████████| 50/50 [00:24<00:00,  3.08it/s]100%|██████████| 50/50 [00:19<00:00,  3.08it/s]100%|██████████| 50/50 [00:24<00:00,  2.07it/s]
代码执行时间: 24.21 秒
100%|██████████| 50/50 [00:19<00:00,  2.59it/s]
代码执行时间: 19.28 秒
100%|██████████| 50/50 [00:20<00:00,  3.08it/s]100%|██████████| 50/50 [00:20<00:00,  2.50it/s]
代码执行时间: 20.03 秒
100%|██████████| 50/50 [00:21<00:00,  3.08it/s]100%|██████████| 50/50 [00:21<00:00,  2.29it/s]
代码执行时间: 21.85 秒
2025-03-08 00:03:41.004 | INFO     | hyvideo.inference:predict:669 - Success, time: 27.268200159072876
2025-03-08 00:03:41.004 | INFO     | hyvideo.inference:predict:669 - Success, time: 22.22856068611145
2025-03-08 00:03:41.320 | INFO     | hyvideo.inference:predict:669 - Success, time: 25.170047760009766
2025-03-08 00:03:41.381 | INFO     | hyvideo.inference:predict:669 - Success, time: 23.329824447631836
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-08 00:03:42.430 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
W0308 00:03:45.991000 140382840096576 torch/distributed/run.py:779] 
W0308 00:03:45.991000 140382840096576 torch/distributed/run.py:779] *****************************************
W0308 00:03:45.991000 140382840096576 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0308 00:03:45.991000 140382840096576 torch/distributed/run.py:779] *****************************************
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=2, ring_degree=1)
2025-03-08 00:03:51.713 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:03:51 [parallel_state.py:200] world_size=2 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=2, ring_degree=1)
2025-03-08 00:03:51.810 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
DEBUG 03-08 00:03:51 [parallel_state.py:200] world_size=2 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl
2025-03-08 00:03:51.851 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:03:51.852 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:03:52.466 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:03:52.475 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:04:08.264 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-08 00:04:10.158 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-08 00:04:10.279 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-08 00:04:12.755 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.61s/it]2025-03-08 00:04:14.673 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-08 00:04:14.787 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.60s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.70s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.71s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.67s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.21s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.73s/it]
2025-03-08 00:04:28.227 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:04:30.451 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:04:30.765 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:04:30.911 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:04:30.948 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:04:31.013 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:04:31.020 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]2025-03-08 00:04:33.414 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:04:35.951 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:04:36.276 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:04:36.428 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:04:36.462 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:04:36.525 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:04:36.532 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:07<06:31,  8.00s/it]  2%|▏         | 1/50 [00:02<01:54,  2.34s/it]  4%|▍         | 2/50 [00:08<02:54,  3.63s/it]  4%|▍         | 2/50 [00:02<01:02,  1.30s/it]  6%|▌         | 3/50 [00:09<01:44,  2.22s/it]  6%|▌         | 3/50 [00:03<00:44,  1.05it/s]  8%|▊         | 4/50 [00:09<01:11,  1.56s/it]  8%|▊         | 4/50 [00:04<00:36,  1.26it/s] 10%|█         | 5/50 [00:10<00:53,  1.20s/it] 10%|█         | 5/50 [00:04<00:31,  1.41it/s] 12%|█▏        | 6/50 [00:10<00:42,  1.03it/s] 12%|█▏        | 6/50 [00:05<00:28,  1.53it/s] 14%|█▍        | 7/50 [00:11<00:35,  1.19it/s] 14%|█▍        | 7/50 [00:05<00:26,  1.61it/s] 16%|█▌        | 8/50 [00:11<00:31,  1.34it/s] 16%|█▌        | 8/50 [00:06<00:25,  1.67it/s] 18%|█▊        | 9/50 [00:12<00:28,  1.46it/s] 18%|█▊        | 9/50 [00:06<00:23,  1.72it/s] 20%|██        | 10/50 [00:12<00:25,  1.56it/s] 20%|██        | 10/50 [00:07<00:22,  1.75it/s] 22%|██▏       | 11/50 [00:13<00:23,  1.63it/s] 22%|██▏       | 11/50 [00:07<00:22,  1.77it/s] 24%|██▍       | 12/50 [00:14<00:22,  1.69it/s] 24%|██▍       | 12/50 [00:08<00:21,  1.79it/s] 26%|██▌       | 13/50 [00:14<00:21,  1.73it/s] 26%|██▌       | 13/50 [00:08<00:20,  1.80it/s] 28%|██▊       | 14/50 [00:15<00:20,  1.76it/s] 28%|██▊       | 14/50 [00:09<00:19,  1.81it/s] 30%|███       | 15/50 [00:15<00:19,  1.78it/s] 30%|███       | 15/50 [00:10<00:19,  1.82it/s] 32%|███▏      | 16/50 [00:16<00:18,  1.80it/s] 32%|███▏      | 16/50 [00:10<00:18,  1.82it/s] 34%|███▍      | 17/50 [00:16<00:18,  1.81it/s] 34%|███▍      | 17/50 [00:11<00:18,  1.82it/s] 36%|███▌      | 18/50 [00:17<00:17,  1.81it/s] 36%|███▌      | 18/50 [00:11<00:17,  1.83it/s] 38%|███▊      | 19/50 [00:17<00:17,  1.82it/s] 38%|███▊      | 19/50 [00:12<00:16,  1.83it/s] 40%|████      | 20/50 [00:18<00:16,  1.82it/s] 40%|████      | 20/50 [00:12<00:16,  1.83it/s] 42%|████▏     | 21/50 [00:18<00:15,  1.82it/s] 42%|████▏     | 21/50 [00:13<00:15,  1.83it/s] 44%|████▍     | 22/50 [00:19<00:15,  1.83it/s] 44%|████▍     | 22/50 [00:13<00:15,  1.83it/s] 46%|████▌     | 23/50 [00:20<00:14,  1.83it/s] 46%|████▌     | 23/50 [00:14<00:14,  1.83it/s] 48%|████▊     | 24/50 [00:20<00:14,  1.83it/s] 48%|████▊     | 24/50 [00:14<00:14,  1.83it/s] 50%|█████     | 25/50 [00:21<00:13,  1.83it/s] 50%|█████     | 25/50 [00:15<00:13,  1.83it/s] 52%|█████▏    | 26/50 [00:21<00:13,  1.83it/s] 52%|█████▏    | 26/50 [00:16<00:13,  1.83it/s] 54%|█████▍    | 27/50 [00:22<00:12,  1.83it/s] 54%|█████▍    | 27/50 [00:16<00:12,  1.83it/s] 56%|█████▌    | 28/50 [00:22<00:12,  1.83it/s] 56%|█████▌    | 28/50 [00:17<00:12,  1.83it/s] 58%|█████▊    | 29/50 [00:23<00:11,  1.83it/s] 58%|█████▊    | 29/50 [00:17<00:11,  1.83it/s] 60%|██████    | 30/50 [00:23<00:10,  1.83it/s] 60%|██████    | 30/50 [00:18<00:10,  1.83it/s] 62%|██████▏   | 31/50 [00:24<00:10,  1.83it/s] 62%|██████▏   | 31/50 [00:18<00:10,  1.83it/s] 64%|██████▍   | 32/50 [00:24<00:09,  1.83it/s] 64%|██████▍   | 32/50 [00:19<00:09,  1.83it/s] 66%|██████▌   | 33/50 [00:25<00:09,  1.83it/s] 66%|██████▌   | 33/50 [00:19<00:09,  1.83it/s] 68%|██████▊   | 34/50 [00:26<00:08,  1.83it/s] 68%|██████▊   | 34/50 [00:20<00:08,  1.83it/s] 70%|███████   | 35/50 [00:26<00:08,  1.83it/s] 70%|███████   | 35/50 [00:20<00:08,  1.83it/s] 72%|███████▏  | 36/50 [00:27<00:07,  1.82it/s] 72%|███████▏  | 36/50 [00:21<00:07,  1.82it/s] 74%|███████▍  | 37/50 [00:27<00:07,  1.83it/s] 74%|███████▍  | 37/50 [00:22<00:07,  1.83it/s] 76%|███████▌  | 38/50 [00:28<00:06,  1.83it/s] 76%|███████▌  | 38/50 [00:22<00:06,  1.83it/s] 78%|███████▊  | 39/50 [00:28<00:06,  1.83it/s] 78%|███████▊  | 39/50 [00:23<00:06,  1.83it/s] 80%|████████  | 40/50 [00:29<00:05,  1.83it/s] 80%|████████  | 40/50 [00:23<00:05,  1.83it/s] 82%|████████▏ | 41/50 [00:29<00:04,  1.83it/s] 82%|████████▏ | 41/50 [00:24<00:04,  1.83it/s] 84%|████████▍ | 42/50 [00:30<00:04,  1.83it/s] 84%|████████▍ | 42/50 [00:24<00:04,  1.83it/s] 86%|████████▌ | 43/50 [00:31<00:03,  1.83it/s] 86%|████████▌ | 43/50 [00:25<00:03,  1.83it/s] 88%|████████▊ | 44/50 [00:31<00:03,  1.83it/s] 88%|████████▊ | 44/50 [00:25<00:03,  1.83it/s] 90%|█████████ | 45/50 [00:32<00:02,  1.83it/s] 90%|█████████ | 45/50 [00:26<00:02,  1.83it/s] 92%|█████████▏| 46/50 [00:32<00:02,  1.84it/s] 92%|█████████▏| 46/50 [00:26<00:02,  1.84it/s] 94%|█████████▍| 47/50 [00:33<00:01,  1.85it/s] 94%|█████████▍| 47/50 [00:27<00:01,  1.85it/s] 96%|█████████▌| 48/50 [00:33<00:01,  1.85it/s] 96%|█████████▌| 48/50 [00:28<00:01,  1.85it/s] 98%|█████████▊| 49/50 [00:34<00:00,  1.86it/s] 98%|█████████▊| 49/50 [00:28<00:00,  1.86it/s]100%|██████████| 50/50 [00:34<00:00,  1.86it/s]100%|██████████| 50/50 [00:34<00:00,  1.44it/s]
代码执行时间: 34.78 秒
100%|██████████| 50/50 [00:29<00:00,  1.86it/s]100%|██████████| 50/50 [00:29<00:00,  1.72it/s]
代码执行时间: 29.12 秒
2025-03-08 00:05:08.852 | INFO     | hyvideo.inference:predict:669 - Success, time: 32.31981158256531
2025-03-08 00:05:08.863 | INFO     | hyvideo.inference:predict:669 - Success, time: 37.84229373931885
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-08 00:05:09.936 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='/data/yexin/workspace/HunyuanVideo/ckpts', dit_weight='/data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=50, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[360, 640], video_length=49, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=False, reproduce=False, ulysses_degree=1, ring_degree=1)
2025-03-08 00:05:19.173 | INFO     | hyvideo.inference:from_pretrained:154 - Got text-to-video model root path: /data/yexin/workspace/HunyuanVideo/ckpts
2025-03-08 00:05:19.173 | INFO     | hyvideo.inference:from_pretrained:189 - Building model...
2025-03-08 00:05:19.415 | INFO     | hyvideo.inference:load_state_dict:340 - Loading torch model /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt...
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/inference.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)
2025-03-08 00:05:34.962 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /data/yexin/workspace/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/vae
/home/xuran/ProfilingDiT/ori/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(vae_ckpt, map_location=vae.device)
2025-03-08 00:05:36.640 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-03-08 00:05:36.783 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.02it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.03it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.54it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.30it/s]
2025-03-08 00:05:44.234 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:05:47.767 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (llm) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder
2025-03-08 00:05:48.086 | INFO     | hyvideo.text_encoder:load_text_encoder:28 - Loading text encoder model (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:05:48.178 | INFO     | hyvideo.text_encoder:load_text_encoder:50 - Text encoder to dtype: torch.float16
2025-03-08 00:05:48.224 | INFO     | hyvideo.text_encoder:load_tokenizer:64 - Loading tokenizer (clipL) from: /data/yexin/workspace/HunyuanVideo/ckpts/text_encoder_2
2025-03-08 00:05:48.294 | INFO     | hyvideo.inference:predict:580 - Input (height, width, video_length) = (360, 640, 49)
2025-03-08 00:05:48.311 | DEBUG    | hyvideo.inference:predict:640 - 
                        height: 368
                         width: 640
                  video_length: 49
                        prompt: ['A cat walks on the grass, realistic style.']
                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']
                          seed: 42
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 11960
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:01<01:04,  1.31s/it]  4%|▍         | 2/50 [00:02<00:52,  1.08s/it]  6%|▌         | 3/50 [00:03<00:47,  1.02s/it]  8%|▊         | 4/50 [00:04<00:45,  1.02it/s] 10%|█         | 5/50 [00:05<00:43,  1.03it/s] 12%|█▏        | 6/50 [00:05<00:42,  1.04it/s] 14%|█▍        | 7/50 [00:06<00:40,  1.05it/s] 16%|█▌        | 8/50 [00:07<00:39,  1.06it/s] 18%|█▊        | 9/50 [00:08<00:38,  1.05it/s] 20%|██        | 10/50 [00:09<00:37,  1.06it/s] 22%|██▏       | 11/50 [00:10<00:36,  1.06it/s] 24%|██▍       | 12/50 [00:11<00:35,  1.06it/s] 26%|██▌       | 13/50 [00:12<00:34,  1.06it/s] 28%|██▊       | 14/50 [00:13<00:33,  1.07it/s] 30%|███       | 15/50 [00:14<00:32,  1.07it/s] 32%|███▏      | 16/50 [00:15<00:31,  1.06it/s] 34%|███▍      | 17/50 [00:16<00:30,  1.07it/s] 36%|███▌      | 18/50 [00:17<00:29,  1.08it/s] 38%|███▊      | 19/50 [00:18<00:28,  1.09it/s] 40%|████      | 20/50 [00:18<00:27,  1.10it/s] 42%|████▏     | 21/50 [00:19<00:26,  1.11it/s] 44%|████▍     | 22/50 [00:20<00:25,  1.11it/s] 46%|████▌     | 23/50 [00:21<00:24,  1.11it/s] 48%|████▊     | 24/50 [00:22<00:23,  1.11it/s] 50%|█████     | 25/50 [00:23<00:22,  1.12it/s] 52%|█████▏    | 26/50 [00:24<00:21,  1.12it/s] 54%|█████▍    | 27/50 [00:25<00:20,  1.12it/s] 56%|█████▌    | 28/50 [00:26<00:19,  1.12it/s] 58%|█████▊    | 29/50 [00:27<00:18,  1.12it/s] 60%|██████    | 30/50 [00:27<00:17,  1.12it/s] 62%|██████▏   | 31/50 [00:28<00:16,  1.12it/s] 64%|██████▍   | 32/50 [00:29<00:16,  1.12it/s] 66%|██████▌   | 33/50 [00:30<00:15,  1.12it/s] 68%|██████▊   | 34/50 [00:31<00:14,  1.12it/s] 70%|███████   | 35/50 [00:32<00:13,  1.12it/s] 72%|███████▏  | 36/50 [00:33<00:12,  1.12it/s] 74%|███████▍  | 37/50 [00:34<00:11,  1.12it/s] 76%|███████▌  | 38/50 [00:35<00:10,  1.12it/s] 78%|███████▊  | 39/50 [00:35<00:09,  1.12it/s] 80%|████████  | 40/50 [00:36<00:08,  1.12it/s] 82%|████████▏ | 41/50 [00:37<00:08,  1.12it/s] 84%|████████▍ | 42/50 [00:38<00:07,  1.12it/s] 86%|████████▌ | 43/50 [00:39<00:06,  1.12it/s] 88%|████████▊ | 44/50 [00:40<00:05,  1.12it/s] 90%|█████████ | 45/50 [00:41<00:04,  1.12it/s] 92%|█████████▏| 46/50 [00:42<00:03,  1.12it/s] 94%|█████████▍| 47/50 [00:43<00:02,  1.12it/s] 96%|█████████▌| 48/50 [00:43<00:01,  1.12it/s] 98%|█████████▊| 49/50 [00:44<00:00,  1.12it/s]100%|██████████| 50/50 [00:45<00:00,  1.12it/s]100%|██████████| 50/50 [00:45<00:00,  1.09it/s]
代码执行时间: 45.76 秒
2025-03-08 00:06:37.258 | INFO     | hyvideo.inference:predict:669 - Success, time: 48.946988105773926
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-08 00:06:38.314 | INFO     | __main__:main:54 - Sample save to: ./results/seed42_A cat walks on the grass, realistic style..mp4
